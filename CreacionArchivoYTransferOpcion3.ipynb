{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b9d4a9",
   "metadata": {},
   "source": [
    "# Creamos la estructura de datos para la opción 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a352587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 09:56:50.290127: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 09:56:50.293372: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 09:56:50.303453: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 09:56:50.320945: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 09:56:50.325927: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 09:56:50.344537: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 09:56:51.027973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import os\n",
    "import json\n",
    "\n",
    "import random as python_random\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras import layers, models\n",
    "\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "from keras_tuner import HyperModel, HyperParameters\n",
    "from keras_tuner.tuners import Hyperband\n",
    "\n",
    "from funcionesComunes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e6d38",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f6b41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir el modelo LSTM basado en la configuración\n",
    "def build_model_from_config(input_shape, config):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Añadir capas LSTM iniciales\n",
    "    for i in range(config[\"num_lstm_layers\"]):\n",
    "        units = config.get(f\"units_lstm_{i}\")\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units=units, input_shape=input_shape, return_sequences=True, use_bias=True))\n",
    "        else:\n",
    "            model.add(LSTM(units=units, return_sequences=True, use_bias=True))\n",
    "    \n",
    "    # Capa Dropout\n",
    "    model.add(Dropout(config[\"dropout\"]))\n",
    "    \n",
    "    # Capas LSTM adicionales después de Dropout\n",
    "    for i in range(config[\"num_lstm_layers_after\"]):\n",
    "        units = config.get(f\"units_lstm_after_{i}\")\n",
    "        return_sequences = (i < config[\"num_lstm_layers_after\"] - 1)  # Última capa no tiene return_sequences\n",
    "        model.add(LSTM(units=units, return_sequences=return_sequences, use_bias=True))\n",
    "    \n",
    "    # Capa Dense\n",
    "    model.add(Dense(config[\"dense_units\"], activation=config[\"dense_activation_1\"], use_bias=True))\n",
    "    \n",
    "    # Segunda capa Dropout\n",
    "    model.add(Dropout(config[\"dropout_2\"]))\n",
    "    \n",
    "    # Capa de salida Dense\n",
    "    model.add(Dense(1, activation=config[\"dense_activation_2\"], use_bias=True))\n",
    "    \n",
    "    # Configurar el optimizador con el learning rate especificado\n",
    "    optimizer = Adam(learning_rate=config[\"learning_rate\"])\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=MeanSquaredError(),\n",
    "                  metrics=[MeanSquaredError(name='mse'),\n",
    "                           RootMeanSquaredError(name='rmse'),\n",
    "                           MeanAbsolutePercentageError(name='mape')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16e6ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: totalMerged\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 0.0531 - mape: 88.6525 - mse: 0.0531 - rmse: 0.2294 - val_loss: 0.0469 - val_mape: 87.4840 - val_mse: 0.0469 - val_rmse: 0.2166\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - loss: 0.0477 - mape: 87.7562 - mse: 0.0477 - rmse: 0.2184 - val_loss: 0.0467 - val_mape: 87.8727 - val_mse: 0.0467 - val_rmse: 0.2161\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - loss: 0.0471 - mape: 86.7097 - mse: 0.0471 - rmse: 0.2170 - val_loss: 0.0472 - val_mape: 89.4058 - val_mse: 0.0472 - val_rmse: 0.2172\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0469 - mape: 86.7213 - mse: 0.0469 - rmse: 0.2166 - val_loss: 0.0469 - val_mape: 88.5503 - val_mse: 0.0469 - val_rmse: 0.2166\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0466 - mape: 86.1260 - mse: 0.0466 - rmse: 0.2159 - val_loss: 0.0465 - val_mape: 86.0774 - val_mse: 0.0465 - val_rmse: 0.2156\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0463 - mape: 85.4693 - mse: 0.0463 - rmse: 0.2152 - val_loss: 0.0468 - val_mape: 84.6582 - val_mse: 0.0468 - val_rmse: 0.2163\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0461 - mape: 85.0562 - mse: 0.0461 - rmse: 0.2146 - val_loss: 0.0463 - val_mape: 85.7231 - val_mse: 0.0462 - val_rmse: 0.2151\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - loss: 0.0460 - mape: 85.1056 - mse: 0.0460 - rmse: 0.2145 - val_loss: 0.0459 - val_mape: 83.5603 - val_mse: 0.0459 - val_rmse: 0.2143\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - loss: 0.0458 - mape: 84.5856 - mse: 0.0458 - rmse: 0.2139 - val_loss: 0.0469 - val_mape: 88.0220 - val_mse: 0.0469 - val_rmse: 0.2166\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0455 - mape: 84.3325 - mse: 0.0455 - rmse: 0.2134 - val_loss: 0.0459 - val_mape: 83.6176 - val_mse: 0.0459 - val_rmse: 0.2141\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - loss: 0.0454 - mape: 84.0674 - mse: 0.0454 - rmse: 0.2131 - val_loss: 0.0463 - val_mape: 85.7243 - val_mse: 0.0462 - val_rmse: 0.2151\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0455 - mape: 84.2783 - mse: 0.0455 - rmse: 0.2133 - val_loss: 0.0457 - val_mape: 84.2215 - val_mse: 0.0457 - val_rmse: 0.2137\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0450 - mape: 83.4278 - mse: 0.0450 - rmse: 0.2122 - val_loss: 0.0463 - val_mape: 81.4281 - val_mse: 0.0463 - val_rmse: 0.2152\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0456 - mape: 83.5820 - mse: 0.0456 - rmse: 0.2135 - val_loss: 0.0457 - val_mape: 82.3097 - val_mse: 0.0457 - val_rmse: 0.2138\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0453 - mape: 83.1176 - mse: 0.0453 - rmse: 0.2128 - val_loss: 0.0458 - val_mape: 82.7973 - val_mse: 0.0458 - val_rmse: 0.2141\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0452 - mape: 82.9185 - mse: 0.0452 - rmse: 0.2125 - val_loss: 0.0459 - val_mape: 82.6134 - val_mse: 0.0459 - val_rmse: 0.2142\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0450 - mape: 82.1549 - mse: 0.0450 - rmse: 0.2122 - val_loss: 0.0455 - val_mape: 82.7494 - val_mse: 0.0455 - val_rmse: 0.2133\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0450 - mape: 82.4585 - mse: 0.0450 - rmse: 0.2122 - val_loss: 0.0460 - val_mape: 85.0983 - val_mse: 0.0460 - val_rmse: 0.2145\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0449 - mape: 82.5230 - mse: 0.0449 - rmse: 0.2119 - val_loss: 0.0453 - val_mape: 81.8748 - val_mse: 0.0453 - val_rmse: 0.2129\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0448 - mape: 81.4209 - mse: 0.0448 - rmse: 0.2116 - val_loss: 0.0457 - val_mape: 84.2890 - val_mse: 0.0457 - val_rmse: 0.2139\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0446 - mape: 80.0700 - mse: 0.0446 - rmse: 0.2113 - val_loss: 0.0453 - val_mape: 84.6305 - val_mse: 0.0453 - val_rmse: 0.2129\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0443 - mape: 80.3675 - mse: 0.0443 - rmse: 0.2105 - val_loss: 0.0447 - val_mape: 80.5348 - val_mse: 0.0447 - val_rmse: 0.2115\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0442 - mape: 79.8937 - mse: 0.0442 - rmse: 0.2101 - val_loss: 0.0453 - val_mape: 79.4264 - val_mse: 0.0453 - val_rmse: 0.2128\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0444 - mape: 80.0593 - mse: 0.0444 - rmse: 0.2107 - val_loss: 0.0451 - val_mape: 77.0318 - val_mse: 0.0451 - val_rmse: 0.2125\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0441 - mape: 79.7463 - mse: 0.0441 - rmse: 0.2100 - val_loss: 0.0453 - val_mape: 78.6392 - val_mse: 0.0453 - val_rmse: 0.2129\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0441 - mape: 80.0303 - mse: 0.0441 - rmse: 0.2100 - val_loss: 0.0446 - val_mape: 77.7625 - val_mse: 0.0446 - val_rmse: 0.2112\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0439 - mape: 78.4649 - mse: 0.0439 - rmse: 0.2094 - val_loss: 0.0446 - val_mape: 80.9329 - val_mse: 0.0446 - val_rmse: 0.2112\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0438 - mape: 79.0748 - mse: 0.0438 - rmse: 0.2092 - val_loss: 0.0442 - val_mape: 79.5933 - val_mse: 0.0442 - val_rmse: 0.2103\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0436 - mape: 78.2564 - mse: 0.0436 - rmse: 0.2087 - val_loss: 0.0438 - val_mape: 78.0099 - val_mse: 0.0438 - val_rmse: 0.2094\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0433 - mape: 77.3443 - mse: 0.0433 - rmse: 0.2081 - val_loss: 0.0437 - val_mape: 77.1448 - val_mse: 0.0437 - val_rmse: 0.2092\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0434 - mape: 78.4631 - mse: 0.0434 - rmse: 0.2084 - val_loss: 0.0444 - val_mape: 77.3631 - val_mse: 0.0444 - val_rmse: 0.2107\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0435 - mape: 78.3798 - mse: 0.0435 - rmse: 0.2085 - val_loss: 0.0450 - val_mape: 75.1758 - val_mse: 0.0450 - val_rmse: 0.2121\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0434 - mape: 78.7695 - mse: 0.0434 - rmse: 0.2083 - val_loss: 0.0432 - val_mape: 76.4710 - val_mse: 0.0432 - val_rmse: 0.2078\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0427 - mape: 76.4830 - mse: 0.0427 - rmse: 0.2065 - val_loss: 0.0431 - val_mape: 75.5010 - val_mse: 0.0431 - val_rmse: 0.2076\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0423 - mape: 76.6829 - mse: 0.0423 - rmse: 0.2057 - val_loss: 0.0432 - val_mape: 72.3068 - val_mse: 0.0432 - val_rmse: 0.2079\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0415 - mape: 73.9821 - mse: 0.0415 - rmse: 0.2037 - val_loss: 0.0400 - val_mape: 68.9844 - val_mse: 0.0400 - val_rmse: 0.2000\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0377 - mape: 67.6093 - mse: 0.0377 - rmse: 0.1941 - val_loss: 0.0313 - val_mape: 50.1820 - val_mse: 0.0313 - val_rmse: 0.1768\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0298 - mape: 55.5947 - mse: 0.0298 - rmse: 0.1725 - val_loss: 0.0315 - val_mape: 47.6606 - val_mse: 0.0315 - val_rmse: 0.1774\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0265 - mape: 52.0370 - mse: 0.0265 - rmse: 0.1626 - val_loss: 0.0227 - val_mape: 44.6115 - val_mse: 0.0227 - val_rmse: 0.1507\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0226 - mape: 46.7548 - mse: 0.0226 - rmse: 0.1503 - val_loss: 0.0197 - val_mape: 39.7171 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0205 - mape: 43.4805 - mse: 0.0205 - rmse: 0.1433 - val_loss: 0.0178 - val_mape: 39.3968 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0198 - mape: 42.2240 - mse: 0.0198 - rmse: 0.1406 - val_loss: 0.0172 - val_mape: 38.1650 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0193 - mape: 41.1470 - mse: 0.0193 - rmse: 0.1390 - val_loss: 0.0172 - val_mape: 37.0367 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0192 - mape: 40.5024 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0173 - val_mape: 37.3695 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0192 - mape: 40.7604 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0170 - val_mape: 36.4840 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0191 - mape: 40.0460 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0171 - val_mape: 37.3166 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0190 - mape: 39.9477 - mse: 0.0190 - rmse: 0.1379 - val_loss: 0.0169 - val_mape: 35.5891 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0190 - mape: 40.0423 - mse: 0.0190 - rmse: 0.1378 - val_loss: 0.0170 - val_mape: 36.4104 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0189 - mape: 39.6660 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0168 - val_mape: 35.1871 - val_mse: 0.0168 - val_rmse: 0.1298\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0188 - mape: 39.0921 - mse: 0.0188 - rmse: 0.1371 - val_loss: 0.0170 - val_mape: 37.4463 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0189 - mape: 38.8606 - mse: 0.0189 - rmse: 0.1374 - val_loss: 0.0172 - val_mape: 36.9807 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0191 - mape: 39.2873 - mse: 0.0191 - rmse: 0.1381 - val_loss: 0.0201 - val_mape: 46.2373 - val_mse: 0.0201 - val_rmse: 0.1417\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0193 - mape: 39.7584 - mse: 0.0193 - rmse: 0.1389 - val_loss: 0.0193 - val_mape: 41.8368 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0190 - mape: 39.0508 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0180 - val_mape: 35.0257 - val_mse: 0.0180 - val_rmse: 0.1341\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.5261 - mse: 0.0188 - rmse: 0.1372 - val_loss: 0.0191 - val_mape: 38.7222 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.3207 - mse: 0.0187 - rmse: 0.1367 - val_loss: 0.0186 - val_mape: 39.5935 - val_mse: 0.0186 - val_rmse: 0.1364\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.5404 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0182 - val_mape: 39.9950 - val_mse: 0.0182 - val_rmse: 0.1350\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.1510 - mse: 0.0187 - rmse: 0.1368 - val_loss: 0.0184 - val_mape: 40.3818 - val_mse: 0.0184 - val_rmse: 0.1358\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.3810 - mse: 0.0187 - rmse: 0.1367 - val_loss: 0.0177 - val_mape: 40.4453 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0186 - mape: 37.8513 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0187 - val_mape: 46.3175 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0186 - mape: 37.7563 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0184 - val_mape: 45.2781 - val_mse: 0.0184 - val_rmse: 0.1358\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.3522 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0180 - val_mape: 39.1733 - val_mse: 0.0180 - val_rmse: 0.1342\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.8181 - mse: 0.0185 - rmse: 0.1362 - val_loss: 0.0178 - val_mape: 35.5716 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 64/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.7369 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0186 - val_mape: 39.2804 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 65/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0184 - mape: 37.2378 - mse: 0.0184 - rmse: 0.1358 - val_loss: 0.0184 - val_mape: 42.1939 - val_mse: 0.0184 - val_rmse: 0.1355\n",
      "Epoch 66/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.6869 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0175 - val_mape: 32.0000 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 67/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.5143 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0198 - val_mape: 40.5586 - val_mse: 0.0198 - val_rmse: 0.1408\n",
      "Epoch 68/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0184 - mape: 37.5035 - mse: 0.0184 - rmse: 0.1357 - val_loss: 0.0186 - val_mape: 40.3848 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 69/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.9375 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0180 - val_mape: 37.6429 - val_mse: 0.0180 - val_rmse: 0.1343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77c28356e980>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOWS_SIZE = 3\n",
    "\n",
    "# Obtenemos el nombre de archivo\n",
    "nombreArchivo = \"totalMerged_best_models.json\".split(\"_best_models.json\")[0]\n",
    "\n",
    "print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "# Cargamos archivos numpy\n",
    "data_train_global = np.load(f'RCPMergedTransferTotal/{nombreArchivo}_train_transfer.npz', allow_pickle=True)\n",
    "data_val_global = np.load(f'RCPMergedTransferTotal/{nombreArchivo}_val_transfer.npz', allow_pickle=True)\n",
    "\n",
    "X_train_transfer = data_train_global['X_train_transfer']\n",
    "y_train_transfer = data_train_global['y_train_transfer']\n",
    "X_val_transfer = data_val_global['X_val_transfer']\n",
    "y_val_transfer = data_val_global['y_val_transfer']\n",
    "valorNormalizacion = data_train_global[\"valorNormalizacion\"]\n",
    "\n",
    "with open(\"models/LSTMMerged_parallel/totalMerged_best_models.json\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "config = params[0]\n",
    "\n",
    "model = build_model_from_config((WINDOWS_SIZE + 1, X_train_transfer.shape[2]), config)\n",
    "\n",
    "\n",
    "model.fit(X_train_transfer, y_train_transfer, epochs=200, batch_size=config[\"batch_size\"],\n",
    "                validation_data=(X_val_transfer, y_val_transfer), callbacks=[EarlyStopping(monitor='val_loss', patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de506e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/LSTMMerged_parallel/totalMerged_best_models.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49082251",
   "metadata": {},
   "source": [
    "# Aplicamos transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acf7d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: Cedrus deodara\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6ms/step - loss: 0.0178 - mape: 34.7417 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0173 - val_mape: 35.0210 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0329 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0173 - val_mape: 34.7948 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0635 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0173 - val_mape: 34.5032 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2065 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0173 - val_mape: 34.9545 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0279 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0173 - val_mape: 34.6501 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0693 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.4771 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8343 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.3479 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9704 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.4262 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0829 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0172 - val_mape: 34.5419 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9577 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.0913 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0602 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.4165 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9561 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 34.3175 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8826 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.4039 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8740 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0172 - val_mape: 34.2964 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7509 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0172 - val_mape: 34.4072 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2258 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0172 - val_mape: 34.3581 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7761 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.0130 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0683 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.1179 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7787 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1093 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9613 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1636 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9290 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.3115 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9043 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.3398 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8715 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.3813 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8618 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.3905 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8036 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.2742 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8701 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1180 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9479 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2010 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9315 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.3324 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8137 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.2285 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7032 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.3324 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7982 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 33.9329 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9589 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1767 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0114 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.1413 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0282 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.4642 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.6656 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.2782 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7508 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.2985 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6711 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.3619 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6921 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.5097 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7722 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.1631 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8873 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.1772 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7899 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.4747 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9230 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.3749 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6612 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.3102 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9569 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.3453 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6523 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0171 - val_mape: 34.4876 - val_mse: 0.0171 - val_rmse: 0.1310\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6910 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.5278 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7989 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.2337 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0476 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2946 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8320 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.0855 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8745 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.3303 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0274 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.3334 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9489 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.4410 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8117 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.2393 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8548 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.4554 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6279 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.3440 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.4994 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.3699 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6192 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.4192 - val_mse: 0.0171 - val_rmse: 0.1310\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7707 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0171 - val_mape: 34.2976 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0006 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.5746 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7332 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0171 - val_mape: 34.3802 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6847 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0171 - val_mape: 34.2602 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6873 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0171 - val_mape: 34.3591 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6543 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.2849 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 64/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7509 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2315 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "[MODELO CONGELADO]: 1914.1665518283844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.29038457975723, 6.503105764152789, 0.8258321556230825, 23.71783833419315\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.040954021872675, 2.835657599547709, 0.9026187208086631, 22.723354062919192\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.262031662931753, 3.203440597690513, 0.9009328797738453, 22.805277957218088\n",
      "PROCESANDO ARCHIVO: Juniperus turkestanica Komar.\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0178 - mape: 34.5345 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 34.8423 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.0900 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 34.2389 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.2534 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 34.2711 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.2282 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 33.9814 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0722 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.0100 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0032 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.3067 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9610 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 33.9498 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9734 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.0701 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0487 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 33.8428 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0479 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 33.9238 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8847 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.2990 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1004 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.1627 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0028 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.0135 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9071 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.7905 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0141 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.9212 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8295 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.3479 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9785 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.5668 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7767 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.7498 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8281 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.6624 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.6841 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.0377 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9873 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.9055 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8170 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.9405 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8057 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 33.7568 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8131 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.0288 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8152 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 33.5728 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0739 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.9642 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.5416 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.2755 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9137 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.0303 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9717 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.0518 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9606 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.7629 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.6423 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.8828 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7882 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 33.9393 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1037 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 33.8417 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0557 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.8527 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8457 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.8020 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6962 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.2141 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8240 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.1632 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6530 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 33.8125 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8454 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.9622 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7275 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 33.9148 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0227 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.0480 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.6156 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.9585 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5803 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 33.8120 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7215 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 33.5948 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8024 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 33.9054 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6808 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.9214 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8373 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.0213 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7042 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 33.6503 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6322 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.1044 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6212 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.9388 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9113 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.8841 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6245 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 33.9622 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "[MODELO CONGELADO]: 1661.3576486110687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.2117488655462, 6.497056938764366, 0.8261560073206083, 23.71535936529131\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.432358498027181, 2.903852354722461, 0.9085059280370296, 22.940262828268267\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.026933086571674, 3.0044854944851496, 0.8966373979214293, 23.25278985292476\n",
      "PROCESANDO ARCHIVO: Abies pindrow\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0179 - mape: 34.4080 - mse: 0.0179 - rmse: 0.1336 - val_loss: 0.0179 - val_mape: 36.1091 - val_mse: 0.0179 - val_rmse: 0.1340\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0355 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0179 - val_mape: 35.7292 - val_mse: 0.0179 - val_rmse: 0.1339\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2113 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0179 - val_mape: 35.9530 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1877 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0179 - val_mape: 35.8951 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0454 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0179 - val_mape: 35.7995 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0667 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0179 - val_mape: 35.8659 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9871 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.9485 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9146 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.9687 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9472 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.8593 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9233 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.7767 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9657 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.8317 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8955 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0179 - val_mape: 35.9816 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9697 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0179 - val_mape: 36.0374 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7837 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.7321 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1290 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0178 - val_mape: 36.0383 - val_mse: 0.0178 - val_rmse: 0.1336\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.5998 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0178 - val_mape: 35.9138 - val_mse: 0.0178 - val_rmse: 0.1336\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7682 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.9168 - val_mse: 0.0178 - val_rmse: 0.1336\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7857 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.4086 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0076 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.9567 - val_mse: 0.0178 - val_rmse: 0.1336\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7958 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.7166 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9210 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.7381 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8940 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.6867 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8172 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.7092 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7741 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.6920 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8282 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.5179 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8450 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.4609 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7730 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.8474 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6926 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.6347 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6673 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.6504 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7263 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 36.1536 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6867 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.6325 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7828 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.8461 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5786 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.8021 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8948 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.5772 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8163 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6593 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6856 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.7421 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7356 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.4257 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6914 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.5956 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8394 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.5489 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8337 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.4052 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9539 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.4767 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8718 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6962 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6790 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.3905 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8248 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.6418 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7797 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.6402 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5265 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0178 - val_mape: 35.5309 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.4859 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.7121 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7784 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.7278 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9084 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.5315 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.3898 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.5872 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9050 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.6535 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7945 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6877 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8281 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.4640 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6133 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0178 - val_mape: 35.6916 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "[MODELO CONGELADO]: 1446.9696354866028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.25470591974389, 6.500361983747051, 0.8259790938778779, 23.737444841184104\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.57329693482617, 2.928019285255165, 0.9065683099668386, 23.415062238263296\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.603602651235807, 3.0989679977753575, 0.899753793746618, 23.399276759263827\n",
      "PROCESANDO ARCHIVO: Abies spectabilis\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6834 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0192 - val_mape: 39.2439 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1855 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0193 - val_mape: 38.8773 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2075 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0193 - val_mape: 39.0173 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.4521 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0193 - val_mape: 39.0020 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1329 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.8066 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0051 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0192 - val_mape: 39.1488 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7864 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.8851 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8980 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 39.0645 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9149 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 39.0268 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0153 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.8609 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0353 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0193 - val_mape: 39.0806 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7481 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0193 - val_mape: 39.1099 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7868 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0193 - val_mape: 38.8683 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7682 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0193 - val_mape: 38.9233 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6453 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0193 - val_mape: 38.9821 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7888 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0193 - val_mape: 39.0445 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "[MODELO CONGELADO]: 414.74484038352966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.407255078251524, 6.512085309503518, 0.8253508385814836, 23.79220211775388\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 12.609607018252351, 3.55100084740237, 0.9035027802839625, 22.8590950584842\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 12.559550916448043, 3.543945670640006, 0.8913341173054345, 23.21141250976686\n",
      "PROCESANDO ARCHIVO: Pinus roxburghii\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.3998 - mse: 0.0178 - rmse: 0.1336 - val_loss: 0.0177 - val_mape: 35.6435 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.6250 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0177 - val_mape: 35.5774 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2777 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.2284 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1432 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.2057 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1725 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.2373 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0060 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 34.9233 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8499 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.1581 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0108 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.1734 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9545 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.8785 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0892 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.0684 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7470 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.1984 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9977 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.1580 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8338 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.0259 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7258 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.9762 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8498 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.6986 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9261 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.3404 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7748 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8869 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8698 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.8487 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7787 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9379 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9224 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9930 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7373 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9633 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1167 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1938 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8983 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9618 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0536 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0144 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8478 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.1408 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8228 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.9243 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8969 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.9299 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7509 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.1299 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8279 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.2118 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0318 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8045 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8300 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1841 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7159 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.7267 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6457 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.8866 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8684 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8874 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.5189 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0663 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7227 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1332 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8051 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7827 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7890 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8050 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8448 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1956 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7341 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9422 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7488 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.8272 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7803 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.0014 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7076 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.1831 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8371 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.9744 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5656 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.0324 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9020 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0538 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0473 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0410 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6634 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1981 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0172 - mape: 32.5970 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0175 - val_mape: 35.0578 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8901 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1051 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6423 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2923 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5241 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.0686 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6156 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.4275 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5543 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.4669 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6458 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0324 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7505 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9948 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8493 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.8003 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "[MODELO CONGELADO]: 1528.893351316452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.21178177593609, 6.497059471479085, 0.8261558717831399, 23.68863422764013\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.766457194735322, 2.960820358403279, 0.9109249868591265, 22.70305692295184\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.435003749983087, 2.9043077918814126, 0.9045434280541165, 22.7167804363034\n",
      "PROCESANDO ARCHIVO: Tsuga dumosa\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6734 - mse: 0.0178 - rmse: 0.1336 - val_loss: 0.0176 - val_mape: 36.0028 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.4754 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0176 - val_mape: 35.5735 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2201 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.7116 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2526 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.5010 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8523 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.3316 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0930 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.6409 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0823 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.2673 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.3283 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.3544 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8171 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.3006 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8155 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.3219 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0368 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.8141 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8826 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0175 - val_mape: 35.4854 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0314 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 35.6454 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9311 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.0683 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0643 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 35.4365 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8821 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.3621 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8146 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9569 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0398 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3191 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9624 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.3248 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7537 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 35.3489 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8243 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.5802 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9742 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.1410 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9006 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1258 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0528 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.5667 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0106 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.4318 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7624 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3404 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8936 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.5233 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6345 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.1905 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9432 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.7037 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7364 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4028 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9479 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4057 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.6670 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4203 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7682 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4412 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9695 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2562 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8594 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.3838 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7798 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2898 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8228 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.2921 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9813 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.5649 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1502 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3730 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9877 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9826 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5712 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2711 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7347 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3629 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6317 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.5143 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6392 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.5248 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9171 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.6331 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6845 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.4326 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7227 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2516 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8216 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.0580 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8814 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2236 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7046 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.4219 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6927 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3079 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6404 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.7424 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7916 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3001 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8955 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.4297 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7795 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3802 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9223 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.3784 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7020 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.4180 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5566 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.7623 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5243 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.4875 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5926 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.4767 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "[MODELO CONGELADO]: 1749.848644733429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.231652472741985, 6.49858849849273, 0.8260740367167686, 23.744355630692187\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 9.019780467035526, 3.003294935073065, 0.9108247100898965, 22.760838821245695\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.003811958000817, 3.0006352590744543, 0.9052490535884409, 22.817287232896046\n",
      "PROCESANDO ARCHIVO: Betula utilis\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0178 - mape: 34.4772 - mse: 0.0178 - rmse: 0.1336 - val_loss: 0.0177 - val_mape: 35.1020 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.1793 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 34.7758 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.2110 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0177 - val_mape: 34.4260 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0253 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.8161 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1424 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.7330 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0099 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.4859 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1694 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.5036 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0207 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.4523 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9762 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.3723 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0854 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.5574 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8211 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.5777 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9872 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 34.1615 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8678 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.8291 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0692 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.2763 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9282 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7349 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9408 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.2597 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1551 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.2417 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7957 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.1825 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9547 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.3801 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8287 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6307 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9827 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6111 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8379 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.2987 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7678 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.2836 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7456 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.3462 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8332 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5297 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8187 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.4069 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9240 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.8736 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7066 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.6351 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8707 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4720 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9303 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7225 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8267 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.4511 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6761 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.3171 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8759 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.4867 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6881 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4198 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7941 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6602 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8038 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7038 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9730 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.4667 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8911 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.1776 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6968 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.2809 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7969 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.5032 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8639 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5659 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9449 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3451 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8507 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.3127 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6077 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5296 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8114 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.6169 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8923 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.5803 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7148 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.4309 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7575 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.4187 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7109 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5385 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6035 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.6546 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7813 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3659 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8626 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.3878 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6135 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8172 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8626 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.1935 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5673 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.6947 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5798 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.6483 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6821 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.5715 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7253 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.7414 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7239 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.8043 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7333 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.4599 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8686 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.7159 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8621 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.7609 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.4339 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.7125 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "[MODELO CONGELADO]: 2013.8842577934265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.287146133103356, 6.502856767075787, 0.825845492774741, 23.765665284892705\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.616235398901788, 2.9353424670558947, 0.9105394370284222, 22.75484423791732\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.878396716533857, 2.979663859654954, 0.9039372230303873, 22.83048566198789\n",
      "PROCESANDO ARCHIVO: Juniperus spp. \n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.3839 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.0174 - val_mape: 35.7876 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2149 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0174 - val_mape: 35.1296 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2311 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0174 - val_mape: 35.0348 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1193 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.0101 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9589 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 35.2493 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9149 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.8581 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0031 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 35.0205 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0850 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 35.0663 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8330 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 35.0192 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8175 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.9083 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8686 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.9737 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8390 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 35.0931 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8280 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 34.7753 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8780 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 34.7632 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7859 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 35.1358 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7844 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 35.0515 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0025 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 34.8165 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7492 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.8896 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8698 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 34.8397 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9869 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 34.9595 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9894 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.6841 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7838 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.6720 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8688 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.8677 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7030 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.9473 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6826 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.9403 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0395 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.6368 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9100 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.5936 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0157 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 35.0899 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8645 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.5703 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6552 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.5436 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8053 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.5836 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0776 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.8417 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7706 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.9299 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8985 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.9818 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6963 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.8049 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8936 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 35.0382 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9550 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.8893 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9352 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.7983 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7274 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 35.0652 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7220 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.6880 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8886 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 35.1214 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7263 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 35.0839 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7408 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.6150 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7522 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.6897 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7550 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.4991 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8394 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.7140 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6374 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 35.3423 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8478 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.9230 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5871 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.8866 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7770 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.6992 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6940 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0172 - val_mape: 35.0081 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7842 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.7176 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.4695 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.8490 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5933 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.9084 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8673 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 34.9526 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7215 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.9861 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7277 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.8901 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "[MODELO CONGELADO]: 1523.8605885505676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.20880136413375, 6.496830101221191, 0.8261681462494075, 23.719191112999834\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.912600203269958, 0.9553011060759629, 0.8948461572947877, 23.033884300169518\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.9916867126772272, 0.99583468139909, 0.9047832912617961, 22.60643104121175\n",
      "PROCESANDO ARCHIVO: Pinus gerardiana\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5056 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0175 - val_mape: 35.5503 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0267 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0175 - val_mape: 35.9884 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1153 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 35.0628 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1510 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.1675 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9612 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.1640 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9010 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 35.4517 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0471 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.4669 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0646 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.2378 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9718 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.2408 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0558 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.0311 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0411 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 34.8875 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7843 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.0974 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7237 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.0380 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0032 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.0827 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9968 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.0193 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9278 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.0986 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7846 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 34.8724 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0725 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.7643 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9917 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.8343 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0150 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.7872 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9463 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.9325 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9069 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.3033 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7161 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.8837 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8299 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1871 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7796 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.0121 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8032 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.8612 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7237 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.0578 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7775 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.9331 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8634 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.7706 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6836 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.4783 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9317 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.9668 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8691 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 35.3389 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7342 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.2102 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8380 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.7320 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6943 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.9257 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7738 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2024 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6088 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.9555 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6469 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.0042 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8586 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.7848 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8484 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.9267 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6293 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 35.3219 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8245 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.2241 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7635 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.7906 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6729 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1898 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8129 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 35.2621 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6639 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.8146 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8249 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.0052 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7040 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.8465 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9536 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.0016 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7241 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 34.9481 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7883 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.3247 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8305 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 35.0823 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9357 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.3711 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9083 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.0589 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8641 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.1232 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7339 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.0171 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7801 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 34.9233 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5867 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.3935 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5808 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.0779 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "[MODELO CONGELADO]: 1588.8064422607422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.199582710561565, 6.496120589287237, 0.8262061121614388, 23.700810835680866\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.425280375969365, 2.902633351970132, 0.9098254960232736, 22.7846697203626\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.573003529524813, 2.9279691817921876, 0.8934009181086209, 23.1331656794548\n",
      "PROCESANDO ARCHIVO: Picea smithiana\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.4132 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0175 - val_mape: 35.9988 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1876 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0175 - val_mape: 35.8406 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1110 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 35.5440 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0914 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.7254 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2524 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 35.6128 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1527 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0175 - val_mape: 35.4611 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2011 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 35.7107 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0738 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 35.6959 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9633 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.5802 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9584 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0175 - val_mape: 35.3905 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9788 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.4648 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8608 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.5025 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8614 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.4694 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2192 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.4318 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9860 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.4694 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8610 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.5637 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8386 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.5064 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0213 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.6777 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8817 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.5106 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0180 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.4356 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7834 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.3114 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9701 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.5742 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0107 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.2748 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8385 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.5344 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6999 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.2691 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7712 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.8041 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0136 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.4365 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7446 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.4829 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7386 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.1176 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7256 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4599 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6230 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2756 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7794 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.3505 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7102 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2702 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7383 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3526 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7459 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2900 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6694 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4167 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5561 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.3096 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7818 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.5149 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7169 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3902 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7981 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5606 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7046 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 35.5979 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6048 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.6386 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7639 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5188 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7914 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.3582 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6250 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5324 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7327 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.4041 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6827 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.6381 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5569 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3607 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6239 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.3464 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7579 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.4169 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5571 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.6961 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6778 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 35.3002 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6996 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.2675 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7316 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.7718 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7785 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4114 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6782 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.4389 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7674 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 35.6306 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "[MODELO CONGELADO]: 1529.8415367603302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.31471857920547, 6.504976447244484, 0.8257319389835063, 23.77178624058607\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.86916054821204, 2.9781135888699812, 0.9050451778547682, 23.091756346533682\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.313693519476844, 3.211493970020315, 0.9000310030107009, 23.016324201582258\n",
      "PROCESANDO ARCHIVO: Juniperus spp. L.\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.4653 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0175 - val_mape: 32.3677 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0642 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 32.3472 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9822 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 31.9471 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9404 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0175 - val_mape: 31.9703 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2805 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 32.0382 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9516 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 32.4483 - val_mse: 0.0175 - val_rmse: 0.1320\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2545 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 32.1293 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8894 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 32.4720 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0301 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 32.2153 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2565 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 32.0670 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9162 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 32.0624 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8343 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 31.9694 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9719 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 31.7217 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8059 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 31.9067 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8793 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.8449 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9243 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.9681 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8261 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 32.0966 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9843 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.8307 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0452 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.8659 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9099 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 31.9148 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8357 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.9051 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8070 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 32.0254 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8800 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.0664 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0111 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 32.0810 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9936 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.7832 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7959 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 32.0204 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9226 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.7950 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8200 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.9109 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6875 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.0250 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0269 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.6299 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9585 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.8970 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7317 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.1312 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7708 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 32.0004 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0144 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.7803 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6855 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 32.3699 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6518 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.9685 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8460 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.7604 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6843 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.2621 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8040 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.9294 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7734 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.8422 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8167 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 31.9373 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5963 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.0292 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8932 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 32.2007 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5864 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.1478 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8969 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.9101 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5637 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 32.0569 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6554 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 32.0876 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7844 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.8408 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "[MODELO CONGELADO]: 1290.1301155090332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.21415875058635, 6.497242395861982, 0.8261460824999474, 23.689012573752336\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.353157241855339, 2.8901829080276804, 0.9129256906410042, 22.43513901689047\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.723648157439804, 2.953582258451558, 0.9030442714042396, 22.760924482204157\n",
      "PROCESANDO ARCHIVO: Populus ciliata\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5152 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 35.3149 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.3107 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0176 - val_mape: 35.2651 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0537 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0176 - val_mape: 35.2978 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1268 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.1268 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1636 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0176 - val_mape: 35.2963 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9615 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.0866 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0042 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.9378 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8614 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.0767 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8636 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.6261 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1338 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.9178 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9997 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.0924 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8842 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.6644 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0481 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.0249 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8898 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9900 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0442 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.0896 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9705 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0342 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2268 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6832 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9021 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0765 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0049 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.6299 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8386 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 35.0812 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7674 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.8937 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0074 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 34.7778 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8299 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.6373 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8637 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 34.8433 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8075 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0089 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8167 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.8564 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0346 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6586 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8522 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1429 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0086 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.5341 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0602 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.8321 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8357 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.7154 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8650 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9461 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8918 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.8209 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7556 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9025 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.1359 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0196 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8248 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1415 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7552 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.8942 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6931 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9574 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6082 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.9491 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6958 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1126 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0412 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.7285 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5683 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9413 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6962 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.9420 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6936 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9073 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7629 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.2213 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7472 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0840 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7165 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9033 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5928 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 34.9514 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7647 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9382 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7023 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9628 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5985 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9179 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6954 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9504 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5912 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3039 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8287 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0023 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6416 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9695 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7308 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9908 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6801 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.7202 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9195 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.7953 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6865 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.0974 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6057 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.1083 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6362 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.0907 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6032 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1306 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0172 - mape: 32.6005 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0175 - val_mape: 34.9806 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "[MODELO CONGELADO]: 1694.9832282066345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.22093813344111, 6.497764087241173, 0.826118162429942, 23.725076230208998\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.615155656042838, 2.93515854018873, 0.9105000564268857, 22.720954498706732\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.38471496653287, 3.0634482150891453, 0.9005915833477338, 23.008192906474463\n",
      "PROCESANDO ARCHIVO: Juniperus recurva\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5366 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 35.8729 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0827 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 35.4363 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0730 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0177 - val_mape: 35.3757 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1205 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 35.5004 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9917 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0177 - val_mape: 35.0394 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8636 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 35.1591 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9225 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.7650 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8547 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.4839 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0229 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.5292 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8818 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.5955 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9178 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.1857 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9267 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.2405 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0218 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.3480 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9956 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.3431 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8603 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0151 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9270 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.6589 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9076 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.9607 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8375 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.1107 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9620 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.3933 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8441 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.2015 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8447 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0800 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8584 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0788 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0715 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.2110 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9458 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.2730 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9091 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.8811 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8508 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.3695 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7471 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1558 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8091 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.4820 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8158 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.9508 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8729 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.3331 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9656 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.4834 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6822 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.3907 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7117 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4205 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.1246 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1747 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7443 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.0643 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7720 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.3296 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7946 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.3119 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7626 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0298 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9893 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.2484 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8153 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.5233 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8410 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3548 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8381 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.2910 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7139 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.0354 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "[MODELO CONGELADO]: 1169.8091797828674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.228861490265714, 6.49837375735389, 0.8260855310412212, 23.672795384807948\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.208147895080835, 2.8649865436125235, 0.9111754975782809, 22.824238922693016\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.22242401653159, 3.0368444175709084, 0.8976109243118846, 23.328095003573665\n",
      "PROCESANDO ARCHIVO: Pinus wallichiana\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.4033 - mse: 0.0178 - rmse: 0.1336 - val_loss: 0.0178 - val_mape: 36.2509 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2520 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0178 - val_mape: 35.7974 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2121 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0178 - val_mape: 36.1054 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0282 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0178 - val_mape: 36.0121 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9729 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 35.9574 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7789 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0178 - val_mape: 35.7896 - val_mse: 0.0178 - val_rmse: 0.1332\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8713 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 35.9123 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0682 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0178 - val_mape: 35.6859 - val_mse: 0.0178 - val_rmse: 0.1332\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8719 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.9536 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0639 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.5662 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9199 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.9950 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7186 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 35.8540 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7484 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.5269 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9780 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.9646 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0452 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.8458 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1679 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 36.0991 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0213 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.6718 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8709 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.7589 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9823 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.6795 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1213 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.6849 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7214 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.6937 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8613 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.6169 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0868 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.6537 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8821 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.4226 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7350 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.5893 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8736 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.7177 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7079 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.8340 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8764 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.5728 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8109 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.4983 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7194 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.8750 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7749 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.8050 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7018 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.7393 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7709 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 36.1845 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7532 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.5008 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7088 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0177 - val_mape: 35.6976 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.5464 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.7737 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9036 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.5821 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7185 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.5909 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5825 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.9991 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7550 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.7631 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7981 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.9110 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6779 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.5703 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5457 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 36.0255 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6060 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.6264 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7411 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 35.9141 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8255 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.6954 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7790 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.7407 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8165 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.5651 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9185 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 36.0764 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6609 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 36.2215 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7176 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 36.2282 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7475 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.9585 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7509 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.8143 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6120 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.8008 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7441 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 36.0232 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6634 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.8592 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6838 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 36.1387 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6026 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.9299 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7916 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.6933 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "[MODELO CONGELADO]: 1589.888599395752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.21207151709201, 6.497081769309358, 0.8261546785191614, 23.700971363140326\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 7.514214489441639, 2.741206757879026, 0.9144885895406473, 22.860126674678323\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.26680526037082, 3.0441427792353664, 0.9021930632731283, 23.122081214434264\n",
      "PROCESANDO ARCHIVO: Juniperus excelsa M.-Bieb\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6144 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0178 - val_mape: 35.0750 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.3929 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0177 - val_mape: 34.9021 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2343 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.7310 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0796 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0177 - val_mape: 34.7544 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8256 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 35.0378 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2063 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 35.0134 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1071 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.8742 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9605 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.7395 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2149 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.5229 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0339 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.7419 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9437 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.7993 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2105 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.6822 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7401 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.6461 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0518 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.5571 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1439 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 34.2884 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9502 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.4508 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7738 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.6180 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8475 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.3067 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8633 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 34.3446 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7856 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 34.5580 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9745 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.6201 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9894 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 34.3177 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9242 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 34.4518 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0674 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.5945 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0250 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.4658 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7785 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6550 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8313 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6844 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6773 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.3224 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0627 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6883 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8475 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4704 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8515 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.5755 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5958 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5398 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8829 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.9060 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8654 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.6108 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8138 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.7574 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6401 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.4971 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7380 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5978 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6934 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.8267 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6135 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.4776 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5025 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3778 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7978 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.7996 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7506 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.6759 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7244 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.5990 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "[MODELO CONGELADO]: 1155.86217212677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.30558686242901, 6.504274507001454, 0.8257695468568378, 23.744794812404173\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.42288402428232, 2.902220533364465, 0.9121747546304922, 22.591071044917133\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.496852948322482, 3.0816964400022404, 0.9011325024335032, 22.985481461653713\n"
     ]
    }
   ],
   "source": [
    "# Creamos un df que contiene los resultados de los modelos freeze de cada especie\n",
    "df_Freeze = pd.DataFrame(columns = [\"File\", \"Time\", \"TrainMSE\", \"TrainRMSE\", \"TrainR2\", \"TrainMAPE\", \n",
    "                                    \"ValidationMSE\", \"ValidationRMSE\", \"ValidationR2\", \"ValidationMAPE\",\n",
    "                                    \"TestMSE\", \"TestRMSE\", \"TestR2\", \"TestMAPE\"])\n",
    "\n",
    "for archivo in os.listdir(\"RCPMergedTransfer\"):\n",
    "    if \"train\" in archivo: \n",
    "        \n",
    "        nombreArchivo = archivo.split(\"_train\")[0]\n",
    "        print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "        # Cargar datos\n",
    "        data_transfer_train = np.load(f'RCPMergedTransferTotal/totalMerged_train_transfer.npz', allow_pickle=True)\n",
    "        data_transfer_val = np.load(f'RCPMergedTransfer/{nombreArchivo}_val.npz', allow_pickle=True)\n",
    "        data_transfer_test = np.load(f'RCPMergedTransfer/{nombreArchivo}_test.npz', allow_pickle=True)\n",
    "        \n",
    "        # Aqui tenemos que usar TRAIN original para aplicar transfer \n",
    "        X_train_transfer = data_transfer_train[\"X_train_transfer\"]\n",
    "        y_train_transfer = data_transfer_train[\"y_train_transfer\"]\n",
    "\n",
    "        # Aqui tenemos que usar VAL original para aplicar transfer \n",
    "        X_val_transfer = data_transfer_val[\"X_val\"]\n",
    "        y_val_transfer = data_transfer_val[\"y_val\"]\n",
    "        \n",
    "        # Este test es para ver la capacidad del modelo\n",
    "        X_test_transfer = data_transfer_test[\"X_test\"]\n",
    "        y_test_transfer = data_transfer_test[\"y_test\"]\n",
    "\n",
    "        # Valor normalizacion\n",
    "        valorNormalizacion_train = data_transfer_train[\"valorNormalizacion\"].item()\n",
    "        valorNormalizacion = data_transfer_test[\"valorNormalizacion\"].item()\n",
    "\n",
    "        # Cargamos el conjunto de datos de val original para hacer el transfer\n",
    "        model = tf.keras.models.load_model('models/LSTMMerged_parallel/totalMerged_best_models.keras')\n",
    "        modelFreeze = model\n",
    "        \n",
    "        # Cargamos el json para obtener el batch_size\n",
    "        with open(\"models/LSTMMerged_parallel/totalMerged_best_models.json\") as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        config = params[0]\n",
    "\n",
    "        # Obtener el optimizador del modelo\n",
    "        optimizer = modelFreeze.optimizer\n",
    "\n",
    "        # Obtenemos el batch\n",
    "        batch_size_LSTM = config[\"batch_size\"]\n",
    "\n",
    "        # Indicamos el numero de layers a entrenar\n",
    "        NUM_TRAINABLE = 1\n",
    "\n",
    "        numLSTM_layers = sum(1 for layer in modelFreeze.layers if \"lstm\" in layer.name)\n",
    "\n",
    "        numFreezeLayers = numLSTM_layers - NUM_TRAINABLE # Congelamos todas menos la útlima capa\n",
    "\n",
    "        numberLayersFreezed = 0\n",
    "\n",
    "        # Congelar las primeras 'numFreezeLayers' capas LSTM\n",
    "        for i, layer in enumerate(modelFreeze.layers):\n",
    "\n",
    "            if \"lstm\" in layer.name and numFreezeLayers>numberLayersFreezed:\n",
    "                numberLayersFreezed += 1\n",
    "                layer.trainable = False\n",
    "\n",
    "            print(layer, layer.trainable)\n",
    "\n",
    "        # Compilamos el modelo con los nuevos datos\n",
    "        modelFreeze.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[\n",
    "                                    MeanSquaredError(name='mse'),\n",
    "                                    RootMeanSquaredError(name='rmse'),\n",
    "                                    MeanAbsolutePercentageError(name='mape')\n",
    "                                ])\n",
    "\n",
    "        # Comienza a medir el tiempo de entrenamiento\n",
    "        start_time = time.time()\n",
    "\n",
    "        historyLSTMTransfer = modelFreeze.fit(X_train_transfer, y_train_transfer, epochs=200, batch_size=batch_size_LSTM,\n",
    "                                validation_data=(X_val_transfer, y_val_transfer), callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "        \n",
    "        # Finaliza la medición del tiempo de entrenamiento\n",
    "        end_time = time.time()\n",
    "        print(f\"[MODELO CONGELADO]: {end_time-start_time}\")\n",
    "\n",
    "        # Guardamos el modelo\n",
    "        modelFreeze.save(f\"models/LSTMMerged_parallel/{nombreArchivo}.keras\")\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de entrenamiento\n",
    "        predictions_train = predictionForIndividuals(X_train_transfer, y_train_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion_train, \"Predictions\"), axis=1)\n",
    "        predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion_train, \"Actuals\"), axis=1)\n",
    "\n",
    "        train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"],predictions_train[\"PredictionsDenormalize\"])\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        train_mape = (np.sum(np.abs(predictions_train[\"PredictionsDenormalize\"] - predictions_train[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_train[\"ActualDenormalize\"]))) * 100\n",
    "        train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de validación\n",
    "        predictions_val = predictionForIndividuals(X_val_transfer, y_val_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"],predictions_val[\"PredictionsDenormalize\"])\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_mape = (np.sum(np.abs(predictions_val[\"PredictionsDenormalize\"] - predictions_val[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_val[\"ActualDenormalize\"]))) * 100\n",
    "        val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de prueba\n",
    "        predictions_test = predictionForIndividuals(X_test_transfer, y_test_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"],predictions_test[\"PredictionsDenormalize\"])\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mape = (np.sum(np.abs(predictions_test[\"PredictionsDenormalize\"] - predictions_test[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_test[\"ActualDenormalize\"]))) * 100\n",
    "        test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "        # Guardamos los datos calculados\n",
    "        df_Freeze.loc[len(df_Freeze)] = [nombreArchivo, end_time-start_time,train_mse, train_rmse, train_r2, train_mape, val_mse, val_rmse, val_r2, val_mape, test_mse, test_rmse, test_r2, test_mape]\n",
    "\n",
    "df_Freeze.to_csv(\"resultsTransferOption3/resultados_Option3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
