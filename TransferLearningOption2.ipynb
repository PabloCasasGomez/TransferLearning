{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicamos transfer learning con un modelo que tienen todos los datos menos el de la especie a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 12:29:40.324547: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-29 12:29:40.327305: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-29 12:29:40.336656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 12:29:40.351613: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 12:29:40.356180: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 12:29:40.367870: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 12:29:41.086885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import os\n",
    "import json\n",
    "\n",
    "import random as python_random\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras import layers, models\n",
    "\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "from funcionesComunes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: Pinus wallichiana\n",
      "(9365, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus wallichiana_best_models.json\n",
      "(5508, 4, 43) (1957, 4, 43) (1500, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m27,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m61,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m115,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m115,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m3,612\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m29\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,229,741</span> (4.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,229,741\u001b[0m (4.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,913</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m409,913\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">819,828</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m819,828\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0180 - mape: 27.5418 - mse: 0.0180 - rmse: 0.1339 - val_loss: 0.0165 - val_mape: 22.6667 - val_mse: 0.0166 - val_rmse: 0.1285\n",
      "Epoch 2/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0169 - mape: 26.5446 - mse: 0.0169 - rmse: 0.1298 - val_loss: 0.0156 - val_mape: 22.5895 - val_mse: 0.0156 - val_rmse: 0.1249\n",
      "Epoch 3/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0164 - mape: 25.9717 - mse: 0.0164 - rmse: 0.1281 - val_loss: 0.0160 - val_mape: 22.5096 - val_mse: 0.0161 - val_rmse: 0.1266\n",
      "Epoch 4/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0162 - mape: 26.0195 - mse: 0.0162 - rmse: 0.1271 - val_loss: 0.0179 - val_mape: 22.7924 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 5/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0159 - mape: 25.6939 - mse: 0.0159 - rmse: 0.1261 - val_loss: 0.0141 - val_mape: 22.2957 - val_mse: 0.0142 - val_rmse: 0.1189\n",
      "Epoch 6/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0157 - mape: 25.4029 - mse: 0.0157 - rmse: 0.1250 - val_loss: 0.0152 - val_mape: 22.2952 - val_mse: 0.0153 - val_rmse: 0.1233\n",
      "Epoch 7/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0154 - mape: 25.0513 - mse: 0.0154 - rmse: 0.1240 - val_loss: 0.0140 - val_mape: 22.9655 - val_mse: 0.0141 - val_rmse: 0.1184\n",
      "Epoch 8/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0160 - mape: 25.4322 - mse: 0.0160 - rmse: 0.1262 - val_loss: 0.0147 - val_mape: 22.0722 - val_mse: 0.0148 - val_rmse: 0.1212\n",
      "Epoch 9/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0157 - mape: 25.2949 - mse: 0.0157 - rmse: 0.1252 - val_loss: 0.0152 - val_mape: 22.0271 - val_mse: 0.0153 - val_rmse: 0.1235\n",
      "Epoch 10/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0158 - mape: 24.8902 - mse: 0.0158 - rmse: 0.1257 - val_loss: 0.0154 - val_mape: 22.0991 - val_mse: 0.0155 - val_rmse: 0.1242\n",
      "Epoch 11/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0156 - mape: 24.9544 - mse: 0.0156 - rmse: 0.1247 - val_loss: 0.0158 - val_mape: 22.1525 - val_mse: 0.0158 - val_rmse: 0.1255\n",
      "Epoch 12/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0152 - mape: 25.1758 - mse: 0.0152 - rmse: 0.1232 - val_loss: 0.0143 - val_mape: 22.5175 - val_mse: 0.0143 - val_rmse: 0.1194\n",
      "Epoch 13/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0151 - mape: 24.8485 - mse: 0.0151 - rmse: 0.1229 - val_loss: 0.0146 - val_mape: 21.8995 - val_mse: 0.0147 - val_rmse: 0.1208\n",
      "Epoch 14/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0155 - mape: 24.6204 - mse: 0.0155 - rmse: 0.1245 - val_loss: 0.0148 - val_mape: 21.8945 - val_mse: 0.0148 - val_rmse: 0.1215\n",
      "Epoch 15/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0154 - mape: 24.7141 - mse: 0.0154 - rmse: 0.1239 - val_loss: 0.0149 - val_mape: 21.9897 - val_mse: 0.0150 - val_rmse: 0.1221\n",
      "Epoch 16/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0147 - mape: 24.2334 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0141 - val_mape: 21.9931 - val_mse: 0.0142 - val_rmse: 0.1189\n",
      "Epoch 17/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0152 - mape: 24.5756 - mse: 0.0152 - rmse: 0.1234 - val_loss: 0.0143 - val_mape: 21.8648 - val_mse: 0.0144 - val_rmse: 0.1196\n",
      "Epoch 18/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0147 - mape: 24.0218 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0144 - val_mape: 21.7225 - val_mse: 0.0145 - val_rmse: 0.1199\n",
      "Epoch 19/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0150 - mape: 24.3939 - mse: 0.0150 - rmse: 0.1225 - val_loss: 0.0136 - val_mape: 22.2507 - val_mse: 0.0137 - val_rmse: 0.1168\n",
      "Epoch 20/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0149 - mape: 23.7970 - mse: 0.0149 - rmse: 0.1218 - val_loss: 0.0141 - val_mape: 21.5041 - val_mse: 0.0142 - val_rmse: 0.1189\n",
      "Epoch 21/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0150 - mape: 24.2921 - mse: 0.0150 - rmse: 0.1224 - val_loss: 0.0138 - val_mape: 21.3450 - val_mse: 0.0139 - val_rmse: 0.1176\n",
      "Epoch 22/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0147 - mape: 23.8822 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0147 - val_mape: 21.3355 - val_mse: 0.0148 - val_rmse: 0.1212\n",
      "Epoch 23/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0146 - mape: 23.8156 - mse: 0.0146 - rmse: 0.1209 - val_loss: 0.0138 - val_mape: 21.5832 - val_mse: 0.0138 - val_rmse: 0.1173\n",
      "Epoch 24/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0149 - mape: 24.2918 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0139 - val_mape: 21.1894 - val_mse: 0.0139 - val_rmse: 0.1177\n",
      "Epoch 25/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0147 - mape: 23.5331 - mse: 0.0147 - rmse: 0.1210 - val_loss: 0.0146 - val_mape: 21.0380 - val_mse: 0.0147 - val_rmse: 0.1209\n",
      "Epoch 26/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0149 - mape: 23.9117 - mse: 0.0149 - rmse: 0.1219 - val_loss: 0.0134 - val_mape: 21.4338 - val_mse: 0.0135 - val_rmse: 0.1159\n",
      "Epoch 27/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0146 - mape: 23.7014 - mse: 0.0146 - rmse: 0.1208 - val_loss: 0.0134 - val_mape: 20.9514 - val_mse: 0.0135 - val_rmse: 0.1158\n",
      "Epoch 28/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0145 - mape: 23.7601 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0133 - val_mape: 21.3430 - val_mse: 0.0134 - val_rmse: 0.1154\n",
      "Epoch 29/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0143 - mape: 23.6978 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0134 - val_mape: 21.1605 - val_mse: 0.0134 - val_rmse: 0.1157\n",
      "Epoch 30/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0147 - mape: 23.7502 - mse: 0.0147 - rmse: 0.1211 - val_loss: 0.0141 - val_mape: 20.8129 - val_mse: 0.0142 - val_rmse: 0.1189\n",
      "Epoch 31/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0147 - mape: 23.6101 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0141 - val_mape: 20.9356 - val_mse: 0.0142 - val_rmse: 0.1187\n",
      "Epoch 32/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0146 - mape: 23.4009 - mse: 0.0146 - rmse: 0.1209 - val_loss: 0.0142 - val_mape: 21.8283 - val_mse: 0.0142 - val_rmse: 0.1190\n",
      "Epoch 33/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0148 - mape: 24.3548 - mse: 0.0148 - rmse: 0.1215 - val_loss: 0.0141 - val_mape: 21.0082 - val_mse: 0.0142 - val_rmse: 0.1189\n",
      "Epoch 34/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0141 - mape: 23.0559 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0139 - val_mape: 20.7303 - val_mse: 0.0140 - val_rmse: 0.1180\n",
      "Epoch 35/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0142 - mape: 23.2289 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0134 - val_mape: 20.8053 - val_mse: 0.0134 - val_rmse: 0.1156\n",
      "Epoch 36/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0145 - mape: 23.2177 - mse: 0.0145 - rmse: 0.1206 - val_loss: 0.0133 - val_mape: 22.3033 - val_mse: 0.0134 - val_rmse: 0.1154\n",
      "Epoch 37/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0147 - mape: 23.7386 - mse: 0.0147 - rmse: 0.1210 - val_loss: 0.0132 - val_mape: 22.3246 - val_mse: 0.0133 - val_rmse: 0.1151\n",
      "Epoch 38/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0142 - mape: 23.2038 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0133 - val_mape: 21.3016 - val_mse: 0.0133 - val_rmse: 0.1151\n",
      "Epoch 39/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0144 - mape: 23.1494 - mse: 0.0144 - rmse: 0.1198 - val_loss: 0.0138 - val_mape: 20.9058 - val_mse: 0.0139 - val_rmse: 0.1175\n",
      "Epoch 40/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0138 - mape: 22.9653 - mse: 0.0138 - rmse: 0.1176 - val_loss: 0.0129 - val_mape: 21.3581 - val_mse: 0.0129 - val_rmse: 0.1135\n",
      "Epoch 41/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0141 - mape: 23.0553 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0135 - val_mape: 20.3825 - val_mse: 0.0136 - val_rmse: 0.1163\n",
      "Epoch 42/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0136 - mape: 22.8189 - mse: 0.0136 - rmse: 0.1166 - val_loss: 0.0128 - val_mape: 20.4422 - val_mse: 0.0129 - val_rmse: 0.1131\n",
      "Epoch 43/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0135 - mape: 22.5870 - mse: 0.0135 - rmse: 0.1159 - val_loss: 0.0129 - val_mape: 20.9892 - val_mse: 0.0129 - val_rmse: 0.1134\n",
      "Epoch 44/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0138 - mape: 22.4469 - mse: 0.0138 - rmse: 0.1174 - val_loss: 0.0128 - val_mape: 21.4871 - val_mse: 0.0129 - val_rmse: 0.1131\n",
      "Epoch 45/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0141 - mape: 23.1412 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0136 - val_mape: 20.9638 - val_mse: 0.0136 - val_rmse: 0.1165\n",
      "Epoch 46/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0143 - mape: 23.2917 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0155 - val_mape: 21.4464 - val_mse: 0.0156 - val_rmse: 0.1246\n",
      "Epoch 47/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0140 - mape: 23.0249 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0121 - val_mape: 20.5485 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 48/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0134 - mape: 22.2918 - mse: 0.0134 - rmse: 0.1156 - val_loss: 0.0125 - val_mape: 20.5202 - val_mse: 0.0126 - val_rmse: 0.1119\n",
      "Epoch 49/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0138 - mape: 22.8245 - mse: 0.0138 - rmse: 0.1173 - val_loss: 0.0141 - val_mape: 20.8264 - val_mse: 0.0142 - val_rmse: 0.1188\n",
      "Epoch 50/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0138 - mape: 23.0997 - mse: 0.0138 - rmse: 0.1176 - val_loss: 0.0125 - val_mape: 20.4794 - val_mse: 0.0126 - val_rmse: 0.1117\n",
      "Epoch 51/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0144 - mape: 23.7476 - mse: 0.0144 - rmse: 0.1199 - val_loss: 0.0131 - val_mape: 20.1632 - val_mse: 0.0132 - val_rmse: 0.1145\n",
      "Epoch 52/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0134 - mape: 22.4785 - mse: 0.0134 - rmse: 0.1159 - val_loss: 0.0128 - val_mape: 21.4364 - val_mse: 0.0128 - val_rmse: 0.1129\n",
      "Epoch 53/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0145 - mape: 23.8093 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0128 - val_mape: 21.0945 - val_mse: 0.0130 - val_rmse: 0.1133\n",
      "Epoch 54/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0133 - mape: 22.7311 - mse: 0.0133 - rmse: 0.1154 - val_loss: 0.0135 - val_mape: 20.4831 - val_mse: 0.0135 - val_rmse: 0.1161\n",
      "Epoch 55/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0129 - mape: 22.3979 - mse: 0.0129 - rmse: 0.1133 - val_loss: 0.0140 - val_mape: 20.6222 - val_mse: 0.0140 - val_rmse: 0.1183\n",
      "Epoch 56/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0138 - mape: 23.3818 - mse: 0.0138 - rmse: 0.1173 - val_loss: 0.0121 - val_mape: 20.5106 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 57/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0134 - mape: 22.6247 - mse: 0.0134 - rmse: 0.1158 - val_loss: 0.0128 - val_mape: 20.1760 - val_mse: 0.0129 - val_rmse: 0.1131\n",
      "Epoch 58/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0134 - mape: 22.5086 - mse: 0.0134 - rmse: 0.1156 - val_loss: 0.0130 - val_mape: 19.8987 - val_mse: 0.0131 - val_rmse: 0.1141\n",
      "Epoch 59/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0136 - mape: 22.9068 - mse: 0.0136 - rmse: 0.1166 - val_loss: 0.0123 - val_mape: 19.8897 - val_mse: 0.0123 - val_rmse: 0.1108\n",
      "Epoch 60/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0140 - mape: 23.5817 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0120 - val_mape: 20.0316 - val_mse: 0.0120 - val_rmse: 0.1094\n",
      "Epoch 61/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0130 - mape: 22.2671 - mse: 0.0130 - rmse: 0.1139 - val_loss: 0.0122 - val_mape: 20.9077 - val_mse: 0.0123 - val_rmse: 0.1104\n",
      "Epoch 62/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0138 - mape: 23.1746 - mse: 0.0138 - rmse: 0.1176 - val_loss: 0.0119 - val_mape: 20.2012 - val_mse: 0.0120 - val_rmse: 0.1092\n",
      "Epoch 63/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0142 - mape: 23.3126 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0120 - val_mape: 21.4138 - val_mse: 0.0121 - val_rmse: 0.1096\n",
      "Epoch 64/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0131 - mape: 22.2404 - mse: 0.0131 - rmse: 0.1142 - val_loss: 0.0117 - val_mape: 20.0429 - val_mse: 0.0118 - val_rmse: 0.1084\n",
      "Epoch 65/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0128 - mape: 22.0895 - mse: 0.0128 - rmse: 0.1131 - val_loss: 0.0124 - val_mape: 20.0246 - val_mse: 0.0124 - val_rmse: 0.1112\n",
      "Epoch 66/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0127 - mape: 22.1123 - mse: 0.0127 - rmse: 0.1126 - val_loss: 0.0122 - val_mape: 19.8865 - val_mse: 0.0123 - val_rmse: 0.1106\n",
      "Epoch 67/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0127 - mape: 22.0955 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0118 - val_mape: 19.8395 - val_mse: 0.0119 - val_rmse: 0.1087\n",
      "Epoch 68/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0129 - mape: 22.5372 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0115 - val_mape: 20.1648 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 69/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0129 - mape: 22.2986 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0117 - val_mape: 20.0199 - val_mse: 0.0118 - val_rmse: 0.1081\n",
      "Epoch 70/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0132 - mape: 22.5706 - mse: 0.0132 - rmse: 0.1148 - val_loss: 0.0115 - val_mape: 20.0114 - val_mse: 0.0116 - val_rmse: 0.1074\n",
      "Epoch 71/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0128 - mape: 21.9595 - mse: 0.0128 - rmse: 0.1130 - val_loss: 0.0116 - val_mape: 20.0214 - val_mse: 0.0117 - val_rmse: 0.1079\n",
      "Epoch 72/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0127 - mape: 21.8696 - mse: 0.0127 - rmse: 0.1128 - val_loss: 0.0123 - val_mape: 19.6854 - val_mse: 0.0124 - val_rmse: 0.1111\n",
      "Epoch 73/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0126 - mape: 21.7747 - mse: 0.0126 - rmse: 0.1124 - val_loss: 0.0114 - val_mape: 19.5117 - val_mse: 0.0115 - val_rmse: 0.1068\n",
      "Epoch 74/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0127 - mape: 21.9748 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0113 - val_mape: 19.7200 - val_mse: 0.0113 - val_rmse: 0.1061\n",
      "Epoch 75/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0133 - mape: 22.5675 - mse: 0.0133 - rmse: 0.1154 - val_loss: 0.0116 - val_mape: 20.5962 - val_mse: 0.0117 - val_rmse: 0.1077\n",
      "Epoch 76/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0126 - mape: 21.5329 - mse: 0.0126 - rmse: 0.1120 - val_loss: 0.0116 - val_mape: 20.4897 - val_mse: 0.0116 - val_rmse: 0.1076\n",
      "Epoch 77/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0130 - mape: 22.4099 - mse: 0.0130 - rmse: 0.1141 - val_loss: 0.0122 - val_mape: 19.8803 - val_mse: 0.0122 - val_rmse: 0.1104\n",
      "Epoch 78/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0124 - mape: 21.5909 - mse: 0.0124 - rmse: 0.1114 - val_loss: 0.0130 - val_mape: 20.0427 - val_mse: 0.0131 - val_rmse: 0.1141\n",
      "Epoch 79/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0121 - mape: 21.1582 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0114 - val_mape: 19.7254 - val_mse: 0.0115 - val_rmse: 0.1067\n",
      "Epoch 80/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0124 - mape: 21.4428 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0117 - val_mape: 19.7074 - val_mse: 0.0117 - val_rmse: 0.1080\n",
      "Epoch 81/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0126 - mape: 21.7027 - mse: 0.0126 - rmse: 0.1122 - val_loss: 0.0113 - val_mape: 20.3232 - val_mse: 0.0113 - val_rmse: 0.1061\n",
      "Epoch 82/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0128 - mape: 21.9165 - mse: 0.0128 - rmse: 0.1133 - val_loss: 0.0113 - val_mape: 20.5728 - val_mse: 0.0114 - val_rmse: 0.1065\n",
      "Epoch 83/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0117 - mape: 20.9995 - mse: 0.0117 - rmse: 0.1082 - val_loss: 0.0117 - val_mape: 19.8289 - val_mse: 0.0118 - val_rmse: 0.1083\n",
      "Epoch 84/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0121 - mape: 21.4692 - mse: 0.0121 - rmse: 0.1100 - val_loss: 0.0121 - val_mape: 21.8543 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 85/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0119 - mape: 21.0248 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 21.8108 - val_mse: 0.0116 - val_rmse: 0.1074\n",
      "Epoch 86/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0122 - mape: 21.5571 - mse: 0.0122 - rmse: 0.1106 - val_loss: 0.0112 - val_mape: 20.7609 - val_mse: 0.0113 - val_rmse: 0.1059\n",
      "Epoch 87/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0123 - mape: 21.5738 - mse: 0.0123 - rmse: 0.1110 - val_loss: 0.0118 - val_mape: 21.6662 - val_mse: 0.0119 - val_rmse: 0.1087\n",
      "Epoch 88/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0120 - mape: 21.7167 - mse: 0.0120 - rmse: 0.1096 - val_loss: 0.0112 - val_mape: 21.4729 - val_mse: 0.0112 - val_rmse: 0.1058\n",
      "Epoch 89/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0115 - mape: 21.1207 - mse: 0.0115 - rmse: 0.1074 - val_loss: 0.0119 - val_mape: 22.6951 - val_mse: 0.0120 - val_rmse: 0.1093\n",
      "Epoch 90/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0119 - mape: 21.3171 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0120 - val_mape: 22.4080 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 91/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0116 - mape: 20.9572 - mse: 0.0116 - rmse: 0.1077 - val_loss: 0.0121 - val_mape: 22.7228 - val_mse: 0.0122 - val_rmse: 0.1100\n",
      "Epoch 92/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0117 - mape: 20.5622 - mse: 0.0117 - rmse: 0.1079 - val_loss: 0.0115 - val_mape: 21.6287 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 93/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0115 - mape: 20.7206 - mse: 0.0115 - rmse: 0.1072 - val_loss: 0.0121 - val_mape: 23.0908 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 94/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0116 - mape: 20.9802 - mse: 0.0116 - rmse: 0.1075 - val_loss: 0.0122 - val_mape: 22.1486 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 95/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0114 - mape: 21.0143 - mse: 0.0114 - rmse: 0.1068 - val_loss: 0.0118 - val_mape: 22.2595 - val_mse: 0.0118 - val_rmse: 0.1086\n",
      "Epoch 96/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0112 - mape: 20.5155 - mse: 0.0112 - rmse: 0.1060 - val_loss: 0.0115 - val_mape: 21.5820 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 97/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0115 - mape: 20.7634 - mse: 0.0115 - rmse: 0.1073 - val_loss: 0.0113 - val_mape: 20.9165 - val_mse: 0.0113 - val_rmse: 0.1062\n",
      "Epoch 98/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0116 - mape: 21.0170 - mse: 0.0116 - rmse: 0.1078 - val_loss: 0.0126 - val_mape: 23.5072 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 99/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0115 - mape: 20.6012 - mse: 0.0115 - rmse: 0.1073 - val_loss: 0.0121 - val_mape: 23.2198 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 100/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0111 - mape: 20.4065 - mse: 0.0111 - rmse: 0.1054 - val_loss: 0.0112 - val_mape: 20.0748 - val_mse: 0.0113 - val_rmse: 0.1058\n",
      "Epoch 101/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0112 - mape: 20.6697 - mse: 0.0112 - rmse: 0.1059 - val_loss: 0.0137 - val_mape: 25.1605 - val_mse: 0.0138 - val_rmse: 0.1172\n",
      "Epoch 102/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0110 - mape: 20.3108 - mse: 0.0110 - rmse: 0.1049 - val_loss: 0.0114 - val_mape: 21.5137 - val_mse: 0.0115 - val_rmse: 0.1068\n",
      "Epoch 103/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0115 - mape: 21.3032 - mse: 0.0115 - rmse: 0.1073 - val_loss: 0.0131 - val_mape: 23.9101 - val_mse: 0.0132 - val_rmse: 0.1145\n",
      "Epoch 104/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0113 - mape: 20.1787 - mse: 0.0113 - rmse: 0.1063 - val_loss: 0.0122 - val_mape: 23.1000 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 105/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0114 - mape: 21.0660 - mse: 0.0114 - rmse: 0.1070 - val_loss: 0.0121 - val_mape: 22.0307 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 106/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0113 - mape: 20.6269 - mse: 0.0113 - rmse: 0.1064 - val_loss: 0.0123 - val_mape: 22.9105 - val_mse: 0.0124 - val_rmse: 0.1111\n",
      "Epoch 107/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0110 - mape: 20.4735 - mse: 0.0110 - rmse: 0.1048 - val_loss: 0.0135 - val_mape: 25.3071 - val_mse: 0.0135 - val_rmse: 0.1160\n",
      "Epoch 108/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0111 - mape: 20.5850 - mse: 0.0111 - rmse: 0.1055 - val_loss: 0.0123 - val_mape: 23.3744 - val_mse: 0.0123 - val_rmse: 0.1108\n",
      "PROCESANDO ARCHIVO: Pinus gerardiana\n",
      "(10101, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus gerardiana_best_models.json\n",
      "(5767, 4, 43) (2181, 4, 43) (1745, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m53,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m115,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m82,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m1,548\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,597</span> (4.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,067,597\u001b[0m (4.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355,865</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m355,865\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">711,732</span> (2.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m711,732\u001b[0m (2.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0251 - mape: 42.0724 - mse: 0.0251 - rmse: 0.1583 - val_loss: 0.0222 - val_mape: 42.8406 - val_mse: 0.0220 - val_rmse: 0.1490\n",
      "Epoch 2/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0223 - mape: 39.0549 - mse: 0.0223 - rmse: 0.1494 - val_loss: 0.0221 - val_mape: 43.6312 - val_mse: 0.0219 - val_rmse: 0.1487\n",
      "Epoch 3/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0222 - mape: 39.1678 - mse: 0.0222 - rmse: 0.1491 - val_loss: 0.0214 - val_mape: 41.8150 - val_mse: 0.0212 - val_rmse: 0.1461\n",
      "Epoch 4/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0220 - mape: 38.1962 - mse: 0.0220 - rmse: 0.1481 - val_loss: 0.0219 - val_mape: 41.6627 - val_mse: 0.0217 - val_rmse: 0.1479\n",
      "Epoch 5/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0214 - mape: 37.8171 - mse: 0.0214 - rmse: 0.1462 - val_loss: 0.0207 - val_mape: 41.0642 - val_mse: 0.0206 - val_rmse: 0.1440\n",
      "Epoch 6/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0211 - mape: 37.1406 - mse: 0.0211 - rmse: 0.1451 - val_loss: 0.0207 - val_mape: 38.6175 - val_mse: 0.0206 - val_rmse: 0.1438\n",
      "Epoch 7/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0207 - mape: 37.0317 - mse: 0.0207 - rmse: 0.1438 - val_loss: 0.0208 - val_mape: 41.2205 - val_mse: 0.0206 - val_rmse: 0.1441\n",
      "Epoch 8/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0210 - mape: 37.4846 - mse: 0.0210 - rmse: 0.1447 - val_loss: 0.0206 - val_mape: 40.5810 - val_mse: 0.0204 - val_rmse: 0.1435\n",
      "Epoch 9/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0205 - mape: 36.4480 - mse: 0.0205 - rmse: 0.1432 - val_loss: 0.0208 - val_mape: 38.1334 - val_mse: 0.0207 - val_rmse: 0.1443\n",
      "Epoch 10/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0202 - mape: 36.1176 - mse: 0.0202 - rmse: 0.1422 - val_loss: 0.0208 - val_mape: 40.6451 - val_mse: 0.0207 - val_rmse: 0.1443\n",
      "Epoch 11/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0203 - mape: 37.1627 - mse: 0.0203 - rmse: 0.1425 - val_loss: 0.0236 - val_mape: 40.8825 - val_mse: 0.0235 - val_rmse: 0.1538\n",
      "Epoch 12/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0201 - mape: 36.0959 - mse: 0.0201 - rmse: 0.1416 - val_loss: 0.0209 - val_mape: 39.6485 - val_mse: 0.0207 - val_rmse: 0.1444\n",
      "Epoch 13/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0197 - mape: 36.0335 - mse: 0.0197 - rmse: 0.1403 - val_loss: 0.0222 - val_mape: 40.1455 - val_mse: 0.0221 - val_rmse: 0.1491\n",
      "Epoch 14/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0195 - mape: 35.5294 - mse: 0.0195 - rmse: 0.1394 - val_loss: 0.0208 - val_mape: 42.2838 - val_mse: 0.0206 - val_rmse: 0.1441\n",
      "Epoch 15/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0193 - mape: 34.8456 - mse: 0.0193 - rmse: 0.1391 - val_loss: 0.0205 - val_mape: 41.1808 - val_mse: 0.0204 - val_rmse: 0.1432\n",
      "Epoch 16/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0193 - mape: 35.4697 - mse: 0.0193 - rmse: 0.1387 - val_loss: 0.0214 - val_mape: 44.0050 - val_mse: 0.0213 - val_rmse: 0.1464\n",
      "Epoch 17/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0193 - mape: 35.7057 - mse: 0.0193 - rmse: 0.1388 - val_loss: 0.0212 - val_mape: 43.7727 - val_mse: 0.0210 - val_rmse: 0.1455\n",
      "Epoch 18/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0188 - mape: 33.9097 - mse: 0.0188 - rmse: 0.1372 - val_loss: 0.0217 - val_mape: 39.5921 - val_mse: 0.0216 - val_rmse: 0.1471\n",
      "Epoch 19/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0188 - mape: 34.4693 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0209 - val_mape: 42.3675 - val_mse: 0.0208 - val_rmse: 0.1447\n",
      "Epoch 20/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0193 - mape: 34.6915 - mse: 0.0193 - rmse: 0.1390 - val_loss: 0.0207 - val_mape: 42.2352 - val_mse: 0.0205 - val_rmse: 0.1439\n",
      "Epoch 21/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0191 - mape: 35.1070 - mse: 0.0191 - rmse: 0.1382 - val_loss: 0.0214 - val_mape: 40.7992 - val_mse: 0.0213 - val_rmse: 0.1462\n",
      "Epoch 22/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0191 - mape: 35.3651 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0204 - val_mape: 42.5019 - val_mse: 0.0202 - val_rmse: 0.1429\n",
      "Epoch 23/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0192 - mape: 34.9871 - mse: 0.0192 - rmse: 0.1384 - val_loss: 0.0211 - val_mape: 40.2794 - val_mse: 0.0209 - val_rmse: 0.1452\n",
      "Epoch 24/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0181 - mape: 34.1979 - mse: 0.0181 - rmse: 0.1344 - val_loss: 0.0208 - val_mape: 41.5663 - val_mse: 0.0207 - val_rmse: 0.1444\n",
      "Epoch 25/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0185 - mape: 34.4042 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0212 - val_mape: 42.4550 - val_mse: 0.0210 - val_rmse: 0.1455\n",
      "Epoch 26/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0185 - mape: 34.4193 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0203 - val_mape: 41.5543 - val_mse: 0.0201 - val_rmse: 0.1424\n",
      "Epoch 27/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0183 - mape: 34.2347 - mse: 0.0183 - rmse: 0.1351 - val_loss: 0.0207 - val_mape: 42.6741 - val_mse: 0.0205 - val_rmse: 0.1439\n",
      "Epoch 28/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0177 - mape: 33.1008 - mse: 0.0177 - rmse: 0.1330 - val_loss: 0.0214 - val_mape: 40.3017 - val_mse: 0.0212 - val_rmse: 0.1461\n",
      "Epoch 29/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0180 - mape: 34.1220 - mse: 0.0180 - rmse: 0.1342 - val_loss: 0.0205 - val_mape: 40.5348 - val_mse: 0.0204 - val_rmse: 0.1433\n",
      "Epoch 30/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0177 - mape: 34.5477 - mse: 0.0177 - rmse: 0.1330 - val_loss: 0.0231 - val_mape: 40.7110 - val_mse: 0.0231 - val_rmse: 0.1521\n",
      "Epoch 31/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0177 - mape: 34.1572 - mse: 0.0177 - rmse: 0.1329 - val_loss: 0.0202 - val_mape: 41.1863 - val_mse: 0.0200 - val_rmse: 0.1421\n",
      "Epoch 32/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0177 - mape: 34.2880 - mse: 0.0177 - rmse: 0.1331 - val_loss: 0.0210 - val_mape: 43.7077 - val_mse: 0.0208 - val_rmse: 0.1449\n",
      "Epoch 33/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0169 - mape: 32.6660 - mse: 0.0169 - rmse: 0.1301 - val_loss: 0.0203 - val_mape: 41.1640 - val_mse: 0.0201 - val_rmse: 0.1423\n",
      "Epoch 34/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0177 - mape: 33.5962 - mse: 0.0177 - rmse: 0.1329 - val_loss: 0.0200 - val_mape: 41.6648 - val_mse: 0.0199 - val_rmse: 0.1416\n",
      "Epoch 35/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0173 - mape: 32.9657 - mse: 0.0173 - rmse: 0.1313 - val_loss: 0.0203 - val_mape: 41.9215 - val_mse: 0.0201 - val_rmse: 0.1424\n",
      "Epoch 36/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0173 - mape: 33.2419 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0209 - val_mape: 40.5766 - val_mse: 0.0208 - val_rmse: 0.1447\n",
      "Epoch 37/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0171 - mape: 32.1136 - mse: 0.0171 - rmse: 0.1305 - val_loss: 0.0204 - val_mape: 38.4635 - val_mse: 0.0204 - val_rmse: 0.1429\n",
      "Epoch 38/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0170 - mape: 32.6190 - mse: 0.0170 - rmse: 0.1302 - val_loss: 0.0204 - val_mape: 42.8608 - val_mse: 0.0202 - val_rmse: 0.1428\n",
      "Epoch 39/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0170 - mape: 32.6435 - mse: 0.0170 - rmse: 0.1304 - val_loss: 0.0202 - val_mape: 41.0425 - val_mse: 0.0201 - val_rmse: 0.1423\n",
      "Epoch 40/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0164 - mape: 32.4754 - mse: 0.0164 - rmse: 0.1279 - val_loss: 0.0207 - val_mape: 42.2990 - val_mse: 0.0206 - val_rmse: 0.1440\n",
      "Epoch 41/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0166 - mape: 31.9611 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0217 - val_mape: 41.4198 - val_mse: 0.0215 - val_rmse: 0.1473\n",
      "Epoch 42/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0166 - mape: 32.4875 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0205 - val_mape: 41.2647 - val_mse: 0.0204 - val_rmse: 0.1432\n",
      "Epoch 43/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0165 - mape: 32.1852 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0206 - val_mape: 42.4743 - val_mse: 0.0204 - val_rmse: 0.1435\n",
      "Epoch 44/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0167 - mape: 32.3261 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0204 - val_mape: 41.5845 - val_mse: 0.0202 - val_rmse: 0.1427\n",
      "Epoch 45/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0176 - mape: 33.4478 - mse: 0.0176 - rmse: 0.1325 - val_loss: 0.0201 - val_mape: 41.6101 - val_mse: 0.0199 - val_rmse: 0.1417\n",
      "Epoch 46/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0169 - mape: 32.7589 - mse: 0.0169 - rmse: 0.1299 - val_loss: 0.0218 - val_mape: 42.1893 - val_mse: 0.0217 - val_rmse: 0.1477\n",
      "Epoch 47/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0170 - mape: 32.4216 - mse: 0.0170 - rmse: 0.1303 - val_loss: 0.0212 - val_mape: 42.8385 - val_mse: 0.0211 - val_rmse: 0.1457\n",
      "Epoch 48/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0164 - mape: 31.8500 - mse: 0.0164 - rmse: 0.1280 - val_loss: 0.0215 - val_mape: 44.1253 - val_mse: 0.0214 - val_rmse: 0.1468\n",
      "Epoch 49/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0171 - mape: 32.9593 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0209 - val_mape: 42.5519 - val_mse: 0.0207 - val_rmse: 0.1444\n",
      "Epoch 50/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0165 - mape: 31.9644 - mse: 0.0165 - rmse: 0.1284 - val_loss: 0.0216 - val_mape: 39.7422 - val_mse: 0.0215 - val_rmse: 0.1471\n",
      "Epoch 51/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0160 - mape: 31.5525 - mse: 0.0160 - rmse: 0.1264 - val_loss: 0.0221 - val_mape: 45.7844 - val_mse: 0.0219 - val_rmse: 0.1486\n",
      "Epoch 52/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0167 - mape: 31.8996 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0204 - val_mape: 43.3372 - val_mse: 0.0202 - val_rmse: 0.1429\n",
      "Epoch 53/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0159 - mape: 31.3875 - mse: 0.0159 - rmse: 0.1259 - val_loss: 0.0195 - val_mape: 40.5123 - val_mse: 0.0193 - val_rmse: 0.1395\n",
      "Epoch 54/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0169 - mape: 32.1253 - mse: 0.0169 - rmse: 0.1298 - val_loss: 0.0209 - val_mape: 41.1056 - val_mse: 0.0208 - val_rmse: 0.1445\n",
      "Epoch 55/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0156 - mape: 31.1122 - mse: 0.0156 - rmse: 0.1248 - val_loss: 0.0210 - val_mape: 41.7584 - val_mse: 0.0208 - val_rmse: 0.1448\n",
      "Epoch 56/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0155 - mape: 31.0516 - mse: 0.0155 - rmse: 0.1244 - val_loss: 0.0216 - val_mape: 39.3369 - val_mse: 0.0215 - val_rmse: 0.1470\n",
      "Epoch 57/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0165 - mape: 32.0106 - mse: 0.0165 - rmse: 0.1282 - val_loss: 0.0208 - val_mape: 41.9542 - val_mse: 0.0206 - val_rmse: 0.1443\n",
      "Epoch 58/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0154 - mape: 30.9124 - mse: 0.0154 - rmse: 0.1243 - val_loss: 0.0204 - val_mape: 42.4180 - val_mse: 0.0202 - val_rmse: 0.1427\n",
      "Epoch 59/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0164 - mape: 32.0473 - mse: 0.0164 - rmse: 0.1279 - val_loss: 0.0201 - val_mape: 40.7002 - val_mse: 0.0200 - val_rmse: 0.1419\n",
      "Epoch 60/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0157 - mape: 31.0823 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0201 - val_mape: 40.8166 - val_mse: 0.0200 - val_rmse: 0.1418\n",
      "Epoch 61/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0153 - mape: 30.5379 - mse: 0.0153 - rmse: 0.1238 - val_loss: 0.0209 - val_mape: 39.8147 - val_mse: 0.0208 - val_rmse: 0.1446\n",
      "Epoch 62/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0145 - mape: 29.8936 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0198 - val_mape: 39.3119 - val_mse: 0.0197 - val_rmse: 0.1408\n",
      "Epoch 63/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0151 - mape: 30.6435 - mse: 0.0151 - rmse: 0.1228 - val_loss: 0.0208 - val_mape: 42.3562 - val_mse: 0.0207 - val_rmse: 0.1443\n",
      "Epoch 64/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0153 - mape: 30.7141 - mse: 0.0153 - rmse: 0.1235 - val_loss: 0.0195 - val_mape: 39.3990 - val_mse: 0.0194 - val_rmse: 0.1396\n",
      "Epoch 65/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0159 - mape: 31.0375 - mse: 0.0159 - rmse: 0.1258 - val_loss: 0.0212 - val_mape: 42.7855 - val_mse: 0.0210 - val_rmse: 0.1455\n",
      "Epoch 66/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0149 - mape: 30.5172 - mse: 0.0149 - rmse: 0.1219 - val_loss: 0.0205 - val_mape: 41.6430 - val_mse: 0.0203 - val_rmse: 0.1432\n",
      "Epoch 67/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0149 - mape: 30.5187 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0209 - val_mape: 41.7541 - val_mse: 0.0207 - val_rmse: 0.1444\n",
      "Epoch 68/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0157 - mape: 31.2441 - mse: 0.0157 - rmse: 0.1251 - val_loss: 0.0196 - val_mape: 40.2166 - val_mse: 0.0194 - val_rmse: 0.1399\n",
      "Epoch 69/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0150 - mape: 30.9857 - mse: 0.0150 - rmse: 0.1223 - val_loss: 0.0208 - val_mape: 42.0996 - val_mse: 0.0207 - val_rmse: 0.1443\n",
      "Epoch 70/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0151 - mape: 30.0636 - mse: 0.0151 - rmse: 0.1229 - val_loss: 0.0205 - val_mape: 38.7931 - val_mse: 0.0203 - val_rmse: 0.1432\n",
      "Epoch 71/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0145 - mape: 29.4692 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0209 - val_mape: 42.7325 - val_mse: 0.0208 - val_rmse: 0.1446\n",
      "Epoch 72/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0147 - mape: 30.2427 - mse: 0.0147 - rmse: 0.1212 - val_loss: 0.0219 - val_mape: 44.7337 - val_mse: 0.0217 - val_rmse: 0.1480\n",
      "Epoch 73/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0144 - mape: 29.2391 - mse: 0.0144 - rmse: 0.1198 - val_loss: 0.0213 - val_mape: 42.5423 - val_mse: 0.0212 - val_rmse: 0.1460\n",
      "PROCESANDO ARCHIVO: Betula utilis\n",
      "(3473, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Betula utilis_best_models.json\n",
      "(2059, 4, 43) (665, 4, 43) (593, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m88,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m115,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m1,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,416,725</span> (5.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,416,725\u001b[0m (5.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,241</span> (1.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m472,241\u001b[0m (1.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">944,484</span> (3.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m944,484\u001b[0m (3.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.0168 - mape: 60.6028 - mse: 0.0168 - rmse: 0.1296 - val_loss: 0.0153 - val_mape: 32.9557 - val_mse: 0.0154 - val_rmse: 0.1237\n",
      "Epoch 2/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0142 - mape: 50.2579 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0167 - val_mape: 30.8293 - val_mse: 0.0172 - val_rmse: 0.1292\n",
      "Epoch 3/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0146 - mape: 51.7884 - mse: 0.0146 - rmse: 0.1207 - val_loss: 0.0177 - val_mape: 32.5398 - val_mse: 0.0182 - val_rmse: 0.1331\n",
      "Epoch 4/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0142 - mape: 48.7505 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0173 - val_mape: 33.4027 - val_mse: 0.0175 - val_rmse: 0.1315\n",
      "Epoch 5/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0139 - mape: 48.9847 - mse: 0.0139 - rmse: 0.1178 - val_loss: 0.0132 - val_mape: 34.9129 - val_mse: 0.0131 - val_rmse: 0.1150\n",
      "Epoch 6/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0132 - mape: 49.9758 - mse: 0.0132 - rmse: 0.1147 - val_loss: 0.0132 - val_mape: 31.8770 - val_mse: 0.0131 - val_rmse: 0.1149\n",
      "Epoch 7/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0136 - mape: 54.1424 - mse: 0.0136 - rmse: 0.1164 - val_loss: 0.0151 - val_mape: 33.6482 - val_mse: 0.0152 - val_rmse: 0.1228\n",
      "Epoch 8/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0133 - mape: 50.0903 - mse: 0.0133 - rmse: 0.1151 - val_loss: 0.0149 - val_mape: 38.4795 - val_mse: 0.0148 - val_rmse: 0.1219\n",
      "Epoch 9/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0127 - mape: 50.7425 - mse: 0.0127 - rmse: 0.1127 - val_loss: 0.0136 - val_mape: 36.4176 - val_mse: 0.0134 - val_rmse: 0.1168\n",
      "Epoch 10/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0127 - mape: 51.4061 - mse: 0.0127 - rmse: 0.1126 - val_loss: 0.0123 - val_mape: 26.1092 - val_mse: 0.0120 - val_rmse: 0.1108\n",
      "Epoch 11/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0124 - mape: 47.2776 - mse: 0.0124 - rmse: 0.1113 - val_loss: 0.0126 - val_mape: 25.7460 - val_mse: 0.0124 - val_rmse: 0.1123\n",
      "Epoch 12/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0121 - mape: 48.8197 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0127 - val_mape: 34.4554 - val_mse: 0.0124 - val_rmse: 0.1125\n",
      "Epoch 13/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0118 - mape: 51.8603 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0135 - val_mape: 38.2324 - val_mse: 0.0133 - val_rmse: 0.1162\n",
      "Epoch 14/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0117 - mape: 51.1739 - mse: 0.0117 - rmse: 0.1079 - val_loss: 0.0120 - val_mape: 25.8082 - val_mse: 0.0118 - val_rmse: 0.1096\n",
      "Epoch 15/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0114 - mape: 47.0666 - mse: 0.0114 - rmse: 0.1066 - val_loss: 0.0122 - val_mape: 25.1302 - val_mse: 0.0120 - val_rmse: 0.1106\n",
      "Epoch 16/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0118 - mape: 46.8861 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0114 - val_mape: 29.3556 - val_mse: 0.0111 - val_rmse: 0.1069\n",
      "Epoch 17/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0115 - mape: 46.3246 - mse: 0.0115 - rmse: 0.1071 - val_loss: 0.0125 - val_mape: 31.9020 - val_mse: 0.0122 - val_rmse: 0.1119\n",
      "Epoch 18/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0117 - mape: 51.6705 - mse: 0.0117 - rmse: 0.1081 - val_loss: 0.0117 - val_mape: 28.3375 - val_mse: 0.0115 - val_rmse: 0.1084\n",
      "Epoch 19/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0118 - mape: 50.2926 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0117 - val_mape: 28.8086 - val_mse: 0.0114 - val_rmse: 0.1082\n",
      "Epoch 20/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0111 - mape: 46.7317 - mse: 0.0111 - rmse: 0.1055 - val_loss: 0.0115 - val_mape: 30.0622 - val_mse: 0.0113 - val_rmse: 0.1073\n",
      "Epoch 21/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0112 - mape: 43.9198 - mse: 0.0112 - rmse: 0.1055 - val_loss: 0.0116 - val_mape: 31.7037 - val_mse: 0.0113 - val_rmse: 0.1076\n",
      "Epoch 22/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0110 - mape: 46.4098 - mse: 0.0110 - rmse: 0.1050 - val_loss: 0.0119 - val_mape: 27.7407 - val_mse: 0.0116 - val_rmse: 0.1090\n",
      "Epoch 23/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0112 - mape: 44.7435 - mse: 0.0112 - rmse: 0.1057 - val_loss: 0.0130 - val_mape: 29.3838 - val_mse: 0.0128 - val_rmse: 0.1138\n",
      "Epoch 24/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0121 - mape: 56.0742 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0118 - val_mape: 28.3614 - val_mse: 0.0115 - val_rmse: 0.1087\n",
      "Epoch 25/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0106 - mape: 44.5409 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0116 - val_mape: 27.6389 - val_mse: 0.0113 - val_rmse: 0.1078\n",
      "Epoch 26/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0107 - mape: 46.0223 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0113 - val_mape: 27.9413 - val_mse: 0.0111 - val_rmse: 0.1065\n",
      "Epoch 27/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0106 - mape: 48.9823 - mse: 0.0106 - rmse: 0.1030 - val_loss: 0.0124 - val_mape: 24.3655 - val_mse: 0.0124 - val_rmse: 0.1114\n",
      "Epoch 28/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0116 - mape: 53.4496 - mse: 0.0116 - rmse: 0.1074 - val_loss: 0.0116 - val_mape: 26.7042 - val_mse: 0.0113 - val_rmse: 0.1076\n",
      "Epoch 29/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mape: 49.5350 - mse: 0.0109 - rmse: 0.1041 - val_loss: 0.0116 - val_mape: 28.4431 - val_mse: 0.0113 - val_rmse: 0.1076\n",
      "Epoch 30/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0107 - mape: 48.3311 - mse: 0.0107 - rmse: 0.1035 - val_loss: 0.0117 - val_mape: 26.5007 - val_mse: 0.0115 - val_rmse: 0.1084\n",
      "Epoch 31/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mape: 46.6042 - mse: 0.0109 - rmse: 0.1043 - val_loss: 0.0119 - val_mape: 27.0101 - val_mse: 0.0118 - val_rmse: 0.1093\n",
      "Epoch 32/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0112 - mape: 49.5136 - mse: 0.0112 - rmse: 0.1058 - val_loss: 0.0111 - val_mape: 27.9097 - val_mse: 0.0108 - val_rmse: 0.1052\n",
      "Epoch 33/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0105 - mape: 49.0911 - mse: 0.0105 - rmse: 0.1024 - val_loss: 0.0112 - val_mape: 27.1951 - val_mse: 0.0112 - val_rmse: 0.1060\n",
      "Epoch 34/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0107 - mape: 48.4903 - mse: 0.0107 - rmse: 0.1034 - val_loss: 0.0122 - val_mape: 28.6237 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 35/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mape: 46.9972 - mse: 0.0109 - rmse: 0.1044 - val_loss: 0.0115 - val_mape: 28.2484 - val_mse: 0.0112 - val_rmse: 0.1071\n",
      "Epoch 36/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0106 - mape: 47.8519 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0132 - val_mape: 27.1116 - val_mse: 0.0132 - val_rmse: 0.1151\n",
      "Epoch 37/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0114 - mape: 50.0397 - mse: 0.0114 - rmse: 0.1069 - val_loss: 0.0117 - val_mape: 27.3810 - val_mse: 0.0116 - val_rmse: 0.1080\n",
      "Epoch 38/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mape: 49.6369 - mse: 0.0109 - rmse: 0.1042 - val_loss: 0.0113 - val_mape: 30.7137 - val_mse: 0.0111 - val_rmse: 0.1063\n",
      "Epoch 39/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0101 - mape: 46.3124 - mse: 0.0101 - rmse: 0.1004 - val_loss: 0.0122 - val_mape: 27.8774 - val_mse: 0.0122 - val_rmse: 0.1106\n",
      "Epoch 40/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0105 - mape: 48.3568 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0144 - val_mape: 25.8595 - val_mse: 0.0153 - val_rmse: 0.1201\n",
      "Epoch 41/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0116 - mape: 50.2727 - mse: 0.0116 - rmse: 0.1077 - val_loss: 0.0110 - val_mape: 28.1389 - val_mse: 0.0107 - val_rmse: 0.1048\n",
      "Epoch 42/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0105 - mape: 48.4312 - mse: 0.0105 - rmse: 0.1023 - val_loss: 0.0113 - val_mape: 28.7749 - val_mse: 0.0110 - val_rmse: 0.1061\n",
      "Epoch 43/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0099 - mape: 45.7697 - mse: 0.0099 - rmse: 0.0996 - val_loss: 0.0126 - val_mape: 24.9530 - val_mse: 0.0127 - val_rmse: 0.1122\n",
      "Epoch 44/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mape: 48.4855 - mse: 0.0109 - rmse: 0.1043 - val_loss: 0.0115 - val_mape: 28.3267 - val_mse: 0.0114 - val_rmse: 0.1074\n",
      "Epoch 45/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0103 - mape: 47.9890 - mse: 0.0103 - rmse: 0.1016 - val_loss: 0.0125 - val_mape: 24.5500 - val_mse: 0.0124 - val_rmse: 0.1117\n",
      "Epoch 46/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0109 - mape: 51.9845 - mse: 0.0109 - rmse: 0.1044 - val_loss: 0.0116 - val_mape: 28.2422 - val_mse: 0.0113 - val_rmse: 0.1076\n",
      "Epoch 47/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0107 - mape: 47.2539 - mse: 0.0107 - rmse: 0.1035 - val_loss: 0.0118 - val_mape: 28.2050 - val_mse: 0.0119 - val_rmse: 0.1086\n",
      "Epoch 48/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0106 - mape: 46.1349 - mse: 0.0106 - rmse: 0.1029 - val_loss: 0.0112 - val_mape: 31.2317 - val_mse: 0.0109 - val_rmse: 0.1056\n",
      "Epoch 49/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0103 - mape: 46.2465 - mse: 0.0103 - rmse: 0.1012 - val_loss: 0.0117 - val_mape: 29.5146 - val_mse: 0.0116 - val_rmse: 0.1079\n",
      "Epoch 50/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0105 - mape: 48.9248 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0119 - val_mape: 25.8069 - val_mse: 0.0119 - val_rmse: 0.1093\n",
      "Epoch 51/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0109 - mape: 49.7157 - mse: 0.0109 - rmse: 0.1045 - val_loss: 0.0132 - val_mape: 23.8270 - val_mse: 0.0134 - val_rmse: 0.1150\n",
      "Epoch 52/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0113 - mape: 52.5972 - mse: 0.0113 - rmse: 0.1063 - val_loss: 0.0124 - val_mape: 24.3473 - val_mse: 0.0124 - val_rmse: 0.1114\n",
      "Epoch 53/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0105 - mape: 47.4685 - mse: 0.0105 - rmse: 0.1022 - val_loss: 0.0126 - val_mape: 23.2736 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 54/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0105 - mape: 48.9304 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0121 - val_mape: 25.0557 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 55/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0104 - mape: 48.7257 - mse: 0.0104 - rmse: 0.1019 - val_loss: 0.0125 - val_mape: 23.2093 - val_mse: 0.0125 - val_rmse: 0.1119\n",
      "Epoch 56/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0101 - mape: 46.6346 - mse: 0.0101 - rmse: 0.1004 - val_loss: 0.0134 - val_mape: 23.5645 - val_mse: 0.0135 - val_rmse: 0.1159\n",
      "Epoch 57/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0107 - mape: 47.8638 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0117 - val_mape: 29.9874 - val_mse: 0.0114 - val_rmse: 0.1081\n",
      "Epoch 58/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0096 - mape: 39.7215 - mse: 0.0096 - rmse: 0.0977 - val_loss: 0.0120 - val_mape: 24.0218 - val_mse: 0.0119 - val_rmse: 0.1095\n",
      "Epoch 59/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0104 - mape: 46.9748 - mse: 0.0104 - rmse: 0.1020 - val_loss: 0.0159 - val_mape: 25.3239 - val_mse: 0.0163 - val_rmse: 0.1263\n",
      "Epoch 60/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0114 - mape: 49.1904 - mse: 0.0114 - rmse: 0.1065 - val_loss: 0.0147 - val_mape: 24.2705 - val_mse: 0.0147 - val_rmse: 0.1213\n",
      "Epoch 61/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0104 - mape: 44.6541 - mse: 0.0104 - rmse: 0.1017 - val_loss: 0.0145 - val_mape: 24.4312 - val_mse: 0.0143 - val_rmse: 0.1204\n",
      "PROCESANDO ARCHIVO: Picea smithiana\n",
      "(34476, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Picea smithiana_best_models.json\n",
      "(19933, 4, 43) (7272, 4, 43) (5863, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">115,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m53,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m49,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m115,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m2,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">971,285</span> (3.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m971,285\u001b[0m (3.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">323,761</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m323,761\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">647,524</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m647,524\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.0188 - mape: 32.1460 - mse: 0.0188 - rmse: 0.1371 - val_loss: 0.0177 - val_mape: 31.8016 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 2/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0185 - mape: 31.5274 - mse: 0.0185 - rmse: 0.1361 - val_loss: 0.0181 - val_mape: 31.4694 - val_mse: 0.0181 - val_rmse: 0.1345\n",
      "Epoch 3/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0185 - mape: 32.0509 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0179 - val_mape: 32.4744 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 4/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0181 - mape: 31.3559 - mse: 0.0181 - rmse: 0.1347 - val_loss: 0.0175 - val_mape: 29.0438 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 5/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0179 - mape: 31.1971 - mse: 0.0179 - rmse: 0.1340 - val_loss: 0.0170 - val_mape: 28.7134 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 6/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0175 - mape: 30.7595 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0167 - val_mape: 28.9881 - val_mse: 0.0167 - val_rmse: 0.1291\n",
      "Epoch 7/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0175 - mape: 30.9075 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0169 - val_mape: 28.9810 - val_mse: 0.0169 - val_rmse: 0.1299\n",
      "Epoch 8/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0173 - mape: 30.3072 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0165 - val_mape: 28.8220 - val_mse: 0.0165 - val_rmse: 0.1285\n",
      "Epoch 9/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0174 - mape: 30.9509 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0170 - val_mape: 29.0268 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 10/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0173 - mape: 31.0469 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 30.2242 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 11/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0176 - mape: 31.1640 - mse: 0.0176 - rmse: 0.1326 - val_loss: 0.0168 - val_mape: 30.1134 - val_mse: 0.0168 - val_rmse: 0.1295\n",
      "Epoch 12/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0173 - mape: 30.8307 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0167 - val_mape: 28.3083 - val_mse: 0.0167 - val_rmse: 0.1291\n",
      "Epoch 13/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0170 - mape: 30.4291 - mse: 0.0170 - rmse: 0.1303 - val_loss: 0.0162 - val_mape: 27.7029 - val_mse: 0.0162 - val_rmse: 0.1273\n",
      "Epoch 14/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0167 - mape: 30.0950 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0159 - val_mape: 27.6045 - val_mse: 0.0159 - val_rmse: 0.1262\n",
      "Epoch 15/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0166 - mape: 29.3453 - mse: 0.0166 - rmse: 0.1287 - val_loss: 0.0158 - val_mape: 27.2289 - val_mse: 0.0158 - val_rmse: 0.1256\n",
      "Epoch 16/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0165 - mape: 29.7838 - mse: 0.0165 - rmse: 0.1283 - val_loss: 0.0158 - val_mape: 27.7409 - val_mse: 0.0158 - val_rmse: 0.1256\n",
      "Epoch 17/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0164 - mape: 29.3756 - mse: 0.0164 - rmse: 0.1282 - val_loss: 0.0160 - val_mape: 26.7343 - val_mse: 0.0160 - val_rmse: 0.1267\n",
      "Epoch 18/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0162 - mape: 29.4811 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0157 - val_mape: 28.7078 - val_mse: 0.0157 - val_rmse: 0.1252\n",
      "Epoch 19/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0162 - mape: 29.3041 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0155 - val_mape: 27.3536 - val_mse: 0.0155 - val_rmse: 0.1245\n",
      "Epoch 20/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0163 - mape: 29.5842 - mse: 0.0163 - rmse: 0.1276 - val_loss: 0.0156 - val_mape: 27.4245 - val_mse: 0.0156 - val_rmse: 0.1247\n",
      "Epoch 21/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0160 - mape: 29.2112 - mse: 0.0160 - rmse: 0.1264 - val_loss: 0.0153 - val_mape: 27.6348 - val_mse: 0.0153 - val_rmse: 0.1237\n",
      "Epoch 22/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0157 - mape: 28.9364 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0162 - val_mape: 28.5248 - val_mse: 0.0163 - val_rmse: 0.1274\n",
      "Epoch 23/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0159 - mape: 28.7840 - mse: 0.0159 - rmse: 0.1261 - val_loss: 0.0156 - val_mape: 27.8769 - val_mse: 0.0156 - val_rmse: 0.1249\n",
      "Epoch 24/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0159 - mape: 28.7606 - mse: 0.0159 - rmse: 0.1260 - val_loss: 0.0152 - val_mape: 26.8679 - val_mse: 0.0153 - val_rmse: 0.1235\n",
      "Epoch 25/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0158 - mape: 28.4862 - mse: 0.0158 - rmse: 0.1257 - val_loss: 0.0151 - val_mape: 27.3823 - val_mse: 0.0151 - val_rmse: 0.1228\n",
      "Epoch 26/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0155 - mape: 28.3621 - mse: 0.0155 - rmse: 0.1243 - val_loss: 0.0160 - val_mape: 30.7395 - val_mse: 0.0160 - val_rmse: 0.1264\n",
      "Epoch 27/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0162 - mape: 29.4219 - mse: 0.0162 - rmse: 0.1273 - val_loss: 0.0155 - val_mape: 29.0977 - val_mse: 0.0155 - val_rmse: 0.1243\n",
      "Epoch 28/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0154 - mape: 28.1533 - mse: 0.0154 - rmse: 0.1242 - val_loss: 0.0149 - val_mape: 27.1226 - val_mse: 0.0149 - val_rmse: 0.1219\n",
      "Epoch 29/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0154 - mape: 28.4223 - mse: 0.0154 - rmse: 0.1242 - val_loss: 0.0157 - val_mape: 32.1966 - val_mse: 0.0158 - val_rmse: 0.1254\n",
      "Epoch 30/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0155 - mape: 28.4408 - mse: 0.0155 - rmse: 0.1245 - val_loss: 0.0151 - val_mape: 27.8019 - val_mse: 0.0152 - val_rmse: 0.1230\n",
      "Epoch 31/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0153 - mape: 28.3612 - mse: 0.0153 - rmse: 0.1236 - val_loss: 0.0148 - val_mape: 28.7749 - val_mse: 0.0149 - val_rmse: 0.1218\n",
      "Epoch 32/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0153 - mape: 28.1825 - mse: 0.0153 - rmse: 0.1235 - val_loss: 0.0152 - val_mape: 26.8328 - val_mse: 0.0152 - val_rmse: 0.1233\n",
      "Epoch 33/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0151 - mape: 28.0279 - mse: 0.0151 - rmse: 0.1230 - val_loss: 0.0153 - val_mape: 26.8634 - val_mse: 0.0153 - val_rmse: 0.1235\n",
      "Epoch 34/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0153 - mape: 28.6006 - mse: 0.0153 - rmse: 0.1237 - val_loss: 0.0152 - val_mape: 26.4056 - val_mse: 0.0152 - val_rmse: 0.1233\n",
      "Epoch 35/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0152 - mape: 27.9999 - mse: 0.0152 - rmse: 0.1232 - val_loss: 0.0152 - val_mape: 27.2891 - val_mse: 0.0152 - val_rmse: 0.1231\n",
      "Epoch 36/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0150 - mape: 27.8279 - mse: 0.0150 - rmse: 0.1225 - val_loss: 0.0150 - val_mape: 26.4203 - val_mse: 0.0150 - val_rmse: 0.1223\n",
      "Epoch 37/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0150 - mape: 27.5754 - mse: 0.0150 - rmse: 0.1226 - val_loss: 0.0154 - val_mape: 25.6674 - val_mse: 0.0154 - val_rmse: 0.1243\n",
      "Epoch 38/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0147 - mape: 27.5673 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0147 - val_mape: 27.4737 - val_mse: 0.0147 - val_rmse: 0.1214\n",
      "Epoch 39/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0147 - mape: 27.6669 - mse: 0.0147 - rmse: 0.1211 - val_loss: 0.0150 - val_mape: 26.0473 - val_mse: 0.0151 - val_rmse: 0.1227\n",
      "Epoch 40/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0147 - mape: 27.4617 - mse: 0.0147 - rmse: 0.1210 - val_loss: 0.0144 - val_mape: 25.4042 - val_mse: 0.0144 - val_rmse: 0.1199\n",
      "Epoch 41/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0145 - mape: 27.1433 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0148 - val_mape: 25.7693 - val_mse: 0.0148 - val_rmse: 0.1215\n",
      "Epoch 42/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0146 - mape: 27.6232 - mse: 0.0146 - rmse: 0.1207 - val_loss: 0.0142 - val_mape: 25.5625 - val_mse: 0.0142 - val_rmse: 0.1191\n",
      "Epoch 43/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0144 - mape: 27.3845 - mse: 0.0144 - rmse: 0.1200 - val_loss: 0.0144 - val_mape: 28.5630 - val_mse: 0.0145 - val_rmse: 0.1202\n",
      "Epoch 44/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0145 - mape: 27.3731 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0143 - val_mape: 26.5457 - val_mse: 0.0143 - val_rmse: 0.1194\n",
      "Epoch 45/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0145 - mape: 27.0693 - mse: 0.0145 - rmse: 0.1206 - val_loss: 0.0152 - val_mape: 25.4751 - val_mse: 0.0152 - val_rmse: 0.1231\n",
      "Epoch 46/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0146 - mape: 27.3817 - mse: 0.0146 - rmse: 0.1207 - val_loss: 0.0146 - val_mape: 26.7300 - val_mse: 0.0146 - val_rmse: 0.1207\n",
      "Epoch 47/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0141 - mape: 26.8183 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0145 - val_mape: 27.3034 - val_mse: 0.0145 - val_rmse: 0.1205\n",
      "Epoch 48/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0143 - mape: 27.2296 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0145 - val_mape: 25.3754 - val_mse: 0.0145 - val_rmse: 0.1203\n",
      "Epoch 49/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0144 - mape: 27.4110 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0143 - val_mape: 30.8629 - val_mse: 0.0143 - val_rmse: 0.1196\n",
      "Epoch 50/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0142 - mape: 26.9667 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0142 - val_mape: 27.3509 - val_mse: 0.0142 - val_rmse: 0.1190\n",
      "Epoch 51/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0142 - mape: 27.1753 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0143 - val_mape: 27.7911 - val_mse: 0.0144 - val_rmse: 0.1197\n",
      "Epoch 52/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0142 - mape: 26.9973 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0144 - val_mape: 25.5043 - val_mse: 0.0144 - val_rmse: 0.1200\n",
      "Epoch 53/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0141 - mape: 27.0755 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0141 - val_mape: 25.7138 - val_mse: 0.0141 - val_rmse: 0.1188\n",
      "Epoch 54/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0140 - mape: 26.7326 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0149 - val_mape: 27.3104 - val_mse: 0.0149 - val_rmse: 0.1222\n",
      "Epoch 55/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0141 - mape: 26.7861 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0148 - val_mape: 28.8284 - val_mse: 0.0149 - val_rmse: 0.1219\n",
      "Epoch 56/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0138 - mape: 26.5795 - mse: 0.0138 - rmse: 0.1177 - val_loss: 0.0139 - val_mape: 26.6763 - val_mse: 0.0140 - val_rmse: 0.1181\n",
      "Epoch 57/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0139 - mape: 26.9715 - mse: 0.0139 - rmse: 0.1179 - val_loss: 0.0149 - val_mape: 29.0314 - val_mse: 0.0149 - val_rmse: 0.1221\n",
      "Epoch 58/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0140 - mape: 27.0304 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0142 - val_mape: 24.6277 - val_mse: 0.0142 - val_rmse: 0.1191\n",
      "Epoch 59/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0140 - mape: 26.5680 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0142 - val_mape: 28.2632 - val_mse: 0.0142 - val_rmse: 0.1190\n",
      "Epoch 60/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.5059 - mse: 0.0137 - rmse: 0.1172 - val_loss: 0.0144 - val_mape: 28.7136 - val_mse: 0.0144 - val_rmse: 0.1201\n",
      "Epoch 61/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0139 - mape: 26.9415 - mse: 0.0139 - rmse: 0.1181 - val_loss: 0.0137 - val_mape: 27.2291 - val_mse: 0.0138 - val_rmse: 0.1172\n",
      "Epoch 62/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0139 - mape: 26.8289 - mse: 0.0139 - rmse: 0.1178 - val_loss: 0.0138 - val_mape: 27.6390 - val_mse: 0.0139 - val_rmse: 0.1176\n",
      "Epoch 63/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0138 - mape: 26.4652 - mse: 0.0138 - rmse: 0.1173 - val_loss: 0.0149 - val_mape: 26.7763 - val_mse: 0.0149 - val_rmse: 0.1221\n",
      "Epoch 64/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0138 - mape: 26.3742 - mse: 0.0138 - rmse: 0.1175 - val_loss: 0.0152 - val_mape: 30.1571 - val_mse: 0.0152 - val_rmse: 0.1232\n",
      "Epoch 65/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.6571 - mse: 0.0137 - rmse: 0.1171 - val_loss: 0.0143 - val_mape: 28.0985 - val_mse: 0.0143 - val_rmse: 0.1194\n",
      "Epoch 66/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.6251 - mse: 0.0137 - rmse: 0.1172 - val_loss: 0.0142 - val_mape: 29.0634 - val_mse: 0.0142 - val_rmse: 0.1190\n",
      "Epoch 67/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.2569 - mse: 0.0137 - rmse: 0.1171 - val_loss: 0.0144 - val_mape: 28.9753 - val_mse: 0.0144 - val_rmse: 0.1200\n",
      "Epoch 68/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0138 - mape: 26.7153 - mse: 0.0138 - rmse: 0.1176 - val_loss: 0.0143 - val_mape: 29.0714 - val_mse: 0.0144 - val_rmse: 0.1197\n",
      "Epoch 69/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0139 - mape: 26.6877 - mse: 0.0139 - rmse: 0.1178 - val_loss: 0.0148 - val_mape: 26.2532 - val_mse: 0.0149 - val_rmse: 0.1218\n",
      "Epoch 70/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.7280 - mse: 0.0137 - rmse: 0.1172 - val_loss: 0.0142 - val_mape: 28.1042 - val_mse: 0.0142 - val_rmse: 0.1190\n",
      "Epoch 71/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.1600 - mse: 0.0137 - rmse: 0.1170 - val_loss: 0.0144 - val_mape: 28.7478 - val_mse: 0.0144 - val_rmse: 0.1199\n",
      "Epoch 72/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0137 - mape: 26.7502 - mse: 0.0137 - rmse: 0.1171 - val_loss: 0.0164 - val_mape: 33.5722 - val_mse: 0.0164 - val_rmse: 0.1282\n",
      "Epoch 73/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0140 - mape: 26.8332 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0146 - val_mape: 25.3399 - val_mse: 0.0146 - val_rmse: 0.1210\n",
      "Epoch 74/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0135 - mape: 26.0010 - mse: 0.0135 - rmse: 0.1161 - val_loss: 0.0142 - val_mape: 26.5844 - val_mse: 0.0143 - val_rmse: 0.1193\n",
      "Epoch 75/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0136 - mape: 26.4380 - mse: 0.0136 - rmse: 0.1164 - val_loss: 0.0136 - val_mape: 27.6405 - val_mse: 0.0136 - val_rmse: 0.1167\n",
      "Epoch 76/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0132 - mape: 25.8612 - mse: 0.0132 - rmse: 0.1150 - val_loss: 0.0138 - val_mape: 27.8838 - val_mse: 0.0139 - val_rmse: 0.1176\n",
      "Epoch 77/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0133 - mape: 26.1002 - mse: 0.0133 - rmse: 0.1154 - val_loss: 0.0146 - val_mape: 31.6212 - val_mse: 0.0146 - val_rmse: 0.1207\n",
      "Epoch 78/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0136 - mape: 26.1309 - mse: 0.0136 - rmse: 0.1164 - val_loss: 0.0143 - val_mape: 28.4730 - val_mse: 0.0143 - val_rmse: 0.1196\n",
      "Epoch 79/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0134 - mape: 26.1131 - mse: 0.0134 - rmse: 0.1159 - val_loss: 0.0150 - val_mape: 29.8479 - val_mse: 0.0151 - val_rmse: 0.1227\n",
      "Epoch 80/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0135 - mape: 26.4104 - mse: 0.0135 - rmse: 0.1163 - val_loss: 0.0138 - val_mape: 26.6555 - val_mse: 0.0139 - val_rmse: 0.1177\n",
      "Epoch 81/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0134 - mape: 26.2928 - mse: 0.0134 - rmse: 0.1157 - val_loss: 0.0138 - val_mape: 26.8818 - val_mse: 0.0139 - val_rmse: 0.1176\n",
      "Epoch 82/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0133 - mape: 26.0110 - mse: 0.0133 - rmse: 0.1152 - val_loss: 0.0138 - val_mape: 26.9954 - val_mse: 0.0139 - val_rmse: 0.1176\n",
      "Epoch 83/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0134 - mape: 26.3328 - mse: 0.0134 - rmse: 0.1158 - val_loss: 0.0149 - val_mape: 27.3492 - val_mse: 0.0149 - val_rmse: 0.1221\n",
      "Epoch 84/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0135 - mape: 26.5046 - mse: 0.0135 - rmse: 0.1163 - val_loss: 0.0137 - val_mape: 27.9122 - val_mse: 0.0138 - val_rmse: 0.1172\n",
      "Epoch 85/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0132 - mape: 25.7003 - mse: 0.0132 - rmse: 0.1149 - val_loss: 0.0133 - val_mape: 24.9756 - val_mse: 0.0133 - val_rmse: 0.1154\n",
      "Epoch 86/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0132 - mape: 25.6963 - mse: 0.0132 - rmse: 0.1148 - val_loss: 0.0136 - val_mape: 28.2628 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 87/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0131 - mape: 25.7517 - mse: 0.0131 - rmse: 0.1143 - val_loss: 0.0145 - val_mape: 28.8412 - val_mse: 0.0145 - val_rmse: 0.1202\n",
      "Epoch 88/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0133 - mape: 25.9092 - mse: 0.0133 - rmse: 0.1152 - val_loss: 0.0136 - val_mape: 26.5306 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 89/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0130 - mape: 25.8007 - mse: 0.0130 - rmse: 0.1141 - val_loss: 0.0135 - val_mape: 27.1891 - val_mse: 0.0136 - val_rmse: 0.1164\n",
      "Epoch 90/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0128 - mape: 25.5285 - mse: 0.0128 - rmse: 0.1133 - val_loss: 0.0135 - val_mape: 26.3269 - val_mse: 0.0135 - val_rmse: 0.1162\n",
      "Epoch 91/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0131 - mape: 26.0342 - mse: 0.0131 - rmse: 0.1145 - val_loss: 0.0136 - val_mape: 25.1208 - val_mse: 0.0137 - val_rmse: 0.1168\n",
      "Epoch 92/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0129 - mape: 25.4155 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0139 - val_mape: 26.6877 - val_mse: 0.0139 - val_rmse: 0.1177\n",
      "Epoch 93/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0128 - mape: 25.4633 - mse: 0.0128 - rmse: 0.1133 - val_loss: 0.0143 - val_mape: 27.6758 - val_mse: 0.0143 - val_rmse: 0.1197\n",
      "Epoch 94/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0130 - mape: 25.8968 - mse: 0.0130 - rmse: 0.1142 - val_loss: 0.0133 - val_mape: 27.3947 - val_mse: 0.0134 - val_rmse: 0.1155\n",
      "Epoch 95/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0130 - mape: 25.6579 - mse: 0.0130 - rmse: 0.1141 - val_loss: 0.0138 - val_mape: 26.3694 - val_mse: 0.0138 - val_rmse: 0.1174\n",
      "Epoch 96/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0130 - mape: 25.7683 - mse: 0.0130 - rmse: 0.1142 - val_loss: 0.0143 - val_mape: 29.4036 - val_mse: 0.0143 - val_rmse: 0.1197\n",
      "Epoch 97/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0130 - mape: 25.7447 - mse: 0.0130 - rmse: 0.1141 - val_loss: 0.0142 - val_mape: 27.8765 - val_mse: 0.0142 - val_rmse: 0.1193\n",
      "Epoch 98/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0127 - mape: 25.2254 - mse: 0.0127 - rmse: 0.1128 - val_loss: 0.0135 - val_mape: 27.7071 - val_mse: 0.0135 - val_rmse: 0.1162\n",
      "Epoch 99/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0128 - mape: 25.5471 - mse: 0.0128 - rmse: 0.1131 - val_loss: 0.0136 - val_mape: 25.6812 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 100/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0127 - mape: 25.6058 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0134 - val_mape: 27.1216 - val_mse: 0.0134 - val_rmse: 0.1159\n",
      "Epoch 101/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0127 - mape: 25.3677 - mse: 0.0127 - rmse: 0.1126 - val_loss: 0.0134 - val_mape: 26.4281 - val_mse: 0.0134 - val_rmse: 0.1159\n",
      "Epoch 102/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0127 - mape: 25.6329 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0140 - val_mape: 28.0620 - val_mse: 0.0140 - val_rmse: 0.1184\n",
      "Epoch 103/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0129 - mape: 25.4892 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0135 - val_mape: 26.4953 - val_mse: 0.0135 - val_rmse: 0.1163\n",
      "Epoch 104/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0129 - mape: 25.3178 - mse: 0.0129 - rmse: 0.1137 - val_loss: 0.0133 - val_mape: 26.0287 - val_mse: 0.0133 - val_rmse: 0.1154\n",
      "Epoch 105/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0126 - mape: 25.3956 - mse: 0.0126 - rmse: 0.1124 - val_loss: 0.0132 - val_mape: 24.5999 - val_mse: 0.0132 - val_rmse: 0.1150\n",
      "Epoch 106/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0127 - mape: 25.1140 - mse: 0.0127 - rmse: 0.1126 - val_loss: 0.0135 - val_mape: 26.2714 - val_mse: 0.0135 - val_rmse: 0.1163\n",
      "Epoch 107/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0129 - mape: 25.9258 - mse: 0.0129 - rmse: 0.1136 - val_loss: 0.0137 - val_mape: 29.9955 - val_mse: 0.0137 - val_rmse: 0.1171\n",
      "Epoch 108/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0126 - mape: 25.2490 - mse: 0.0126 - rmse: 0.1121 - val_loss: 0.0135 - val_mape: 24.2198 - val_mse: 0.0135 - val_rmse: 0.1160\n",
      "Epoch 109/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0124 - mape: 25.0105 - mse: 0.0124 - rmse: 0.1115 - val_loss: 0.0135 - val_mape: 29.1614 - val_mse: 0.0135 - val_rmse: 0.1163\n",
      "Epoch 110/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0126 - mape: 25.4032 - mse: 0.0126 - rmse: 0.1121 - val_loss: 0.0139 - val_mape: 28.3789 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 111/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0123 - mape: 24.8647 - mse: 0.0123 - rmse: 0.1111 - val_loss: 0.0129 - val_mape: 23.6390 - val_mse: 0.0129 - val_rmse: 0.1135\n",
      "Epoch 112/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0123 - mape: 24.6152 - mse: 0.0123 - rmse: 0.1110 - val_loss: 0.0130 - val_mape: 24.0026 - val_mse: 0.0131 - val_rmse: 0.1142\n",
      "Epoch 113/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0124 - mape: 25.0544 - mse: 0.0124 - rmse: 0.1114 - val_loss: 0.0129 - val_mape: 25.7822 - val_mse: 0.0129 - val_rmse: 0.1136\n",
      "Epoch 114/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0124 - mape: 24.9485 - mse: 0.0124 - rmse: 0.1113 - val_loss: 0.0133 - val_mape: 28.2541 - val_mse: 0.0134 - val_rmse: 0.1155\n",
      "Epoch 115/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0124 - mape: 25.0700 - mse: 0.0124 - rmse: 0.1111 - val_loss: 0.0139 - val_mape: 28.2048 - val_mse: 0.0139 - val_rmse: 0.1180\n",
      "Epoch 116/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0125 - mape: 25.0772 - mse: 0.0125 - rmse: 0.1116 - val_loss: 0.0134 - val_mape: 26.1910 - val_mse: 0.0134 - val_rmse: 0.1158\n",
      "Epoch 117/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0122 - mape: 24.6620 - mse: 0.0122 - rmse: 0.1103 - val_loss: 0.0142 - val_mape: 28.1183 - val_mse: 0.0142 - val_rmse: 0.1192\n",
      "Epoch 118/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0124 - mape: 24.9111 - mse: 0.0124 - rmse: 0.1115 - val_loss: 0.0130 - val_mape: 25.0267 - val_mse: 0.0130 - val_rmse: 0.1138\n",
      "Epoch 119/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.6607 - mse: 0.0121 - rmse: 0.1102 - val_loss: 0.0130 - val_mape: 24.7544 - val_mse: 0.0130 - val_rmse: 0.1141\n",
      "Epoch 120/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0124 - mape: 25.0470 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0130 - val_mape: 26.5472 - val_mse: 0.0130 - val_rmse: 0.1138\n",
      "Epoch 121/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0122 - mape: 24.8501 - mse: 0.0122 - rmse: 0.1102 - val_loss: 0.0130 - val_mape: 25.7332 - val_mse: 0.0130 - val_rmse: 0.1139\n",
      "Epoch 122/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0122 - mape: 24.5920 - mse: 0.0122 - rmse: 0.1104 - val_loss: 0.0134 - val_mape: 27.6340 - val_mse: 0.0134 - val_rmse: 0.1159\n",
      "Epoch 123/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0123 - mape: 24.9619 - mse: 0.0123 - rmse: 0.1109 - val_loss: 0.0128 - val_mape: 26.5787 - val_mse: 0.0128 - val_rmse: 0.1131\n",
      "Epoch 124/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.6902 - mse: 0.0121 - rmse: 0.1102 - val_loss: 0.0138 - val_mape: 30.1829 - val_mse: 0.0138 - val_rmse: 0.1173\n",
      "Epoch 125/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.4988 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0127 - val_mape: 25.2639 - val_mse: 0.0127 - val_rmse: 0.1127\n",
      "Epoch 126/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.6691 - mse: 0.0121 - rmse: 0.1100 - val_loss: 0.0131 - val_mape: 28.5652 - val_mse: 0.0131 - val_rmse: 0.1144\n",
      "Epoch 127/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.7773 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0130 - val_mape: 25.0214 - val_mse: 0.0131 - val_rmse: 0.1142\n",
      "Epoch 128/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0122 - mape: 24.7808 - mse: 0.0122 - rmse: 0.1104 - val_loss: 0.0135 - val_mape: 29.5079 - val_mse: 0.0135 - val_rmse: 0.1161\n",
      "Epoch 129/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.6429 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0130 - val_mape: 24.4914 - val_mse: 0.0130 - val_rmse: 0.1141\n",
      "Epoch 130/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0121 - mape: 24.7043 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0129 - val_mape: 24.6367 - val_mse: 0.0129 - val_rmse: 0.1134\n",
      "Epoch 131/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0118 - mape: 24.1757 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0126 - val_mape: 24.6302 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 132/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0120 - mape: 24.3602 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0135 - val_mape: 23.8768 - val_mse: 0.0135 - val_rmse: 0.1162\n",
      "Epoch 133/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0119 - mape: 24.6274 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0130 - val_mape: 26.2572 - val_mse: 0.0130 - val_rmse: 0.1140\n",
      "Epoch 134/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0119 - mape: 24.6295 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0128 - val_mape: 26.2283 - val_mse: 0.0128 - val_rmse: 0.1133\n",
      "Epoch 135/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0118 - mape: 24.5062 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0130 - val_mape: 27.4791 - val_mse: 0.0130 - val_rmse: 0.1138\n",
      "Epoch 136/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0119 - mape: 24.8673 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0128 - val_mape: 25.6676 - val_mse: 0.0128 - val_rmse: 0.1130\n",
      "Epoch 137/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0118 - mape: 24.3484 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0136 - val_mape: 28.9957 - val_mse: 0.0136 - val_rmse: 0.1164\n",
      "Epoch 138/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0118 - mape: 24.3418 - mse: 0.0118 - rmse: 0.1084 - val_loss: 0.0130 - val_mape: 25.8616 - val_mse: 0.0130 - val_rmse: 0.1138\n",
      "Epoch 139/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0117 - mape: 24.6023 - mse: 0.0117 - rmse: 0.1080 - val_loss: 0.0130 - val_mape: 26.9019 - val_mse: 0.0130 - val_rmse: 0.1140\n",
      "Epoch 140/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0117 - mape: 24.5049 - mse: 0.0117 - rmse: 0.1083 - val_loss: 0.0130 - val_mape: 25.6885 - val_mse: 0.0130 - val_rmse: 0.1139\n",
      "Epoch 141/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0116 - mape: 24.3518 - mse: 0.0116 - rmse: 0.1078 - val_loss: 0.0131 - val_mape: 28.9585 - val_mse: 0.0131 - val_rmse: 0.1143\n",
      "Epoch 142/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0115 - mape: 24.2592 - mse: 0.0115 - rmse: 0.1072 - val_loss: 0.0133 - val_mape: 25.6927 - val_mse: 0.0133 - val_rmse: 0.1153\n",
      "Epoch 143/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0118 - mape: 24.4462 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0131 - val_mape: 30.2853 - val_mse: 0.0131 - val_rmse: 0.1143\n",
      "Epoch 144/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0117 - mape: 24.1969 - mse: 0.0117 - rmse: 0.1081 - val_loss: 0.0130 - val_mape: 28.5781 - val_mse: 0.0130 - val_rmse: 0.1140\n",
      "Epoch 145/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0117 - mape: 24.2182 - mse: 0.0117 - rmse: 0.1082 - val_loss: 0.0134 - val_mape: 28.3743 - val_mse: 0.0134 - val_rmse: 0.1156\n",
      "Epoch 146/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0118 - mape: 24.4433 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0134 - val_mape: 27.7576 - val_mse: 0.0134 - val_rmse: 0.1156\n",
      "Epoch 147/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0115 - mape: 24.0997 - mse: 0.0115 - rmse: 0.1074 - val_loss: 0.0129 - val_mape: 27.3091 - val_mse: 0.0129 - val_rmse: 0.1135\n",
      "Epoch 148/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0117 - mape: 24.3470 - mse: 0.0117 - rmse: 0.1081 - val_loss: 0.0129 - val_mape: 26.1448 - val_mse: 0.0130 - val_rmse: 0.1138\n",
      "Epoch 149/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0117 - mape: 24.1657 - mse: 0.0117 - rmse: 0.1080 - val_loss: 0.0130 - val_mape: 29.6259 - val_mse: 0.0131 - val_rmse: 0.1142\n",
      "Epoch 150/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0113 - mape: 24.0840 - mse: 0.0113 - rmse: 0.1064 - val_loss: 0.0128 - val_mape: 28.7677 - val_mse: 0.0128 - val_rmse: 0.1131\n",
      "Epoch 151/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0116 - mape: 24.4479 - mse: 0.0116 - rmse: 0.1077 - val_loss: 0.0127 - val_mape: 27.0691 - val_mse: 0.0127 - val_rmse: 0.1125\n",
      "PROCESANDO ARCHIVO: Abies spectabilis\n",
      "(96429, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Abies spectabilis_best_models.json\n",
      "(56618, 4, 43) (19637, 4, 43) (15689, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 28 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m27,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m61,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m3,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m57\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">403,157</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m403,157\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,385</span> (524.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,385\u001b[0m (524.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,772</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m268,772\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0165 - mape: 36.8963 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0143 - val_mape: 27.3316 - val_mse: 0.0143 - val_rmse: 0.1196\n",
      "Epoch 2/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0160 - mape: 34.5382 - mse: 0.0160 - rmse: 0.1266 - val_loss: 0.0144 - val_mape: 27.5637 - val_mse: 0.0144 - val_rmse: 0.1201\n",
      "Epoch 3/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0160 - mape: 34.3230 - mse: 0.0160 - rmse: 0.1264 - val_loss: 0.0144 - val_mape: 28.3214 - val_mse: 0.0144 - val_rmse: 0.1199\n",
      "Epoch 4/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0156 - mape: 33.9910 - mse: 0.0156 - rmse: 0.1248 - val_loss: 0.0145 - val_mape: 30.6239 - val_mse: 0.0145 - val_rmse: 0.1205\n",
      "Epoch 5/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0156 - mape: 34.0574 - mse: 0.0156 - rmse: 0.1248 - val_loss: 0.0141 - val_mape: 26.5224 - val_mse: 0.0141 - val_rmse: 0.1189\n",
      "Epoch 6/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0156 - mape: 34.3126 - mse: 0.0156 - rmse: 0.1250 - val_loss: 0.0139 - val_mape: 28.7510 - val_mse: 0.0139 - val_rmse: 0.1180\n",
      "Epoch 7/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0153 - mape: 33.4467 - mse: 0.0153 - rmse: 0.1237 - val_loss: 0.0140 - val_mape: 28.7418 - val_mse: 0.0140 - val_rmse: 0.1183\n",
      "Epoch 8/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0153 - mape: 33.8404 - mse: 0.0153 - rmse: 0.1237 - val_loss: 0.0141 - val_mape: 27.2718 - val_mse: 0.0141 - val_rmse: 0.1188\n",
      "Epoch 9/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0152 - mape: 32.6779 - mse: 0.0152 - rmse: 0.1231 - val_loss: 0.0138 - val_mape: 29.8680 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 10/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0151 - mape: 33.1072 - mse: 0.0151 - rmse: 0.1228 - val_loss: 0.0140 - val_mape: 29.2465 - val_mse: 0.0140 - val_rmse: 0.1183\n",
      "Epoch 11/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0152 - mape: 32.9390 - mse: 0.0152 - rmse: 0.1231 - val_loss: 0.0138 - val_mape: 26.3978 - val_mse: 0.0138 - val_rmse: 0.1174\n",
      "Epoch 12/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0150 - mape: 32.6183 - mse: 0.0150 - rmse: 0.1223 - val_loss: 0.0140 - val_mape: 26.0273 - val_mse: 0.0139 - val_rmse: 0.1181\n",
      "Epoch 13/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0151 - mape: 32.9140 - mse: 0.0151 - rmse: 0.1228 - val_loss: 0.0142 - val_mape: 25.7842 - val_mse: 0.0142 - val_rmse: 0.1190\n",
      "Epoch 14/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0150 - mape: 32.6042 - mse: 0.0150 - rmse: 0.1224 - val_loss: 0.0142 - val_mape: 24.9445 - val_mse: 0.0142 - val_rmse: 0.1192\n",
      "Epoch 15/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0149 - mape: 32.2251 - mse: 0.0149 - rmse: 0.1222 - val_loss: 0.0140 - val_mape: 31.1215 - val_mse: 0.0140 - val_rmse: 0.1184\n",
      "Epoch 16/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0149 - mape: 32.7073 - mse: 0.0149 - rmse: 0.1219 - val_loss: 0.0136 - val_mape: 25.9089 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 17/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0149 - mape: 32.3005 - mse: 0.0149 - rmse: 0.1220 - val_loss: 0.0141 - val_mape: 28.8749 - val_mse: 0.0141 - val_rmse: 0.1189\n",
      "Epoch 18/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0147 - mape: 31.8149 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0140 - val_mape: 29.2523 - val_mse: 0.0140 - val_rmse: 0.1183\n",
      "Epoch 19/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0147 - mape: 31.7737 - mse: 0.0147 - rmse: 0.1212 - val_loss: 0.0136 - val_mape: 25.3655 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 20/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0148 - mape: 31.9858 - mse: 0.0148 - rmse: 0.1218 - val_loss: 0.0145 - val_mape: 24.5655 - val_mse: 0.0145 - val_rmse: 0.1206\n",
      "Epoch 21/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0148 - mape: 31.9215 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0141 - val_mape: 27.5707 - val_mse: 0.0141 - val_rmse: 0.1189\n",
      "Epoch 22/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0149 - mape: 32.1743 - mse: 0.0149 - rmse: 0.1218 - val_loss: 0.0141 - val_mape: 29.5465 - val_mse: 0.0141 - val_rmse: 0.1188\n",
      "Epoch 23/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0148 - mape: 32.0864 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0135 - val_mape: 26.9197 - val_mse: 0.0135 - val_rmse: 0.1163\n",
      "Epoch 24/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0148 - mape: 32.2713 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0139 - val_mape: 28.3422 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 25/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0147 - mape: 31.9181 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0138 - val_mape: 26.7244 - val_mse: 0.0138 - val_rmse: 0.1173\n",
      "Epoch 26/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0147 - mape: 31.9986 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0137 - val_mape: 26.9992 - val_mse: 0.0137 - val_rmse: 0.1173\n",
      "Epoch 27/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0148 - mape: 31.9782 - mse: 0.0148 - rmse: 0.1215 - val_loss: 0.0138 - val_mape: 28.2293 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 28/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0146 - mape: 31.2944 - mse: 0.0146 - rmse: 0.1207 - val_loss: 0.0136 - val_mape: 27.2812 - val_mse: 0.0136 - val_rmse: 0.1165\n",
      "Epoch 29/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.6456 - mse: 0.0145 - rmse: 0.1206 - val_loss: 0.0136 - val_mape: 27.2843 - val_mse: 0.0136 - val_rmse: 0.1167\n",
      "Epoch 30/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.3148 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0135 - val_mape: 24.6604 - val_mse: 0.0135 - val_rmse: 0.1163\n",
      "Epoch 31/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0146 - mape: 31.5629 - mse: 0.0146 - rmse: 0.1206 - val_loss: 0.0137 - val_mape: 26.9975 - val_mse: 0.0137 - val_rmse: 0.1170\n",
      "Epoch 32/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.6050 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0138 - val_mape: 26.4148 - val_mse: 0.0138 - val_rmse: 0.1174\n",
      "Epoch 33/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.6045 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0141 - val_mape: 24.7342 - val_mse: 0.0140 - val_rmse: 0.1185\n",
      "Epoch 34/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.4490 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0146 - val_mape: 33.2364 - val_mse: 0.0146 - val_rmse: 0.1207\n",
      "Epoch 35/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0147 - mape: 31.5354 - mse: 0.0147 - rmse: 0.1211 - val_loss: 0.0137 - val_mape: 26.4036 - val_mse: 0.0137 - val_rmse: 0.1172\n",
      "Epoch 36/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.3406 - mse: 0.0145 - rmse: 0.1206 - val_loss: 0.0138 - val_mape: 24.7187 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 37/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.3482 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0136 - val_mape: 26.0341 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 38/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0144 - mape: 31.4246 - mse: 0.0144 - rmse: 0.1202 - val_loss: 0.0138 - val_mape: 25.2573 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 39/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.2644 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0141 - val_mape: 25.3566 - val_mse: 0.0141 - val_rmse: 0.1189\n",
      "Epoch 40/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0145 - mape: 31.2931 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0134 - val_mape: 24.7503 - val_mse: 0.0134 - val_rmse: 0.1156\n",
      "Epoch 41/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.0655 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0137 - val_mape: 23.9971 - val_mse: 0.0137 - val_rmse: 0.1172\n",
      "Epoch 42/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0142 - mape: 30.7599 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0141 - val_mape: 27.8461 - val_mse: 0.0141 - val_rmse: 0.1189\n",
      "Epoch 43/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0144 - mape: 31.5574 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0133 - val_mape: 26.1049 - val_mse: 0.0133 - val_rmse: 0.1151\n",
      "Epoch 44/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.3971 - mse: 0.0143 - rmse: 0.1198 - val_loss: 0.0136 - val_mape: 25.5885 - val_mse: 0.0136 - val_rmse: 0.1165\n",
      "Epoch 45/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.2438 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0135 - val_mape: 28.2857 - val_mse: 0.0135 - val_rmse: 0.1162\n",
      "Epoch 46/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.2195 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0137 - val_mape: 24.0902 - val_mse: 0.0137 - val_rmse: 0.1172\n",
      "Epoch 47/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.0800 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0136 - val_mape: 25.6535 - val_mse: 0.0136 - val_rmse: 0.1166\n",
      "Epoch 48/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.2115 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0133 - val_mape: 25.0113 - val_mse: 0.0133 - val_rmse: 0.1153\n",
      "Epoch 49/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0141 - mape: 31.0659 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0140 - val_mape: 24.3248 - val_mse: 0.0140 - val_rmse: 0.1184\n",
      "Epoch 50/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 30.8444 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0137 - val_mape: 25.1505 - val_mse: 0.0137 - val_rmse: 0.1170\n",
      "Epoch 51/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0141 - mape: 31.1320 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0137 - val_mape: 27.0404 - val_mse: 0.0137 - val_rmse: 0.1169\n",
      "Epoch 52/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0141 - mape: 30.8838 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0133 - val_mape: 25.0935 - val_mse: 0.0133 - val_rmse: 0.1153\n",
      "Epoch 53/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - loss: 0.0141 - mape: 30.7636 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0134 - val_mape: 25.7811 - val_mse: 0.0134 - val_rmse: 0.1157\n",
      "Epoch 54/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0142 - mape: 31.0420 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0131 - val_mape: 28.0470 - val_mse: 0.0131 - val_rmse: 0.1145\n",
      "Epoch 55/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 0.0140 - mape: 30.8182 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0135 - val_mape: 27.7510 - val_mse: 0.0135 - val_rmse: 0.1161\n",
      "Epoch 56/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0142 - mape: 31.3343 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0134 - val_mape: 24.8705 - val_mse: 0.0134 - val_rmse: 0.1159\n",
      "Epoch 57/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0141 - mape: 30.7774 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0141 - val_mape: 24.9940 - val_mse: 0.0141 - val_rmse: 0.1187\n",
      "Epoch 58/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0142 - mape: 31.1017 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0132 - val_mape: 24.6308 - val_mse: 0.0132 - val_rmse: 0.1149\n",
      "Epoch 59/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0140 - mape: 30.8137 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0134 - val_mape: 25.9710 - val_mse: 0.0134 - val_rmse: 0.1158\n",
      "Epoch 60/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0140 - mape: 30.9554 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0137 - val_mape: 24.7376 - val_mse: 0.0137 - val_rmse: 0.1169\n",
      "Epoch 61/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0140 - mape: 31.1437 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0136 - val_mape: 25.0002 - val_mse: 0.0136 - val_rmse: 0.1167\n",
      "Epoch 62/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0139 - mape: 30.6251 - mse: 0.0139 - rmse: 0.1181 - val_loss: 0.0133 - val_mape: 26.3518 - val_mse: 0.0133 - val_rmse: 0.1152\n",
      "Epoch 63/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 0.0143 - mape: 31.3984 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0136 - val_mape: 26.4499 - val_mse: 0.0136 - val_rmse: 0.1165\n",
      "Epoch 64/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - loss: 0.0139 - mape: 30.5737 - mse: 0.0139 - rmse: 0.1179 - val_loss: 0.0140 - val_mape: 27.6166 - val_mse: 0.0140 - val_rmse: 0.1183\n",
      "Epoch 65/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0140 - mape: 30.4255 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0133 - val_mape: 24.8352 - val_mse: 0.0133 - val_rmse: 0.1154\n",
      "Epoch 66/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0139 - mape: 30.3473 - mse: 0.0139 - rmse: 0.1180 - val_loss: 0.0143 - val_mape: 28.6535 - val_mse: 0.0143 - val_rmse: 0.1195\n",
      "Epoch 67/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0140 - mape: 30.6691 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0135 - val_mape: 24.6557 - val_mse: 0.0135 - val_rmse: 0.1160\n",
      "Epoch 68/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - loss: 0.0139 - mape: 30.6123 - mse: 0.0139 - rmse: 0.1180 - val_loss: 0.0136 - val_mape: 25.8212 - val_mse: 0.0136 - val_rmse: 0.1167\n",
      "Epoch 69/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - loss: 0.0140 - mape: 30.7661 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0136 - val_mape: 25.1387 - val_mse: 0.0135 - val_rmse: 0.1164\n",
      "Epoch 70/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0144 - mape: 31.5009 - mse: 0.0144 - rmse: 0.1198 - val_loss: 0.0139 - val_mape: 24.9732 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 71/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0139 - mape: 30.5395 - mse: 0.0139 - rmse: 0.1178 - val_loss: 0.0143 - val_mape: 26.4659 - val_mse: 0.0143 - val_rmse: 0.1197\n",
      "Epoch 72/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0143 - mape: 31.7824 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0152 - val_mape: 26.4762 - val_mse: 0.0152 - val_rmse: 0.1235\n",
      "Epoch 73/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0139 - mape: 30.3541 - mse: 0.0139 - rmse: 0.1177 - val_loss: 0.0132 - val_mape: 26.0591 - val_mse: 0.0132 - val_rmse: 0.1149\n",
      "Epoch 74/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 0.0139 - mape: 30.6649 - mse: 0.0139 - rmse: 0.1179 - val_loss: 0.0143 - val_mape: 25.9863 - val_mse: 0.0143 - val_rmse: 0.1197\n",
      "PROCESANDO ARCHIVO: Juniperus excelsa M.-Bieb\n",
      "(7449, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus excelsa M.-Bieb_best_models.json\n",
      "(4189, 4, 43) (1707, 4, 43) (1228, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 28 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m27,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m61,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m3,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m57\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">403,157</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m403,157\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,385</span> (524.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,385\u001b[0m (524.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,772</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m268,772\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0176 - mape: 42.7172 - mse: 0.0176 - rmse: 0.1325 - val_loss: 0.0145 - val_mape: 45.3935 - val_mse: 0.0146 - val_rmse: 0.1205\n",
      "Epoch 2/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - mape: 40.1453 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0135 - val_mape: 38.9200 - val_mse: 0.0135 - val_rmse: 0.1160\n",
      "Epoch 3/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mape: 39.5526 - mse: 0.0163 - rmse: 0.1277 - val_loss: 0.0134 - val_mape: 39.8760 - val_mse: 0.0134 - val_rmse: 0.1157\n",
      "Epoch 4/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mape: 39.3317 - mse: 0.0163 - rmse: 0.1274 - val_loss: 0.0134 - val_mape: 39.7914 - val_mse: 0.0134 - val_rmse: 0.1156\n",
      "Epoch 5/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - mape: 39.1468 - mse: 0.0160 - rmse: 0.1263 - val_loss: 0.0136 - val_mape: 40.1740 - val_mse: 0.0136 - val_rmse: 0.1167\n",
      "Epoch 6/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0158 - mape: 38.5053 - mse: 0.0158 - rmse: 0.1257 - val_loss: 0.0132 - val_mape: 38.1977 - val_mse: 0.0132 - val_rmse: 0.1148\n",
      "Epoch 7/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mape: 37.5791 - mse: 0.0154 - rmse: 0.1241 - val_loss: 0.0132 - val_mape: 38.2424 - val_mse: 0.0133 - val_rmse: 0.1150\n",
      "Epoch 8/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mape: 38.7053 - mse: 0.0157 - rmse: 0.1250 - val_loss: 0.0134 - val_mape: 39.9855 - val_mse: 0.0134 - val_rmse: 0.1156\n",
      "Epoch 9/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mape: 38.1539 - mse: 0.0155 - rmse: 0.1246 - val_loss: 0.0137 - val_mape: 42.0993 - val_mse: 0.0137 - val_rmse: 0.1170\n",
      "Epoch 10/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mape: 38.2162 - mse: 0.0155 - rmse: 0.1244 - val_loss: 0.0132 - val_mape: 39.0426 - val_mse: 0.0132 - val_rmse: 0.1147\n",
      "Epoch 11/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mape: 37.6726 - mse: 0.0155 - rmse: 0.1244 - val_loss: 0.0125 - val_mape: 36.0583 - val_mse: 0.0126 - val_rmse: 0.1120\n",
      "Epoch 12/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mape: 36.9169 - mse: 0.0154 - rmse: 0.1240 - val_loss: 0.0127 - val_mape: 35.7592 - val_mse: 0.0128 - val_rmse: 0.1129\n",
      "Epoch 13/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mape: 36.9155 - mse: 0.0151 - rmse: 0.1227 - val_loss: 0.0132 - val_mape: 37.9051 - val_mse: 0.0132 - val_rmse: 0.1147\n",
      "Epoch 14/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mape: 37.7496 - mse: 0.0154 - rmse: 0.1241 - val_loss: 0.0126 - val_mape: 35.0177 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 15/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mape: 36.4111 - mse: 0.0147 - rmse: 0.1211 - val_loss: 0.0130 - val_mape: 38.3460 - val_mse: 0.0130 - val_rmse: 0.1141\n",
      "Epoch 16/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - mape: 37.3024 - mse: 0.0148 - rmse: 0.1214 - val_loss: 0.0127 - val_mape: 39.0688 - val_mse: 0.0127 - val_rmse: 0.1127\n",
      "Epoch 17/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mape: 36.8958 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0124 - val_mape: 36.7682 - val_mse: 0.0124 - val_rmse: 0.1113\n",
      "Epoch 18/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0145 - mape: 36.0325 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0126 - val_mape: 37.4368 - val_mse: 0.0127 - val_rmse: 0.1124\n",
      "Epoch 19/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mape: 36.9637 - mse: 0.0146 - rmse: 0.1208 - val_loss: 0.0125 - val_mape: 38.7754 - val_mse: 0.0125 - val_rmse: 0.1116\n",
      "Epoch 20/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0146 - mape: 37.3076 - mse: 0.0146 - rmse: 0.1208 - val_loss: 0.0124 - val_mape: 36.1813 - val_mse: 0.0124 - val_rmse: 0.1113\n",
      "Epoch 21/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - mape: 36.9877 - mse: 0.0148 - rmse: 0.1215 - val_loss: 0.0127 - val_mape: 38.4104 - val_mse: 0.0127 - val_rmse: 0.1127\n",
      "Epoch 22/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0145 - mape: 36.6264 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0131 - val_mape: 40.6136 - val_mse: 0.0132 - val_rmse: 0.1145\n",
      "Epoch 23/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0142 - mape: 36.5863 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0124 - val_mape: 35.7397 - val_mse: 0.0125 - val_rmse: 0.1115\n",
      "Epoch 24/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0139 - mape: 35.6363 - mse: 0.0139 - rmse: 0.1178 - val_loss: 0.0122 - val_mape: 35.1195 - val_mse: 0.0122 - val_rmse: 0.1104\n",
      "Epoch 25/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mape: 36.3514 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0128 - val_mape: 37.1392 - val_mse: 0.0128 - val_rmse: 0.1130\n",
      "Epoch 26/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mape: 36.5651 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0124 - val_mape: 36.3436 - val_mse: 0.0124 - val_rmse: 0.1112\n",
      "Epoch 27/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0142 - mape: 36.7042 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0120 - val_mape: 33.6316 - val_mse: 0.0120 - val_rmse: 0.1095\n",
      "Epoch 28/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mape: 36.6803 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0127 - val_mape: 37.6133 - val_mse: 0.0128 - val_rmse: 0.1128\n",
      "Epoch 29/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0143 - mape: 37.4704 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0124 - val_mape: 35.7867 - val_mse: 0.0125 - val_rmse: 0.1115\n",
      "Epoch 30/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mape: 35.8004 - mse: 0.0137 - rmse: 0.1171 - val_loss: 0.0122 - val_mape: 35.4594 - val_mse: 0.0123 - val_rmse: 0.1105\n",
      "Epoch 31/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0144 - mape: 36.4914 - mse: 0.0144 - rmse: 0.1199 - val_loss: 0.0123 - val_mape: 37.0167 - val_mse: 0.0123 - val_rmse: 0.1107\n",
      "Epoch 32/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mape: 35.5044 - mse: 0.0137 - rmse: 0.1171 - val_loss: 0.0127 - val_mape: 39.2608 - val_mse: 0.0127 - val_rmse: 0.1127\n",
      "Epoch 33/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0136 - mape: 35.3965 - mse: 0.0136 - rmse: 0.1167 - val_loss: 0.0124 - val_mape: 37.4758 - val_mse: 0.0125 - val_rmse: 0.1114\n",
      "Epoch 34/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mape: 36.3437 - mse: 0.0137 - rmse: 0.1170 - val_loss: 0.0123 - val_mape: 34.2821 - val_mse: 0.0123 - val_rmse: 0.1108\n",
      "Epoch 35/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mape: 36.4950 - mse: 0.0137 - rmse: 0.1169 - val_loss: 0.0123 - val_mape: 34.0694 - val_mse: 0.0124 - val_rmse: 0.1110\n",
      "Epoch 36/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mape: 36.4829 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0121 - val_mape: 35.1097 - val_mse: 0.0122 - val_rmse: 0.1100\n",
      "Epoch 37/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mape: 35.9118 - mse: 0.0135 - rmse: 0.1160 - val_loss: 0.0121 - val_mape: 33.0085 - val_mse: 0.0121 - val_rmse: 0.1100\n",
      "Epoch 38/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mape: 35.3845 - mse: 0.0132 - rmse: 0.1148 - val_loss: 0.0124 - val_mape: 35.6718 - val_mse: 0.0124 - val_rmse: 0.1112\n",
      "Epoch 39/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mape: 34.2337 - mse: 0.0128 - rmse: 0.1131 - val_loss: 0.0119 - val_mape: 34.4299 - val_mse: 0.0120 - val_rmse: 0.1093\n",
      "Epoch 40/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mape: 35.4291 - mse: 0.0133 - rmse: 0.1154 - val_loss: 0.0125 - val_mape: 36.4733 - val_mse: 0.0126 - val_rmse: 0.1119\n",
      "Epoch 41/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0136 - mape: 36.4979 - mse: 0.0136 - rmse: 0.1166 - val_loss: 0.0120 - val_mape: 34.1702 - val_mse: 0.0121 - val_rmse: 0.1096\n",
      "Epoch 42/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mape: 35.7879 - mse: 0.0133 - rmse: 0.1152 - val_loss: 0.0122 - val_mape: 34.4307 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 43/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mape: 34.9814 - mse: 0.0133 - rmse: 0.1153 - val_loss: 0.0121 - val_mape: 34.4484 - val_mse: 0.0122 - val_rmse: 0.1101\n",
      "Epoch 44/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130 - mape: 33.8646 - mse: 0.0130 - rmse: 0.1140 - val_loss: 0.0121 - val_mape: 33.7949 - val_mse: 0.0121 - val_rmse: 0.1099\n",
      "Epoch 45/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mape: 35.1153 - mse: 0.0132 - rmse: 0.1148 - val_loss: 0.0120 - val_mape: 35.8331 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 46/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mape: 34.8560 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0123 - val_mape: 34.2385 - val_mse: 0.0124 - val_rmse: 0.1110\n",
      "Epoch 47/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0131 - mape: 35.0146 - mse: 0.0131 - rmse: 0.1144 - val_loss: 0.0121 - val_mape: 32.9883 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 48/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mape: 34.4914 - mse: 0.0128 - rmse: 0.1132 - val_loss: 0.0126 - val_mape: 36.9551 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 49/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mape: 35.3732 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0119 - val_mape: 33.7293 - val_mse: 0.0120 - val_rmse: 0.1093\n",
      "Epoch 50/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mape: 34.3570 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0120 - val_mape: 32.8699 - val_mse: 0.0120 - val_rmse: 0.1093\n",
      "Epoch 51/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mape: 34.3112 - mse: 0.0127 - rmse: 0.1128 - val_loss: 0.0124 - val_mape: 34.9381 - val_mse: 0.0124 - val_rmse: 0.1113\n",
      "Epoch 52/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0125 - mape: 34.1257 - mse: 0.0125 - rmse: 0.1118 - val_loss: 0.0127 - val_mape: 36.9418 - val_mse: 0.0128 - val_rmse: 0.1128\n",
      "Epoch 53/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mape: 34.3815 - mse: 0.0128 - rmse: 0.1129 - val_loss: 0.0123 - val_mape: 35.3059 - val_mse: 0.0124 - val_rmse: 0.1111\n",
      "Epoch 54/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mape: 34.7221 - mse: 0.0126 - rmse: 0.1123 - val_loss: 0.0121 - val_mape: 34.3451 - val_mse: 0.0122 - val_rmse: 0.1101\n",
      "Epoch 55/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mape: 34.9095 - mse: 0.0126 - rmse: 0.1124 - val_loss: 0.0121 - val_mape: 35.0620 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 56/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0119 - mape: 33.7521 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0122 - val_mape: 36.3444 - val_mse: 0.0122 - val_rmse: 0.1104\n",
      "Epoch 57/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0123 - mape: 34.0958 - mse: 0.0123 - rmse: 0.1108 - val_loss: 0.0122 - val_mape: 34.7290 - val_mse: 0.0122 - val_rmse: 0.1104\n",
      "Epoch 58/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mape: 34.7143 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0122 - val_mape: 36.2576 - val_mse: 0.0123 - val_rmse: 0.1106\n",
      "Epoch 59/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mape: 34.1094 - mse: 0.0129 - rmse: 0.1136 - val_loss: 0.0123 - val_mape: 34.2747 - val_mse: 0.0123 - val_rmse: 0.1107\n",
      "Epoch 60/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mape: 34.5985 - mse: 0.0132 - rmse: 0.1148 - val_loss: 0.0124 - val_mape: 36.3111 - val_mse: 0.0124 - val_rmse: 0.1114\n",
      "Epoch 61/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0131 - mape: 35.0421 - mse: 0.0131 - rmse: 0.1146 - val_loss: 0.0129 - val_mape: 39.8655 - val_mse: 0.0129 - val_rmse: 0.1135\n",
      "Epoch 62/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130 - mape: 35.4662 - mse: 0.0130 - rmse: 0.1139 - val_loss: 0.0126 - val_mape: 36.4312 - val_mse: 0.0127 - val_rmse: 0.1124\n",
      "Epoch 63/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mape: 34.5984 - mse: 0.0128 - rmse: 0.1132 - val_loss: 0.0130 - val_mape: 39.2156 - val_mse: 0.0130 - val_rmse: 0.1139\n",
      "Epoch 64/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mape: 34.7813 - mse: 0.0128 - rmse: 0.1131 - val_loss: 0.0128 - val_mape: 39.1420 - val_mse: 0.0129 - val_rmse: 0.1133\n",
      "Epoch 65/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mape: 34.4415 - mse: 0.0126 - rmse: 0.1121 - val_loss: 0.0123 - val_mape: 33.9296 - val_mse: 0.0123 - val_rmse: 0.1107\n",
      "Epoch 66/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - mape: 33.2859 - mse: 0.0124 - rmse: 0.1114 - val_loss: 0.0128 - val_mape: 37.6616 - val_mse: 0.0128 - val_rmse: 0.1131\n",
      "Epoch 67/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mape: 34.6849 - mse: 0.0127 - rmse: 0.1128 - val_loss: 0.0123 - val_mape: 34.3550 - val_mse: 0.0123 - val_rmse: 0.1108\n",
      "Epoch 68/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - mape: 34.2315 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0123 - val_mape: 34.9962 - val_mse: 0.0123 - val_rmse: 0.1109\n",
      "Epoch 69/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0121 - mape: 33.0343 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0125 - val_mape: 35.2867 - val_mse: 0.0125 - val_rmse: 0.1118\n",
      "PROCESANDO ARCHIVO: Cedrus deodara\n",
      "(37273, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Cedrus deodara_best_models.json\n",
      "(22017, 4, 43) (7410, 4, 43) (6282, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,644</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m88,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m20,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │         \u001b[38;5;34m4,644\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">810,077</span> (3.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m810,077\u001b[0m (3.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">270,025</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m270,025\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">540,052</span> (2.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m540,052\u001b[0m (2.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0214 - mape: 43.8878 - mse: 0.0214 - rmse: 0.1464 - val_loss: 0.0204 - val_mape: 43.9508 - val_mse: 0.0204 - val_rmse: 0.1427\n",
      "Epoch 2/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0209 - mape: 43.3823 - mse: 0.0209 - rmse: 0.1447 - val_loss: 0.0205 - val_mape: 44.2630 - val_mse: 0.0205 - val_rmse: 0.1431\n",
      "Epoch 3/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0208 - mape: 42.7699 - mse: 0.0208 - rmse: 0.1444 - val_loss: 0.0222 - val_mape: 50.2071 - val_mse: 0.0222 - val_rmse: 0.1489\n",
      "Epoch 4/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0208 - mape: 43.4250 - mse: 0.0208 - rmse: 0.1443 - val_loss: 0.0223 - val_mape: 51.3506 - val_mse: 0.0223 - val_rmse: 0.1492\n",
      "Epoch 5/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 42.5475 - mse: 0.0205 - rmse: 0.1431 - val_loss: 0.0197 - val_mape: 43.3738 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 6/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 42.8500 - mse: 0.0205 - rmse: 0.1432 - val_loss: 0.0204 - val_mape: 45.8750 - val_mse: 0.0204 - val_rmse: 0.1428\n",
      "Epoch 7/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0206 - mape: 43.0385 - mse: 0.0206 - rmse: 0.1435 - val_loss: 0.0218 - val_mape: 46.0265 - val_mse: 0.0218 - val_rmse: 0.1476\n",
      "Epoch 8/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0204 - mape: 42.4773 - mse: 0.0204 - rmse: 0.1428 - val_loss: 0.0259 - val_mape: 56.3159 - val_mse: 0.0258 - val_rmse: 0.1608\n",
      "Epoch 9/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0207 - mape: 43.1478 - mse: 0.0207 - rmse: 0.1438 - val_loss: 0.0202 - val_mape: 45.2687 - val_mse: 0.0201 - val_rmse: 0.1420\n",
      "Epoch 10/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0203 - mape: 42.8492 - mse: 0.0203 - rmse: 0.1426 - val_loss: 0.0236 - val_mape: 51.1662 - val_mse: 0.0236 - val_rmse: 0.1535\n",
      "Epoch 11/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0208 - mape: 43.0894 - mse: 0.0208 - rmse: 0.1443 - val_loss: 0.0206 - val_mape: 46.2584 - val_mse: 0.0206 - val_rmse: 0.1435\n",
      "Epoch 12/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0203 - mape: 42.3062 - mse: 0.0203 - rmse: 0.1425 - val_loss: 0.0229 - val_mape: 50.7481 - val_mse: 0.0229 - val_rmse: 0.1514\n",
      "Epoch 13/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 42.7123 - mse: 0.0205 - rmse: 0.1433 - val_loss: 0.0231 - val_mape: 49.7898 - val_mse: 0.0230 - val_rmse: 0.1519\n",
      "Epoch 14/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0204 - mape: 42.5862 - mse: 0.0204 - rmse: 0.1428 - val_loss: 0.0228 - val_mape: 49.4103 - val_mse: 0.0228 - val_rmse: 0.1511\n",
      "Epoch 15/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0204 - mape: 42.1611 - mse: 0.0204 - rmse: 0.1429 - val_loss: 0.0226 - val_mape: 51.5697 - val_mse: 0.0226 - val_rmse: 0.1504\n",
      "Epoch 16/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 42.9298 - mse: 0.0205 - rmse: 0.1430 - val_loss: 0.0226 - val_mape: 51.4941 - val_mse: 0.0226 - val_rmse: 0.1504\n",
      "Epoch 17/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 43.3153 - mse: 0.0205 - rmse: 0.1432 - val_loss: 0.0232 - val_mape: 52.4779 - val_mse: 0.0232 - val_rmse: 0.1524\n",
      "Epoch 18/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0204 - mape: 42.5048 - mse: 0.0204 - rmse: 0.1430 - val_loss: 0.0230 - val_mape: 49.4293 - val_mse: 0.0230 - val_rmse: 0.1515\n",
      "Epoch 19/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 43.1786 - mse: 0.0205 - rmse: 0.1432 - val_loss: 0.0205 - val_mape: 45.2830 - val_mse: 0.0205 - val_rmse: 0.1431\n",
      "Epoch 20/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0206 - mape: 42.7347 - mse: 0.0206 - rmse: 0.1436 - val_loss: 0.0224 - val_mape: 46.3655 - val_mse: 0.0224 - val_rmse: 0.1496\n",
      "Epoch 21/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0210 - mape: 43.0076 - mse: 0.0210 - rmse: 0.1449 - val_loss: 0.0204 - val_mape: 45.3916 - val_mse: 0.0204 - val_rmse: 0.1428\n",
      "Epoch 22/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 41.9641 - mse: 0.0201 - rmse: 0.1418 - val_loss: 0.0214 - val_mape: 49.7846 - val_mse: 0.0214 - val_rmse: 0.1462\n",
      "Epoch 23/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0205 - mape: 42.6705 - mse: 0.0205 - rmse: 0.1430 - val_loss: 0.0192 - val_mape: 42.1888 - val_mse: 0.0191 - val_rmse: 0.1384\n",
      "Epoch 24/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 42.2618 - mse: 0.0201 - rmse: 0.1418 - val_loss: 0.0206 - val_mape: 44.7820 - val_mse: 0.0206 - val_rmse: 0.1436\n",
      "Epoch 25/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0207 - mape: 43.6354 - mse: 0.0207 - rmse: 0.1440 - val_loss: 0.0197 - val_mape: 44.0494 - val_mse: 0.0197 - val_rmse: 0.1404\n",
      "Epoch 26/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0206 - mape: 43.4214 - mse: 0.0206 - rmse: 0.1436 - val_loss: 0.0224 - val_mape: 49.1818 - val_mse: 0.0224 - val_rmse: 0.1498\n",
      "Epoch 27/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0202 - mape: 41.8691 - mse: 0.0202 - rmse: 0.1420 - val_loss: 0.0196 - val_mape: 44.0403 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 28/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0202 - mape: 42.5435 - mse: 0.0202 - rmse: 0.1420 - val_loss: 0.0195 - val_mape: 44.3389 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 29/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 42.4651 - mse: 0.0200 - rmse: 0.1415 - val_loss: 0.0189 - val_mape: 39.9967 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 30/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 42.4146 - mse: 0.0201 - rmse: 0.1416 - val_loss: 0.0191 - val_mape: 42.2359 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 31/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 42.4468 - mse: 0.0200 - rmse: 0.1414 - val_loss: 0.0191 - val_mape: 42.3904 - val_mse: 0.0190 - val_rmse: 0.1380\n",
      "Epoch 32/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0205 - mape: 42.7088 - mse: 0.0205 - rmse: 0.1430 - val_loss: 0.0207 - val_mape: 47.0725 - val_mse: 0.0207 - val_rmse: 0.1438\n",
      "Epoch 33/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 42.1065 - mse: 0.0201 - rmse: 0.1419 - val_loss: 0.0200 - val_mape: 40.7263 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 34/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 42.0308 - mse: 0.0201 - rmse: 0.1418 - val_loss: 0.0210 - val_mape: 47.7057 - val_mse: 0.0210 - val_rmse: 0.1448\n",
      "Epoch 35/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 41.9742 - mse: 0.0200 - rmse: 0.1414 - val_loss: 0.0214 - val_mape: 48.4759 - val_mse: 0.0214 - val_rmse: 0.1463\n",
      "Epoch 36/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 41.7467 - mse: 0.0200 - rmse: 0.1413 - val_loss: 0.0192 - val_mape: 43.2218 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 37/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0202 - mape: 42.4474 - mse: 0.0202 - rmse: 0.1422 - val_loss: 0.0189 - val_mape: 41.8768 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 38/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0197 - mape: 41.7032 - mse: 0.0197 - rmse: 0.1405 - val_loss: 0.0206 - val_mape: 45.0881 - val_mse: 0.0206 - val_rmse: 0.1437\n",
      "Epoch 39/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 41.7886 - mse: 0.0200 - rmse: 0.1415 - val_loss: 0.0192 - val_mape: 43.1002 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 40/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0197 - mape: 41.9652 - mse: 0.0197 - rmse: 0.1403 - val_loss: 0.0195 - val_mape: 42.7869 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 41/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0198 - mape: 41.4273 - mse: 0.0198 - rmse: 0.1406 - val_loss: 0.0204 - val_mape: 47.1847 - val_mse: 0.0204 - val_rmse: 0.1429\n",
      "Epoch 42/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 41.7356 - mse: 0.0200 - rmse: 0.1416 - val_loss: 0.0193 - val_mape: 42.6747 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 43/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0198 - mape: 42.1348 - mse: 0.0198 - rmse: 0.1405 - val_loss: 0.0190 - val_mape: 42.7428 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 44/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 42.8006 - mse: 0.0201 - rmse: 0.1417 - val_loss: 0.0188 - val_mape: 39.1277 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 45/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0198 - mape: 41.9715 - mse: 0.0198 - rmse: 0.1407 - val_loss: 0.0191 - val_mape: 43.3197 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 46/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0198 - mape: 41.5186 - mse: 0.0198 - rmse: 0.1406 - val_loss: 0.0209 - val_mape: 47.3245 - val_mse: 0.0209 - val_rmse: 0.1446\n",
      "Epoch 47/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0196 - mape: 41.7410 - mse: 0.0196 - rmse: 0.1400 - val_loss: 0.0191 - val_mape: 40.2196 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 48/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0194 - mape: 41.5281 - mse: 0.0194 - rmse: 0.1394 - val_loss: 0.0190 - val_mape: 42.7837 - val_mse: 0.0189 - val_rmse: 0.1377\n",
      "Epoch 49/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0195 - mape: 41.3210 - mse: 0.0195 - rmse: 0.1397 - val_loss: 0.0187 - val_mape: 41.9591 - val_mse: 0.0187 - val_rmse: 0.1368\n",
      "Epoch 50/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0195 - mape: 41.1365 - mse: 0.0195 - rmse: 0.1396 - val_loss: 0.0203 - val_mape: 47.4810 - val_mse: 0.0203 - val_rmse: 0.1426\n",
      "Epoch 51/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0195 - mape: 41.2739 - mse: 0.0195 - rmse: 0.1396 - val_loss: 0.0250 - val_mape: 55.5621 - val_mse: 0.0250 - val_rmse: 0.1581\n",
      "Epoch 52/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0196 - mape: 41.6006 - mse: 0.0196 - rmse: 0.1399 - val_loss: 0.0243 - val_mape: 53.9781 - val_mse: 0.0243 - val_rmse: 0.1559\n",
      "Epoch 53/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0200 - mape: 42.9138 - mse: 0.0200 - rmse: 0.1414 - val_loss: 0.0189 - val_mape: 40.0951 - val_mse: 0.0189 - val_rmse: 0.1374\n",
      "Epoch 54/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0195 - mape: 41.5910 - mse: 0.0195 - rmse: 0.1397 - val_loss: 0.0231 - val_mape: 52.1988 - val_mse: 0.0231 - val_rmse: 0.1519\n",
      "Epoch 55/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0197 - mape: 41.7129 - mse: 0.0197 - rmse: 0.1404 - val_loss: 0.0185 - val_mape: 42.8231 - val_mse: 0.0185 - val_rmse: 0.1360\n",
      "Epoch 56/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0194 - mape: 41.3654 - mse: 0.0194 - rmse: 0.1394 - val_loss: 0.0188 - val_mape: 43.0437 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 57/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0196 - mape: 41.2980 - mse: 0.0196 - rmse: 0.1398 - val_loss: 0.0186 - val_mape: 41.8592 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 58/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0195 - mape: 41.4764 - mse: 0.0195 - rmse: 0.1397 - val_loss: 0.0190 - val_mape: 42.9788 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 59/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 40.7473 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0194 - val_mape: 44.5306 - val_mse: 0.0194 - val_rmse: 0.1394\n",
      "Epoch 60/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0196 - mape: 41.5525 - mse: 0.0196 - rmse: 0.1399 - val_loss: 0.0190 - val_mape: 43.7381 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 61/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0195 - mape: 41.4013 - mse: 0.0195 - rmse: 0.1395 - val_loss: 0.0183 - val_mape: 39.7106 - val_mse: 0.0183 - val_rmse: 0.1354\n",
      "Epoch 62/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0193 - mape: 41.2292 - mse: 0.0193 - rmse: 0.1387 - val_loss: 0.0191 - val_mape: 44.7276 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 63/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0194 - mape: 41.6358 - mse: 0.0194 - rmse: 0.1394 - val_loss: 0.0196 - val_mape: 46.8387 - val_mse: 0.0196 - val_rmse: 0.1399\n",
      "Epoch 64/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0194 - mape: 41.5895 - mse: 0.0194 - rmse: 0.1392 - val_loss: 0.0188 - val_mape: 42.0762 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 65/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0194 - mape: 40.8786 - mse: 0.0194 - rmse: 0.1391 - val_loss: 0.0191 - val_mape: 43.6366 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 66/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0193 - mape: 41.5647 - mse: 0.0193 - rmse: 0.1391 - val_loss: 0.0207 - val_mape: 46.8743 - val_mse: 0.0207 - val_rmse: 0.1439\n",
      "Epoch 67/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0194 - mape: 41.5863 - mse: 0.0194 - rmse: 0.1394 - val_loss: 0.0191 - val_mape: 44.2981 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 68/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0193 - mape: 40.8705 - mse: 0.0193 - rmse: 0.1387 - val_loss: 0.0195 - val_mape: 42.8527 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 69/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0196 - mape: 42.2636 - mse: 0.0196 - rmse: 0.1399 - val_loss: 0.0184 - val_mape: 42.7859 - val_mse: 0.0184 - val_rmse: 0.1358\n",
      "Epoch 70/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0191 - mape: 40.5993 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0190 - val_mape: 43.8573 - val_mse: 0.0190 - val_rmse: 0.1378\n",
      "Epoch 71/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 41.5808 - mse: 0.0192 - rmse: 0.1386 - val_loss: 0.0186 - val_mape: 43.9932 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 72/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0193 - mape: 41.4409 - mse: 0.0193 - rmse: 0.1390 - val_loss: 0.0186 - val_mape: 42.8619 - val_mse: 0.0185 - val_rmse: 0.1362\n",
      "Epoch 73/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 41.7546 - mse: 0.0192 - rmse: 0.1387 - val_loss: 0.0192 - val_mape: 44.3108 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 74/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0201 - mape: 42.7357 - mse: 0.0201 - rmse: 0.1415 - val_loss: 0.0189 - val_mape: 43.0938 - val_mse: 0.0189 - val_rmse: 0.1375\n",
      "Epoch 75/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0190 - mape: 40.0849 - mse: 0.0190 - rmse: 0.1380 - val_loss: 0.0186 - val_mape: 39.8510 - val_mse: 0.0186 - val_rmse: 0.1364\n",
      "Epoch 76/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 41.0329 - mse: 0.0192 - rmse: 0.1387 - val_loss: 0.0188 - val_mape: 42.6178 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 77/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0193 - mape: 41.6397 - mse: 0.0193 - rmse: 0.1388 - val_loss: 0.0185 - val_mape: 42.1607 - val_mse: 0.0185 - val_rmse: 0.1362\n",
      "Epoch 78/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0196 - mape: 42.2470 - mse: 0.0196 - rmse: 0.1400 - val_loss: 0.0186 - val_mape: 42.4450 - val_mse: 0.0186 - val_rmse: 0.1362\n",
      "Epoch 79/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0190 - mape: 40.6572 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0183 - val_mape: 41.9487 - val_mse: 0.0183 - val_rmse: 0.1351\n",
      "Epoch 80/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 40.8209 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0196 - val_mape: 45.3094 - val_mse: 0.0195 - val_rmse: 0.1398\n",
      "Epoch 81/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0190 - mape: 40.7546 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0230 - val_mape: 52.0925 - val_mse: 0.0230 - val_rmse: 0.1517\n",
      "Epoch 82/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0190 - mape: 41.0076 - mse: 0.0190 - rmse: 0.1380 - val_loss: 0.0180 - val_mape: 39.8342 - val_mse: 0.0180 - val_rmse: 0.1343\n",
      "Epoch 83/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0190 - mape: 40.8795 - mse: 0.0190 - rmse: 0.1378 - val_loss: 0.0215 - val_mape: 49.0435 - val_mse: 0.0215 - val_rmse: 0.1467\n",
      "Epoch 84/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0192 - mape: 41.5873 - mse: 0.0192 - rmse: 0.1384 - val_loss: 0.0185 - val_mape: 41.2481 - val_mse: 0.0185 - val_rmse: 0.1362\n",
      "Epoch 85/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0189 - mape: 40.4169 - mse: 0.0189 - rmse: 0.1373 - val_loss: 0.0189 - val_mape: 43.0827 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 86/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0189 - mape: 40.5016 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0195 - val_mape: 44.1622 - val_mse: 0.0194 - val_rmse: 0.1395\n",
      "Epoch 87/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0190 - mape: 40.7259 - mse: 0.0190 - rmse: 0.1378 - val_loss: 0.0188 - val_mape: 39.3579 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 88/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 41.1040 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0188 - val_mape: 44.4831 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 89/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0193 - mape: 41.7099 - mse: 0.0193 - rmse: 0.1390 - val_loss: 0.0181 - val_mape: 41.4090 - val_mse: 0.0181 - val_rmse: 0.1344\n",
      "Epoch 90/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 40.2498 - mse: 0.0188 - rmse: 0.1371 - val_loss: 0.0201 - val_mape: 46.8196 - val_mse: 0.0201 - val_rmse: 0.1418\n",
      "Epoch 91/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 40.2041 - mse: 0.0188 - rmse: 0.1373 - val_loss: 0.0192 - val_mape: 43.0883 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 92/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 40.0957 - mse: 0.0189 - rmse: 0.1376 - val_loss: 0.0187 - val_mape: 44.2602 - val_mse: 0.0187 - val_rmse: 0.1366\n",
      "Epoch 93/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 40.4636 - mse: 0.0189 - rmse: 0.1374 - val_loss: 0.0179 - val_mape: 39.3916 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 94/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 39.9337 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0185 - val_mape: 42.8000 - val_mse: 0.0185 - val_rmse: 0.1360\n",
      "Epoch 95/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 40.4250 - mse: 0.0188 - rmse: 0.1372 - val_loss: 0.0174 - val_mape: 38.5248 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 96/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 40.7473 - mse: 0.0188 - rmse: 0.1371 - val_loss: 0.0192 - val_mape: 45.1575 - val_mse: 0.0191 - val_rmse: 0.1384\n",
      "Epoch 97/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0187 - mape: 40.4339 - mse: 0.0187 - rmse: 0.1369 - val_loss: 0.0201 - val_mape: 46.4984 - val_mse: 0.0201 - val_rmse: 0.1418\n",
      "Epoch 98/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0191 - mape: 40.8916 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0194 - val_mape: 45.0907 - val_mse: 0.0194 - val_rmse: 0.1393\n",
      "Epoch 99/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 40.3456 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0186 - val_mape: 41.3242 - val_mse: 0.0186 - val_rmse: 0.1364\n",
      "Epoch 100/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 41.7478 - mse: 0.0192 - rmse: 0.1386 - val_loss: 0.0219 - val_mape: 50.0541 - val_mse: 0.0219 - val_rmse: 0.1482\n",
      "Epoch 101/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 41.3444 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0200 - val_mape: 44.3117 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 102/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0191 - mape: 40.9087 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0176 - val_mape: 39.5479 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 103/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 40.7077 - mse: 0.0189 - rmse: 0.1374 - val_loss: 0.0193 - val_mape: 45.5859 - val_mse: 0.0193 - val_rmse: 0.1391\n",
      "Epoch 104/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 41.0668 - mse: 0.0189 - rmse: 0.1373 - val_loss: 0.0188 - val_mape: 40.9964 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 105/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0192 - mape: 41.0320 - mse: 0.0192 - rmse: 0.1386 - val_loss: 0.0188 - val_mape: 44.4609 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 106/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0189 - mape: 40.7104 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0182 - val_mape: 41.5280 - val_mse: 0.0182 - val_rmse: 0.1349\n",
      "Epoch 107/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0190 - mape: 40.5749 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0183 - val_mape: 42.6589 - val_mse: 0.0183 - val_rmse: 0.1354\n",
      "Epoch 108/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0186 - mape: 39.8890 - mse: 0.0186 - rmse: 0.1364 - val_loss: 0.0182 - val_mape: 41.6383 - val_mse: 0.0182 - val_rmse: 0.1351\n",
      "Epoch 109/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0188 - mape: 40.1746 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0200 - val_mape: 46.2569 - val_mse: 0.0200 - val_rmse: 0.1416\n",
      "Epoch 110/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0187 - mape: 40.1417 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0188 - val_mape: 43.9014 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 111/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0186 - mape: 40.1500 - mse: 0.0186 - rmse: 0.1363 - val_loss: 0.0208 - val_mape: 49.3046 - val_mse: 0.0208 - val_rmse: 0.1443\n",
      "Epoch 112/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0186 - mape: 40.2541 - mse: 0.0186 - rmse: 0.1363 - val_loss: 0.0180 - val_mape: 40.8952 - val_mse: 0.0179 - val_rmse: 0.1340\n",
      "Epoch 113/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0186 - mape: 40.4799 - mse: 0.0186 - rmse: 0.1362 - val_loss: 0.0178 - val_mape: 40.0857 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 114/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0186 - mape: 40.2988 - mse: 0.0186 - rmse: 0.1364 - val_loss: 0.0182 - val_mape: 41.7752 - val_mse: 0.0182 - val_rmse: 0.1348\n",
      "Epoch 115/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0184 - mape: 39.4895 - mse: 0.0184 - rmse: 0.1356 - val_loss: 0.0178 - val_mape: 38.8017 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "PROCESANDO ARCHIVO: Tsuga dumosa\n",
      "(20493, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Tsuga dumosa_best_models.json\n",
      "(11935, 4, 43) (4144, 4, 43) (3469, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m88,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m20,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">540,389</span> (2.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m540,389\u001b[0m (2.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">180,129</span> (703.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m180,129\u001b[0m (703.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">360,260</span> (1.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m360,260\u001b[0m (1.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0194 - mape: 39.4104 - mse: 0.0194 - rmse: 0.1393 - val_loss: 0.0174 - val_mape: 35.2447 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 2/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0191 - mape: 39.3658 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0180 - val_mape: 38.4685 - val_mse: 0.0180 - val_rmse: 0.1341\n",
      "Epoch 3/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.2120 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0214 - val_mape: 47.6872 - val_mse: 0.0214 - val_rmse: 0.1462\n",
      "Epoch 4/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0192 - mape: 39.9233 - mse: 0.0192 - rmse: 0.1384 - val_loss: 0.0197 - val_mape: 43.8891 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 5/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0187 - mape: 39.4356 - mse: 0.0187 - rmse: 0.1368 - val_loss: 0.0209 - val_mape: 46.3050 - val_mse: 0.0209 - val_rmse: 0.1446\n",
      "Epoch 6/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.8986 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0172 - val_mape: 35.7696 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 7/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.9580 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0207 - val_mape: 46.5388 - val_mse: 0.0207 - val_rmse: 0.1440\n",
      "Epoch 8/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 38.8064 - mse: 0.0185 - rmse: 0.1361 - val_loss: 0.0178 - val_mape: 38.3325 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 9/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0182 - mape: 37.8764 - mse: 0.0182 - rmse: 0.1350 - val_loss: 0.0204 - val_mape: 45.4960 - val_mse: 0.0204 - val_rmse: 0.1427\n",
      "Epoch 10/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 39.1167 - mse: 0.0185 - rmse: 0.1361 - val_loss: 0.0181 - val_mape: 39.3986 - val_mse: 0.0181 - val_rmse: 0.1346\n",
      "Epoch 11/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 38.7953 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0170 - val_mape: 34.3084 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 12/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0190 - mape: 39.3376 - mse: 0.0190 - rmse: 0.1379 - val_loss: 0.0199 - val_mape: 44.2792 - val_mse: 0.0199 - val_rmse: 0.1409\n",
      "Epoch 13/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0189 - mape: 39.3169 - mse: 0.0189 - rmse: 0.1376 - val_loss: 0.0171 - val_mape: 36.1602 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 14/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0182 - mape: 38.1945 - mse: 0.0182 - rmse: 0.1349 - val_loss: 0.0179 - val_mape: 38.0964 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 15/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0190 - mape: 38.7945 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0202 - val_mape: 45.2700 - val_mse: 0.0203 - val_rmse: 0.1423\n",
      "Epoch 16/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0186 - mape: 38.8686 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0166 - val_mape: 32.4305 - val_mse: 0.0166 - val_rmse: 0.1290\n",
      "Epoch 17/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0184 - mape: 38.3892 - mse: 0.0184 - rmse: 0.1357 - val_loss: 0.0183 - val_mape: 39.8678 - val_mse: 0.0183 - val_rmse: 0.1353\n",
      "Epoch 18/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.1742 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0209 - val_mape: 46.6709 - val_mse: 0.0209 - val_rmse: 0.1446\n",
      "Epoch 19/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 38.7331 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0190 - val_mape: 42.0223 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 20/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0181 - mape: 38.2489 - mse: 0.0181 - rmse: 0.1346 - val_loss: 0.0175 - val_mape: 37.5703 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 21/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0183 - mape: 38.0060 - mse: 0.0183 - rmse: 0.1351 - val_loss: 0.0166 - val_mape: 34.4517 - val_mse: 0.0166 - val_rmse: 0.1287\n",
      "Epoch 22/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0182 - mape: 37.7450 - mse: 0.0182 - rmse: 0.1350 - val_loss: 0.0168 - val_mape: 35.7412 - val_mse: 0.0169 - val_rmse: 0.1298\n",
      "Epoch 23/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0184 - mape: 37.9471 - mse: 0.0184 - rmse: 0.1355 - val_loss: 0.0169 - val_mape: 35.2550 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 24/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0183 - mape: 38.2990 - mse: 0.0183 - rmse: 0.1354 - val_loss: 0.0171 - val_mape: 35.7240 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 25/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0181 - mape: 37.9676 - mse: 0.0181 - rmse: 0.1344 - val_loss: 0.0193 - val_mape: 42.8333 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 26/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.8394 - mse: 0.0188 - rmse: 0.1372 - val_loss: 0.0216 - val_mape: 48.0002 - val_mse: 0.0216 - val_rmse: 0.1471\n",
      "Epoch 27/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 38.7347 - mse: 0.0185 - rmse: 0.1358 - val_loss: 0.0234 - val_mape: 51.6626 - val_mse: 0.0234 - val_rmse: 0.1531\n",
      "Epoch 28/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0181 - mape: 37.8864 - mse: 0.0181 - rmse: 0.1345 - val_loss: 0.0215 - val_mape: 48.1550 - val_mse: 0.0215 - val_rmse: 0.1466\n",
      "Epoch 29/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 38.9806 - mse: 0.0185 - rmse: 0.1358 - val_loss: 0.0171 - val_mape: 36.1248 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 30/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0186 - mape: 38.3515 - mse: 0.0186 - rmse: 0.1362 - val_loss: 0.0195 - val_mape: 43.4642 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 31/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0186 - mape: 38.7221 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0191 - val_mape: 42.6500 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 32/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0184 - mape: 37.5074 - mse: 0.0184 - rmse: 0.1358 - val_loss: 0.0172 - val_mape: 36.5767 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 33/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.9072 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0173 - val_mape: 36.7763 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 34/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0182 - mape: 37.9140 - mse: 0.0182 - rmse: 0.1348 - val_loss: 0.0171 - val_mape: 36.5150 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 35/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0179 - mape: 38.2153 - mse: 0.0179 - rmse: 0.1339 - val_loss: 0.0239 - val_mape: 52.4089 - val_mse: 0.0239 - val_rmse: 0.1546\n",
      "Epoch 36/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0186 - mape: 39.2689 - mse: 0.0186 - rmse: 0.1362 - val_loss: 0.0216 - val_mape: 47.9981 - val_mse: 0.0216 - val_rmse: 0.1469\n",
      "Epoch 37/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0186 - mape: 38.2580 - mse: 0.0186 - rmse: 0.1362 - val_loss: 0.0195 - val_mape: 43.8605 - val_mse: 0.0195 - val_rmse: 0.1397\n",
      "Epoch 38/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0183 - mape: 38.2439 - mse: 0.0183 - rmse: 0.1353 - val_loss: 0.0187 - val_mape: 41.7334 - val_mse: 0.0187 - val_rmse: 0.1368\n",
      "Epoch 39/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.9476 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0203 - val_mape: 45.5255 - val_mse: 0.0203 - val_rmse: 0.1424\n",
      "Epoch 40/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0186 - mape: 38.3714 - mse: 0.0186 - rmse: 0.1362 - val_loss: 0.0228 - val_mape: 50.3691 - val_mse: 0.0228 - val_rmse: 0.1510\n",
      "Epoch 41/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.9978 - mse: 0.0187 - rmse: 0.1369 - val_loss: 0.0168 - val_mape: 34.8372 - val_mse: 0.0168 - val_rmse: 0.1296\n",
      "PROCESANDO ARCHIVO: Juniperus spp. \n",
      "(17976, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus spp. _best_models.json\n",
      "(10218, 4, 43) (3900, 4, 43) (3018, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m27,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m61,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m74,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m3,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m49\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">623,909</span> (2.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m623,909\u001b[0m (2.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">207,969</span> (812.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m207,969\u001b[0m (812.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,940</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m415,940\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0196 - mape: 40.1162 - mse: 0.0196 - rmse: 0.1399 - val_loss: 0.0197 - val_mape: 38.5480 - val_mse: 0.0196 - val_rmse: 0.1402\n",
      "Epoch 2/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0190 - mape: 39.8651 - mse: 0.0190 - rmse: 0.1376 - val_loss: 0.0197 - val_mape: 35.8435 - val_mse: 0.0196 - val_rmse: 0.1402\n",
      "Epoch 3/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0185 - mape: 38.9231 - mse: 0.0185 - rmse: 0.1362 - val_loss: 0.0190 - val_mape: 36.5231 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 4/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0186 - mape: 39.9120 - mse: 0.0186 - rmse: 0.1362 - val_loss: 0.0190 - val_mape: 38.0352 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 5/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0182 - mape: 39.1216 - mse: 0.0182 - rmse: 0.1348 - val_loss: 0.0189 - val_mape: 36.9644 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 6/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0185 - mape: 39.7262 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0190 - val_mape: 35.2954 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 7/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0182 - mape: 40.1530 - mse: 0.0182 - rmse: 0.1350 - val_loss: 0.0185 - val_mape: 36.2113 - val_mse: 0.0184 - val_rmse: 0.1359\n",
      "Epoch 8/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0177 - mape: 37.2112 - mse: 0.0177 - rmse: 0.1331 - val_loss: 0.0187 - val_mape: 37.6482 - val_mse: 0.0186 - val_rmse: 0.1366\n",
      "Epoch 9/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0177 - mape: 39.0769 - mse: 0.0177 - rmse: 0.1332 - val_loss: 0.0192 - val_mape: 37.0795 - val_mse: 0.0191 - val_rmse: 0.1384\n",
      "Epoch 10/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0184 - mape: 39.0632 - mse: 0.0184 - rmse: 0.1356 - val_loss: 0.0186 - val_mape: 36.2536 - val_mse: 0.0185 - val_rmse: 0.1363\n",
      "Epoch 11/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0181 - mape: 39.5971 - mse: 0.0181 - rmse: 0.1346 - val_loss: 0.0188 - val_mape: 36.9051 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 12/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0178 - mape: 38.0255 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.0187 - val_mape: 37.1201 - val_mse: 0.0187 - val_rmse: 0.1369\n",
      "Epoch 13/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0180 - mape: 39.3700 - mse: 0.0180 - rmse: 0.1340 - val_loss: 0.0188 - val_mape: 37.0524 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 14/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0181 - mape: 38.9692 - mse: 0.0181 - rmse: 0.1345 - val_loss: 0.0190 - val_mape: 36.8256 - val_mse: 0.0189 - val_rmse: 0.1378\n",
      "Epoch 15/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0181 - mape: 38.3985 - mse: 0.0181 - rmse: 0.1346 - val_loss: 0.0186 - val_mape: 37.2002 - val_mse: 0.0185 - val_rmse: 0.1362\n",
      "Epoch 16/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0182 - mape: 40.2248 - mse: 0.0182 - rmse: 0.1347 - val_loss: 0.0193 - val_mape: 36.8448 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 17/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0183 - mape: 39.2403 - mse: 0.0183 - rmse: 0.1354 - val_loss: 0.0193 - val_mape: 38.7383 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 18/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0182 - mape: 40.3921 - mse: 0.0182 - rmse: 0.1349 - val_loss: 0.0190 - val_mape: 36.4982 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 19/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0183 - mape: 39.8196 - mse: 0.0183 - rmse: 0.1353 - val_loss: 0.0192 - val_mape: 37.6876 - val_mse: 0.0192 - val_rmse: 0.1386\n",
      "Epoch 20/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0183 - mape: 40.2096 - mse: 0.0183 - rmse: 0.1353 - val_loss: 0.0193 - val_mape: 37.2971 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 21/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0185 - mape: 40.3903 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0191 - val_mape: 38.1535 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 22/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0179 - mape: 38.5751 - mse: 0.0179 - rmse: 0.1338 - val_loss: 0.0189 - val_mape: 37.6585 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 23/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0180 - mape: 38.9148 - mse: 0.0180 - rmse: 0.1340 - val_loss: 0.0193 - val_mape: 39.1962 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 24/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0180 - mape: 39.3016 - mse: 0.0180 - rmse: 0.1343 - val_loss: 0.0190 - val_mape: 35.9535 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 25/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0179 - mape: 38.3670 - mse: 0.0179 - rmse: 0.1336 - val_loss: 0.0190 - val_mape: 36.6463 - val_mse: 0.0190 - val_rmse: 0.1380\n",
      "Epoch 26/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0180 - mape: 39.0343 - mse: 0.0180 - rmse: 0.1339 - val_loss: 0.0190 - val_mape: 38.5673 - val_mse: 0.0189 - val_rmse: 0.1378\n",
      "Epoch 27/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0177 - mape: 38.8256 - mse: 0.0177 - rmse: 0.1329 - val_loss: 0.0190 - val_mape: 36.4519 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "PROCESANDO ARCHIVO: Juniperus recurva\n",
      "(5316, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus recurva_best_models.json\n",
      "(3188, 4, 43) (1082, 4, 43) (810, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m88,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m20,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m49,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m82,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m7,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m57\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">793,301</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m793,301\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,433</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,433\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,868</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m528,868\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0171 - mape: 27.8827 - mse: 0.0171 - rmse: 0.1302 - val_loss: 0.0209 - val_mape: 24.0137 - val_mse: 0.0208 - val_rmse: 0.1445\n",
      "Epoch 2/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0138 - mape: 24.5989 - mse: 0.0138 - rmse: 0.1176 - val_loss: 0.0193 - val_mape: 23.4611 - val_mse: 0.0192 - val_rmse: 0.1388\n",
      "Epoch 3/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0134 - mape: 24.4612 - mse: 0.0134 - rmse: 0.1156 - val_loss: 0.0178 - val_mape: 22.8380 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 4/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0134 - mape: 24.8283 - mse: 0.0134 - rmse: 0.1157 - val_loss: 0.0200 - val_mape: 23.4663 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 5/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0135 - mape: 24.6196 - mse: 0.0135 - rmse: 0.1161 - val_loss: 0.0192 - val_mape: 23.0937 - val_mse: 0.0191 - val_rmse: 0.1385\n",
      "Epoch 6/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0138 - mape: 25.0426 - mse: 0.0138 - rmse: 0.1173 - val_loss: 0.0187 - val_mape: 23.0425 - val_mse: 0.0186 - val_rmse: 0.1367\n",
      "Epoch 7/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0130 - mape: 24.0487 - mse: 0.0130 - rmse: 0.1138 - val_loss: 0.0191 - val_mape: 23.3015 - val_mse: 0.0190 - val_rmse: 0.1383\n",
      "Epoch 8/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0129 - mape: 24.1042 - mse: 0.0129 - rmse: 0.1133 - val_loss: 0.0192 - val_mape: 23.2018 - val_mse: 0.0191 - val_rmse: 0.1386\n",
      "Epoch 9/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0131 - mape: 24.3086 - mse: 0.0131 - rmse: 0.1143 - val_loss: 0.0198 - val_mape: 23.6962 - val_mse: 0.0197 - val_rmse: 0.1409\n",
      "Epoch 10/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0127 - mape: 24.0004 - mse: 0.0127 - rmse: 0.1129 - val_loss: 0.0170 - val_mape: 22.7486 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 11/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.4639 - mse: 0.0123 - rmse: 0.1107 - val_loss: 0.0172 - val_mape: 22.7048 - val_mse: 0.0171 - val_rmse: 0.1310\n",
      "Epoch 12/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.3687 - mse: 0.0123 - rmse: 0.1108 - val_loss: 0.0166 - val_mape: 22.6922 - val_mse: 0.0166 - val_rmse: 0.1290\n",
      "Epoch 13/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0122 - mape: 23.4434 - mse: 0.0122 - rmse: 0.1105 - val_loss: 0.0166 - val_mape: 22.6040 - val_mse: 0.0165 - val_rmse: 0.1288\n",
      "Epoch 14/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0122 - mape: 23.5026 - mse: 0.0122 - rmse: 0.1106 - val_loss: 0.0175 - val_mape: 22.9783 - val_mse: 0.0174 - val_rmse: 0.1322\n",
      "Epoch 15/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.6354 - mse: 0.0123 - rmse: 0.1110 - val_loss: 0.0168 - val_mape: 22.7687 - val_mse: 0.0167 - val_rmse: 0.1296\n",
      "Epoch 16/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0122 - mape: 23.6300 - mse: 0.0122 - rmse: 0.1106 - val_loss: 0.0188 - val_mape: 23.2380 - val_mse: 0.0187 - val_rmse: 0.1372\n",
      "Epoch 17/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0126 - mape: 23.8221 - mse: 0.0126 - rmse: 0.1122 - val_loss: 0.0188 - val_mape: 23.2364 - val_mse: 0.0187 - val_rmse: 0.1370\n",
      "Epoch 18/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.3493 - mse: 0.0123 - rmse: 0.1108 - val_loss: 0.0173 - val_mape: 22.6364 - val_mse: 0.0172 - val_rmse: 0.1315\n",
      "Epoch 19/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0122 - mape: 23.4460 - mse: 0.0122 - rmse: 0.1104 - val_loss: 0.0173 - val_mape: 22.6398 - val_mse: 0.0172 - val_rmse: 0.1314\n",
      "Epoch 20/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0121 - mape: 23.1822 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0176 - val_mape: 22.6797 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 21/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0121 - mape: 23.5212 - mse: 0.0121 - rmse: 0.1101 - val_loss: 0.0174 - val_mape: 22.6250 - val_mse: 0.0173 - val_rmse: 0.1320\n",
      "Epoch 22/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.5362 - mse: 0.0123 - rmse: 0.1109 - val_loss: 0.0185 - val_mape: 23.0470 - val_mse: 0.0184 - val_rmse: 0.1359\n",
      "Epoch 23/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0126 - mape: 23.8125 - mse: 0.0126 - rmse: 0.1120 - val_loss: 0.0169 - val_mape: 22.6213 - val_mse: 0.0168 - val_rmse: 0.1301\n",
      "Epoch 24/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0122 - mape: 23.7421 - mse: 0.0122 - rmse: 0.1106 - val_loss: 0.0158 - val_mape: 22.5223 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 25/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.5887 - mse: 0.0123 - rmse: 0.1109 - val_loss: 0.0160 - val_mape: 22.4258 - val_mse: 0.0159 - val_rmse: 0.1263\n",
      "Epoch 26/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0123 - mape: 23.5745 - mse: 0.0123 - rmse: 0.1109 - val_loss: 0.0194 - val_mape: 23.5012 - val_mse: 0.0193 - val_rmse: 0.1394\n",
      "Epoch 27/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0133 - mape: 24.7757 - mse: 0.0133 - rmse: 0.1154 - val_loss: 0.0185 - val_mape: 23.0091 - val_mse: 0.0184 - val_rmse: 0.1359\n",
      "Epoch 28/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0127 - mape: 24.0983 - mse: 0.0127 - rmse: 0.1128 - val_loss: 0.0204 - val_mape: 23.6918 - val_mse: 0.0203 - val_rmse: 0.1428\n",
      "Epoch 29/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0129 - mape: 24.0206 - mse: 0.0129 - rmse: 0.1137 - val_loss: 0.0181 - val_mape: 22.7748 - val_mse: 0.0180 - val_rmse: 0.1346\n",
      "Epoch 30/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0127 - mape: 24.1616 - mse: 0.0127 - rmse: 0.1128 - val_loss: 0.0194 - val_mape: 23.2661 - val_mse: 0.0193 - val_rmse: 0.1392\n",
      "Epoch 31/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0130 - mape: 24.5663 - mse: 0.0130 - rmse: 0.1139 - val_loss: 0.0206 - val_mape: 23.9308 - val_mse: 0.0206 - val_rmse: 0.1437\n",
      "Epoch 32/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0136 - mape: 24.8443 - mse: 0.0136 - rmse: 0.1165 - val_loss: 0.0190 - val_mape: 23.2476 - val_mse: 0.0189 - val_rmse: 0.1378\n",
      "Epoch 33/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0134 - mape: 24.7152 - mse: 0.0134 - rmse: 0.1158 - val_loss: 0.0193 - val_mape: 23.3738 - val_mse: 0.0192 - val_rmse: 0.1388\n",
      "Epoch 34/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0130 - mape: 24.0705 - mse: 0.0130 - rmse: 0.1140 - val_loss: 0.0186 - val_mape: 23.0938 - val_mse: 0.0186 - val_rmse: 0.1365\n",
      "Epoch 35/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0129 - mape: 24.1311 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0181 - val_mape: 22.8683 - val_mse: 0.0180 - val_rmse: 0.1344\n",
      "Epoch 36/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0130 - mape: 24.3155 - mse: 0.0130 - rmse: 0.1138 - val_loss: 0.0198 - val_mape: 23.4725 - val_mse: 0.0197 - val_rmse: 0.1406\n",
      "Epoch 37/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0131 - mape: 24.4633 - mse: 0.0131 - rmse: 0.1144 - val_loss: 0.0205 - val_mape: 23.8668 - val_mse: 0.0204 - val_rmse: 0.1432\n",
      "Epoch 38/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0125 - mape: 23.6499 - mse: 0.0125 - rmse: 0.1117 - val_loss: 0.0191 - val_mape: 23.1532 - val_mse: 0.0190 - val_rmse: 0.1383\n",
      "Epoch 39/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0127 - mape: 23.9416 - mse: 0.0127 - rmse: 0.1129 - val_loss: 0.0178 - val_mape: 22.5731 - val_mse: 0.0177 - val_rmse: 0.1334\n",
      "Epoch 40/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0124 - mape: 23.4257 - mse: 0.0124 - rmse: 0.1111 - val_loss: 0.0198 - val_mape: 23.3809 - val_mse: 0.0197 - val_rmse: 0.1407\n",
      "Epoch 41/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0124 - mape: 23.6277 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0221 - val_mape: 24.2729 - val_mse: 0.0220 - val_rmse: 0.1486\n",
      "Epoch 42/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0132 - mape: 24.3417 - mse: 0.0132 - rmse: 0.1147 - val_loss: 0.0192 - val_mape: 23.1846 - val_mse: 0.0191 - val_rmse: 0.1386\n",
      "Epoch 43/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0129 - mape: 24.0730 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0184 - val_mape: 22.8400 - val_mse: 0.0183 - val_rmse: 0.1355\n",
      "Epoch 44/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0125 - mape: 23.3580 - mse: 0.0125 - rmse: 0.1119 - val_loss: 0.0190 - val_mape: 23.1363 - val_mse: 0.0189 - val_rmse: 0.1379\n",
      "PROCESANDO ARCHIVO: Juniperus spp. L.\n",
      "(7264, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus spp. L._best_models.json\n",
      "(4216, 4, 43) (1524, 4, 43) (1188, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 40 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">88,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m88,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m74,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │         \u001b[38;5;34m5,820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m61\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,208,045</span> (4.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,208,045\u001b[0m (4.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,681</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m402,681\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">805,364</span> (3.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m805,364\u001b[0m (3.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0247 - mape: 61.6098 - mse: 0.0247 - rmse: 0.1570 - val_loss: 0.0243 - val_mape: 56.0337 - val_mse: 0.0243 - val_rmse: 0.1559\n",
      "Epoch 2/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0229 - mape: 51.4137 - mse: 0.0229 - rmse: 0.1513 - val_loss: 0.0230 - val_mape: 50.5807 - val_mse: 0.0229 - val_rmse: 0.1516\n",
      "Epoch 3/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0224 - mape: 53.6660 - mse: 0.0224 - rmse: 0.1498 - val_loss: 0.0228 - val_mape: 51.1717 - val_mse: 0.0228 - val_rmse: 0.1510\n",
      "Epoch 4/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0220 - mape: 48.1828 - mse: 0.0220 - rmse: 0.1483 - val_loss: 0.0229 - val_mape: 51.0737 - val_mse: 0.0229 - val_rmse: 0.1515\n",
      "Epoch 5/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0221 - mape: 49.9744 - mse: 0.0221 - rmse: 0.1486 - val_loss: 0.0231 - val_mape: 51.7101 - val_mse: 0.0230 - val_rmse: 0.1519\n",
      "Epoch 6/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0218 - mape: 49.5089 - mse: 0.0218 - rmse: 0.1475 - val_loss: 0.0226 - val_mape: 49.7146 - val_mse: 0.0225 - val_rmse: 0.1502\n",
      "Epoch 7/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0213 - mape: 46.8752 - mse: 0.0213 - rmse: 0.1459 - val_loss: 0.0225 - val_mape: 50.2396 - val_mse: 0.0225 - val_rmse: 0.1501\n",
      "Epoch 8/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0212 - mape: 53.7770 - mse: 0.0212 - rmse: 0.1457 - val_loss: 0.0225 - val_mape: 46.3963 - val_mse: 0.0225 - val_rmse: 0.1499\n",
      "Epoch 9/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0211 - mape: 54.2876 - mse: 0.0211 - rmse: 0.1451 - val_loss: 0.0223 - val_mape: 49.0419 - val_mse: 0.0223 - val_rmse: 0.1492\n",
      "Epoch 10/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0211 - mape: 46.8150 - mse: 0.0211 - rmse: 0.1454 - val_loss: 0.0222 - val_mape: 49.1322 - val_mse: 0.0222 - val_rmse: 0.1490\n",
      "Epoch 11/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0205 - mape: 48.4067 - mse: 0.0205 - rmse: 0.1433 - val_loss: 0.0218 - val_mape: 47.9215 - val_mse: 0.0218 - val_rmse: 0.1477\n",
      "Epoch 12/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0207 - mape: 45.9663 - mse: 0.0207 - rmse: 0.1439 - val_loss: 0.0221 - val_mape: 48.6137 - val_mse: 0.0221 - val_rmse: 0.1488\n",
      "Epoch 13/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0206 - mape: 48.1553 - mse: 0.0206 - rmse: 0.1437 - val_loss: 0.0215 - val_mape: 47.2093 - val_mse: 0.0215 - val_rmse: 0.1468\n",
      "Epoch 14/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0201 - mape: 46.4800 - mse: 0.0201 - rmse: 0.1418 - val_loss: 0.0219 - val_mape: 46.1515 - val_mse: 0.0219 - val_rmse: 0.1479\n",
      "Epoch 15/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0203 - mape: 47.8775 - mse: 0.0203 - rmse: 0.1424 - val_loss: 0.0221 - val_mape: 49.6383 - val_mse: 0.0221 - val_rmse: 0.1485\n",
      "Epoch 16/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0201 - mape: 47.7732 - mse: 0.0201 - rmse: 0.1418 - val_loss: 0.0218 - val_mape: 48.6985 - val_mse: 0.0218 - val_rmse: 0.1478\n",
      "Epoch 17/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0203 - mape: 51.5399 - mse: 0.0203 - rmse: 0.1424 - val_loss: 0.0217 - val_mape: 48.9481 - val_mse: 0.0217 - val_rmse: 0.1474\n",
      "Epoch 18/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - mape: 46.5018 - mse: 0.0198 - rmse: 0.1406 - val_loss: 0.0215 - val_mape: 47.5513 - val_mse: 0.0214 - val_rmse: 0.1465\n",
      "Epoch 19/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - mape: 50.3709 - mse: 0.0198 - rmse: 0.1406 - val_loss: 0.0219 - val_mape: 46.8145 - val_mse: 0.0218 - val_rmse: 0.1478\n",
      "Epoch 20/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0197 - mape: 47.0773 - mse: 0.0197 - rmse: 0.1404 - val_loss: 0.0215 - val_mape: 47.6985 - val_mse: 0.0215 - val_rmse: 0.1466\n",
      "Epoch 21/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - mape: 45.9889 - mse: 0.0198 - rmse: 0.1409 - val_loss: 0.0212 - val_mape: 46.4740 - val_mse: 0.0211 - val_rmse: 0.1455\n",
      "Epoch 22/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0190 - mape: 43.9319 - mse: 0.0190 - rmse: 0.1378 - val_loss: 0.0222 - val_mape: 51.4366 - val_mse: 0.0222 - val_rmse: 0.1491\n",
      "Epoch 23/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0193 - mape: 43.9348 - mse: 0.0193 - rmse: 0.1389 - val_loss: 0.0207 - val_mape: 43.5566 - val_mse: 0.0207 - val_rmse: 0.1439\n",
      "Epoch 24/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0192 - mape: 45.9107 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0209 - val_mape: 45.6001 - val_mse: 0.0209 - val_rmse: 0.1446\n",
      "Epoch 25/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0189 - mape: 45.8633 - mse: 0.0189 - rmse: 0.1376 - val_loss: 0.0209 - val_mape: 45.8298 - val_mse: 0.0209 - val_rmse: 0.1447\n",
      "Epoch 26/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0187 - mape: 44.8105 - mse: 0.0187 - rmse: 0.1368 - val_loss: 0.0220 - val_mape: 50.2053 - val_mse: 0.0220 - val_rmse: 0.1484\n",
      "Epoch 27/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0192 - mape: 45.2514 - mse: 0.0192 - rmse: 0.1387 - val_loss: 0.0209 - val_mape: 45.6184 - val_mse: 0.0208 - val_rmse: 0.1444\n",
      "Epoch 28/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0187 - mape: 44.1334 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0209 - val_mape: 44.7256 - val_mse: 0.0210 - val_rmse: 0.1447\n",
      "Epoch 29/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0188 - mape: 43.9129 - mse: 0.0188 - rmse: 0.1371 - val_loss: 0.0204 - val_mape: 43.5764 - val_mse: 0.0204 - val_rmse: 0.1430\n",
      "Epoch 30/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0189 - mape: 46.4844 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0209 - val_mape: 46.9453 - val_mse: 0.0209 - val_rmse: 0.1446\n",
      "Epoch 31/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0188 - mape: 47.0421 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0207 - val_mape: 45.7999 - val_mse: 0.0207 - val_rmse: 0.1439\n",
      "Epoch 32/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0191 - mape: 45.4856 - mse: 0.0191 - rmse: 0.1382 - val_loss: 0.0208 - val_mape: 45.7503 - val_mse: 0.0208 - val_rmse: 0.1442\n",
      "Epoch 33/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0190 - mape: 43.1130 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0204 - val_mape: 44.7955 - val_mse: 0.0205 - val_rmse: 0.1430\n",
      "Epoch 34/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0189 - mape: 43.0731 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0209 - val_mape: 47.0264 - val_mse: 0.0209 - val_rmse: 0.1445\n",
      "Epoch 35/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0186 - mape: 51.2829 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0204 - val_mape: 44.5876 - val_mse: 0.0204 - val_rmse: 0.1427\n",
      "Epoch 36/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0186 - mape: 43.9033 - mse: 0.0186 - rmse: 0.1364 - val_loss: 0.0202 - val_mape: 44.4342 - val_mse: 0.0203 - val_rmse: 0.1422\n",
      "Epoch 37/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0187 - mape: 46.8391 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0207 - val_mape: 45.3212 - val_mse: 0.0207 - val_rmse: 0.1439\n",
      "Epoch 38/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0189 - mape: 45.1877 - mse: 0.0189 - rmse: 0.1374 - val_loss: 0.0203 - val_mape: 44.7904 - val_mse: 0.0203 - val_rmse: 0.1424\n",
      "Epoch 39/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0187 - mape: 48.2014 - mse: 0.0187 - rmse: 0.1367 - val_loss: 0.0204 - val_mape: 43.2166 - val_mse: 0.0204 - val_rmse: 0.1428\n",
      "Epoch 40/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0182 - mape: 42.3078 - mse: 0.0182 - rmse: 0.1350 - val_loss: 0.0200 - val_mape: 42.2877 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 41/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0184 - mape: 49.5178 - mse: 0.0184 - rmse: 0.1358 - val_loss: 0.0204 - val_mape: 41.7042 - val_mse: 0.0204 - val_rmse: 0.1429\n",
      "Epoch 42/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0185 - mape: 41.9378 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0205 - val_mape: 46.3227 - val_mse: 0.0205 - val_rmse: 0.1433\n",
      "Epoch 43/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0181 - mape: 41.6313 - mse: 0.0181 - rmse: 0.1345 - val_loss: 0.0200 - val_mape: 42.4165 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 44/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0183 - mape: 48.6710 - mse: 0.0183 - rmse: 0.1353 - val_loss: 0.0200 - val_mape: 44.3284 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 45/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0183 - mape: 41.9550 - mse: 0.0183 - rmse: 0.1351 - val_loss: 0.0197 - val_mape: 42.5105 - val_mse: 0.0198 - val_rmse: 0.1405\n",
      "Epoch 46/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0178 - mape: 41.5278 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.0200 - val_mape: 42.1568 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 47/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0177 - mape: 44.3777 - mse: 0.0177 - rmse: 0.1329 - val_loss: 0.0197 - val_mape: 43.0675 - val_mse: 0.0197 - val_rmse: 0.1404\n",
      "Epoch 48/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0176 - mape: 41.1384 - mse: 0.0176 - rmse: 0.1326 - val_loss: 0.0198 - val_mape: 42.5975 - val_mse: 0.0198 - val_rmse: 0.1407\n",
      "Epoch 49/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0178 - mape: 49.0583 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0199 - val_mape: 43.8675 - val_mse: 0.0199 - val_rmse: 0.1411\n",
      "Epoch 50/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0180 - mape: 41.5486 - mse: 0.0180 - rmse: 0.1340 - val_loss: 0.0202 - val_mape: 45.5222 - val_mse: 0.0202 - val_rmse: 0.1421\n",
      "Epoch 51/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0179 - mape: 41.8607 - mse: 0.0179 - rmse: 0.1339 - val_loss: 0.0201 - val_mape: 45.2516 - val_mse: 0.0201 - val_rmse: 0.1418\n",
      "Epoch 52/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0178 - mape: 40.9608 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.0199 - val_mape: 43.1699 - val_mse: 0.0198 - val_rmse: 0.1409\n",
      "Epoch 53/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0177 - mape: 42.7738 - mse: 0.0177 - rmse: 0.1329 - val_loss: 0.0201 - val_mape: 45.1588 - val_mse: 0.0201 - val_rmse: 0.1419\n",
      "Epoch 54/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0175 - mape: 41.3504 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0198 - val_mape: 42.3319 - val_mse: 0.0197 - val_rmse: 0.1406\n",
      "Epoch 55/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0180 - mape: 40.7194 - mse: 0.0180 - rmse: 0.1342 - val_loss: 0.0200 - val_mape: 42.5553 - val_mse: 0.0200 - val_rmse: 0.1416\n",
      "Epoch 56/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0175 - mape: 43.2913 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0197 - val_mape: 43.3626 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 57/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0172 - mape: 41.7626 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0198 - val_mape: 44.1105 - val_mse: 0.0198 - val_rmse: 0.1406\n",
      "Epoch 58/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0173 - mape: 41.0961 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0197 - val_mape: 42.2317 - val_mse: 0.0197 - val_rmse: 0.1404\n",
      "Epoch 59/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0173 - mape: 41.3838 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0201 - val_mape: 43.5067 - val_mse: 0.0200 - val_rmse: 0.1417\n",
      "Epoch 60/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0171 - mape: 45.2467 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0197 - val_mape: 42.9513 - val_mse: 0.0197 - val_rmse: 0.1404\n",
      "Epoch 61/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0174 - mape: 46.8403 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0196 - val_mape: 43.8263 - val_mse: 0.0196 - val_rmse: 0.1400\n",
      "Epoch 62/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0173 - mape: 45.5648 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0205 - val_mape: 41.8046 - val_mse: 0.0206 - val_rmse: 0.1433\n",
      "Epoch 63/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0171 - mape: 45.4983 - mse: 0.0171 - rmse: 0.1309 - val_loss: 0.0199 - val_mape: 43.4384 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 64/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0171 - mape: 40.2884 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0205 - val_mape: 46.0250 - val_mse: 0.0205 - val_rmse: 0.1433\n",
      "Epoch 65/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0170 - mape: 49.9503 - mse: 0.0170 - rmse: 0.1302 - val_loss: 0.0199 - val_mape: 43.7552 - val_mse: 0.0199 - val_rmse: 0.1409\n",
      "Epoch 66/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0166 - mape: 41.9388 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0207 - val_mape: 46.9644 - val_mse: 0.0207 - val_rmse: 0.1439\n",
      "Epoch 67/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0172 - mape: 45.9149 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0205 - val_mape: 46.7271 - val_mse: 0.0205 - val_rmse: 0.1431\n",
      "Epoch 68/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0168 - mape: 41.3390 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0217 - val_mape: 50.5287 - val_mse: 0.0217 - val_rmse: 0.1472\n",
      "Epoch 69/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0172 - mape: 41.3000 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0204 - val_mape: 45.8680 - val_mse: 0.0204 - val_rmse: 0.1429\n",
      "Epoch 70/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0171 - mape: 40.7367 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0201 - val_mape: 46.0798 - val_mse: 0.0201 - val_rmse: 0.1417\n",
      "Epoch 71/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0170 - mape: 41.2787 - mse: 0.0170 - rmse: 0.1302 - val_loss: 0.0196 - val_mape: 43.6129 - val_mse: 0.0196 - val_rmse: 0.1400\n",
      "Epoch 72/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0167 - mape: 43.3464 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0200 - val_mape: 46.2681 - val_mse: 0.0200 - val_rmse: 0.1416\n",
      "Epoch 73/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0169 - mape: 55.5672 - mse: 0.0169 - rmse: 0.1301 - val_loss: 0.0203 - val_mape: 45.9330 - val_mse: 0.0204 - val_rmse: 0.1426\n",
      "Epoch 74/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0165 - mape: 42.2733 - mse: 0.0165 - rmse: 0.1283 - val_loss: 0.0204 - val_mape: 48.0620 - val_mse: 0.0204 - val_rmse: 0.1430\n",
      "Epoch 75/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0166 - mape: 44.6879 - mse: 0.0166 - rmse: 0.1287 - val_loss: 0.0204 - val_mape: 45.5464 - val_mse: 0.0204 - val_rmse: 0.1428\n",
      "Epoch 76/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0169 - mape: 45.9870 - mse: 0.0169 - rmse: 0.1298 - val_loss: 0.0201 - val_mape: 44.1288 - val_mse: 0.0200 - val_rmse: 0.1417\n",
      "Epoch 77/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0162 - mape: 42.0434 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0222 - val_mape: 51.4195 - val_mse: 0.0223 - val_rmse: 0.1491\n",
      "Epoch 78/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0169 - mape: 46.0820 - mse: 0.0169 - rmse: 0.1300 - val_loss: 0.0216 - val_mape: 50.4393 - val_mse: 0.0216 - val_rmse: 0.1469\n",
      "Epoch 79/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0167 - mape: 49.9392 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0214 - val_mape: 50.7934 - val_mse: 0.0214 - val_rmse: 0.1463\n",
      "Epoch 80/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0173 - mape: 42.7240 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0215 - val_mape: 49.3699 - val_mse: 0.0215 - val_rmse: 0.1466\n",
      "Epoch 81/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0167 - mape: 43.1682 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0212 - val_mape: 49.2499 - val_mse: 0.0212 - val_rmse: 0.1456\n",
      "Epoch 82/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0172 - mape: 41.9429 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0208 - val_mape: 48.5269 - val_mse: 0.0208 - val_rmse: 0.1444\n",
      "Epoch 83/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0164 - mape: 50.0153 - mse: 0.0164 - rmse: 0.1280 - val_loss: 0.0217 - val_mape: 49.8677 - val_mse: 0.0217 - val_rmse: 0.1472\n",
      "Epoch 84/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0166 - mape: 44.5871 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0203 - val_mape: 45.9144 - val_mse: 0.0204 - val_rmse: 0.1425\n",
      "Epoch 85/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0166 - mape: 42.3643 - mse: 0.0166 - rmse: 0.1287 - val_loss: 0.0209 - val_mape: 47.6117 - val_mse: 0.0209 - val_rmse: 0.1447\n",
      "Epoch 86/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0162 - mape: 45.1146 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0220 - val_mape: 50.7765 - val_mse: 0.0221 - val_rmse: 0.1483\n",
      "Epoch 87/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0161 - mape: 42.9768 - mse: 0.0161 - rmse: 0.1268 - val_loss: 0.0233 - val_mape: 53.8722 - val_mse: 0.0233 - val_rmse: 0.1526\n",
      "Epoch 88/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0168 - mape: 43.0131 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0211 - val_mape: 47.6770 - val_mse: 0.0211 - val_rmse: 0.1453\n",
      "Epoch 89/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0167 - mape: 45.2488 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0219 - val_mape: 48.9960 - val_mse: 0.0220 - val_rmse: 0.1480\n",
      "Epoch 90/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0168 - mape: 40.8553 - mse: 0.0168 - rmse: 0.1298 - val_loss: 0.0210 - val_mape: 46.9544 - val_mse: 0.0210 - val_rmse: 0.1449\n",
      "Epoch 91/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0162 - mape: 42.2579 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0218 - val_mape: 49.3149 - val_mse: 0.0218 - val_rmse: 0.1477\n",
      "PROCESANDO ARCHIVO: Pinus roxburghii\n",
      "(10635, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus roxburghii_best_models.json\n",
      "(6309, 4, 43) (2167, 4, 43) (1647, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,848</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m9,728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m82,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m20,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m1,848\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m57\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,445</span> (4.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,183,445\u001b[0m (4.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,481</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,481\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,964</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m788,964\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0197 - mape: 37.6492 - mse: 0.0197 - rmse: 0.1404 - val_loss: 0.0183 - val_mape: 27.6964 - val_mse: 0.0183 - val_rmse: 0.1352\n",
      "Epoch 2/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0190 - mape: 37.1108 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0176 - val_mape: 28.2946 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 3/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0188 - mape: 36.4919 - mse: 0.0188 - rmse: 0.1369 - val_loss: 0.0179 - val_mape: 33.3503 - val_mse: 0.0179 - val_rmse: 0.1339\n",
      "Epoch 4/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0188 - mape: 38.3660 - mse: 0.0188 - rmse: 0.1369 - val_loss: 0.0210 - val_mape: 40.3750 - val_mse: 0.0210 - val_rmse: 0.1450\n",
      "Epoch 5/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0185 - mape: 37.6216 - mse: 0.0185 - rmse: 0.1361 - val_loss: 0.0184 - val_mape: 32.9667 - val_mse: 0.0184 - val_rmse: 0.1355\n",
      "Epoch 6/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0183 - mape: 37.4145 - mse: 0.0183 - rmse: 0.1351 - val_loss: 0.0170 - val_mape: 29.1613 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 7/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0181 - mape: 36.7607 - mse: 0.0181 - rmse: 0.1345 - val_loss: 0.0169 - val_mape: 29.1580 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 8/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0180 - mape: 36.9497 - mse: 0.0180 - rmse: 0.1341 - val_loss: 0.0176 - val_mape: 30.6887 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 9/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0180 - mape: 36.3864 - mse: 0.0180 - rmse: 0.1340 - val_loss: 0.0213 - val_mape: 40.8518 - val_mse: 0.0213 - val_rmse: 0.1461\n",
      "Epoch 10/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0181 - mape: 37.0238 - mse: 0.0181 - rmse: 0.1346 - val_loss: 0.0193 - val_mape: 37.2120 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 11/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0177 - mape: 36.3186 - mse: 0.0177 - rmse: 0.1332 - val_loss: 0.0176 - val_mape: 31.8438 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 12/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0174 - mape: 36.1637 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0170 - val_mape: 28.4986 - val_mse: 0.0170 - val_rmse: 0.1302\n",
      "Epoch 13/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0177 - mape: 36.6190 - mse: 0.0177 - rmse: 0.1330 - val_loss: 0.0177 - val_mape: 27.3723 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 14/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0177 - mape: 36.1593 - mse: 0.0177 - rmse: 0.1329 - val_loss: 0.0169 - val_mape: 27.3213 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 15/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0176 - mape: 35.7525 - mse: 0.0176 - rmse: 0.1327 - val_loss: 0.0173 - val_mape: 30.5933 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 16/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0173 - mape: 35.3094 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0170 - val_mape: 27.1959 - val_mse: 0.0170 - val_rmse: 0.1302\n",
      "Epoch 17/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0174 - mape: 36.0237 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0171 - val_mape: 27.1367 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 18/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0171 - mape: 35.6063 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0175 - val_mape: 27.0271 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 19/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0172 - mape: 35.1825 - mse: 0.0172 - rmse: 0.1311 - val_loss: 0.0171 - val_mape: 27.7221 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 20/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0173 - mape: 35.0351 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 26.9616 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 21/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0169 - mape: 34.2656 - mse: 0.0169 - rmse: 0.1301 - val_loss: 0.0172 - val_mape: 27.8331 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 22/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0173 - mape: 34.9714 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 27.0900 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 23/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0169 - mape: 35.8270 - mse: 0.0169 - rmse: 0.1301 - val_loss: 0.0171 - val_mape: 27.5006 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 24/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0170 - mape: 35.0057 - mse: 0.0170 - rmse: 0.1305 - val_loss: 0.0173 - val_mape: 26.9769 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 25/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0169 - mape: 34.7530 - mse: 0.0169 - rmse: 0.1300 - val_loss: 0.0173 - val_mape: 27.0208 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 26/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0168 - mape: 34.3368 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0163 - val_mape: 28.0926 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 27/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0167 - mape: 34.9866 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0164 - val_mape: 26.8616 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 28/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0168 - mape: 35.5413 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0175 - val_mape: 30.4707 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 29/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0168 - mape: 34.5648 - mse: 0.0168 - rmse: 0.1298 - val_loss: 0.0161 - val_mape: 27.3548 - val_mse: 0.0161 - val_rmse: 0.1270\n",
      "Epoch 30/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0169 - mape: 34.2075 - mse: 0.0169 - rmse: 0.1300 - val_loss: 0.0160 - val_mape: 27.2945 - val_mse: 0.0160 - val_rmse: 0.1265\n",
      "Epoch 31/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0169 - mape: 35.1955 - mse: 0.0169 - rmse: 0.1301 - val_loss: 0.0166 - val_mape: 26.9959 - val_mse: 0.0166 - val_rmse: 0.1287\n",
      "Epoch 32/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0168 - mape: 35.2182 - mse: 0.0168 - rmse: 0.1296 - val_loss: 0.0169 - val_mape: 26.5692 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 33/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0164 - mape: 34.3656 - mse: 0.0164 - rmse: 0.1278 - val_loss: 0.0166 - val_mape: 26.6252 - val_mse: 0.0166 - val_rmse: 0.1288\n",
      "Epoch 34/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0165 - mape: 34.5179 - mse: 0.0165 - rmse: 0.1285 - val_loss: 0.0165 - val_mape: 26.6324 - val_mse: 0.0165 - val_rmse: 0.1285\n",
      "Epoch 35/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0165 - mape: 35.2639 - mse: 0.0165 - rmse: 0.1285 - val_loss: 0.0162 - val_mape: 26.6022 - val_mse: 0.0162 - val_rmse: 0.1273\n",
      "Epoch 36/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0163 - mape: 34.3940 - mse: 0.0163 - rmse: 0.1278 - val_loss: 0.0162 - val_mape: 26.8623 - val_mse: 0.0162 - val_rmse: 0.1272\n",
      "Epoch 37/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0163 - mape: 33.9656 - mse: 0.0163 - rmse: 0.1275 - val_loss: 0.0162 - val_mape: 27.4298 - val_mse: 0.0162 - val_rmse: 0.1273\n",
      "Epoch 38/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0163 - mape: 34.5030 - mse: 0.0163 - rmse: 0.1277 - val_loss: 0.0166 - val_mape: 26.0852 - val_mse: 0.0166 - val_rmse: 0.1288\n",
      "Epoch 39/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0163 - mape: 34.3527 - mse: 0.0163 - rmse: 0.1275 - val_loss: 0.0194 - val_mape: 34.9352 - val_mse: 0.0193 - val_rmse: 0.1391\n",
      "Epoch 40/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0160 - mape: 34.3590 - mse: 0.0160 - rmse: 0.1266 - val_loss: 0.0168 - val_mape: 26.9557 - val_mse: 0.0168 - val_rmse: 0.1294\n",
      "Epoch 41/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0164 - mape: 34.5566 - mse: 0.0164 - rmse: 0.1279 - val_loss: 0.0173 - val_mape: 26.7417 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 42/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0162 - mape: 34.5122 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0204 - val_mape: 37.7152 - val_mse: 0.0204 - val_rmse: 0.1430\n",
      "Epoch 43/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0158 - mape: 33.4361 - mse: 0.0158 - rmse: 0.1258 - val_loss: 0.0175 - val_mape: 26.4907 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 44/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0161 - mape: 34.6103 - mse: 0.0161 - rmse: 0.1268 - val_loss: 0.0167 - val_mape: 26.3958 - val_mse: 0.0167 - val_rmse: 0.1291\n",
      "Epoch 45/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0160 - mape: 33.2226 - mse: 0.0160 - rmse: 0.1265 - val_loss: 0.0169 - val_mape: 26.2853 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 46/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0162 - mape: 33.7813 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0166 - val_mape: 26.1821 - val_mse: 0.0166 - val_rmse: 0.1289\n",
      "Epoch 47/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0159 - mape: 32.9155 - mse: 0.0159 - rmse: 0.1259 - val_loss: 0.0175 - val_mape: 26.5017 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 48/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0159 - mape: 33.9885 - mse: 0.0159 - rmse: 0.1260 - val_loss: 0.0176 - val_mape: 27.6287 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 49/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0159 - mape: 32.9340 - mse: 0.0159 - rmse: 0.1261 - val_loss: 0.0166 - val_mape: 28.3254 - val_mse: 0.0166 - val_rmse: 0.1290\n",
      "Epoch 50/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0161 - mape: 34.7043 - mse: 0.0161 - rmse: 0.1269 - val_loss: 0.0168 - val_mape: 26.0810 - val_mse: 0.0168 - val_rmse: 0.1295\n",
      "PROCESANDO ARCHIVO: Juniperus turkestanica Komar.\n",
      "(6305, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus turkestanica Komar._best_models.json\n",
      "(3664, 4, 43) (1368, 4, 43) (1001, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 28 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m53,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m61,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,757</span> (1.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m472,757\u001b[0m (1.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,585</span> (615.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m157,585\u001b[0m (615.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,172</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m315,172\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0170 - mape: 30.5958 - mse: 0.0170 - rmse: 0.1304 - val_loss: 0.0176 - val_mape: 34.3692 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 2/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168 - mape: 30.4537 - mse: 0.0168 - rmse: 0.1298 - val_loss: 0.0178 - val_mape: 35.2564 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 3/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0164 - mape: 29.6322 - mse: 0.0164 - rmse: 0.1282 - val_loss: 0.0171 - val_mape: 30.9078 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 4/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - mape: 29.3016 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0168 - val_mape: 31.9212 - val_mse: 0.0168 - val_rmse: 0.1296\n",
      "Epoch 5/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0165 - mape: 28.8936 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0172 - val_mape: 30.9397 - val_mse: 0.0171 - val_rmse: 0.1310\n",
      "Epoch 6/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0164 - mape: 28.9854 - mse: 0.0164 - rmse: 0.1279 - val_loss: 0.0172 - val_mape: 32.0123 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 7/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166 - mape: 29.5002 - mse: 0.0166 - rmse: 0.1286 - val_loss: 0.0187 - val_mape: 33.3295 - val_mse: 0.0187 - val_rmse: 0.1366\n",
      "Epoch 8/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162 - mape: 29.9854 - mse: 0.0162 - rmse: 0.1271 - val_loss: 0.0185 - val_mape: 36.7068 - val_mse: 0.0185 - val_rmse: 0.1359\n",
      "Epoch 9/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mape: 28.7330 - mse: 0.0163 - rmse: 0.1274 - val_loss: 0.0178 - val_mape: 35.3279 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 10/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162 - mape: 29.2891 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0180 - val_mape: 34.5021 - val_mse: 0.0180 - val_rmse: 0.1340\n",
      "Epoch 11/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0158 - mape: 29.4413 - mse: 0.0158 - rmse: 0.1258 - val_loss: 0.0180 - val_mape: 36.0949 - val_mse: 0.0180 - val_rmse: 0.1341\n",
      "Epoch 12/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0159 - mape: 30.3419 - mse: 0.0159 - rmse: 0.1259 - val_loss: 0.0177 - val_mape: 35.9063 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 13/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0161 - mape: 29.1189 - mse: 0.0161 - rmse: 0.1269 - val_loss: 0.0179 - val_mape: 35.7857 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 14/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0156 - mape: 28.8289 - mse: 0.0156 - rmse: 0.1250 - val_loss: 0.0179 - val_mape: 36.2196 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 15/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mape: 28.7493 - mse: 0.0157 - rmse: 0.1251 - val_loss: 0.0182 - val_mape: 36.6326 - val_mse: 0.0183 - val_rmse: 0.1351\n",
      "Epoch 16/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mape: 28.6483 - mse: 0.0153 - rmse: 0.1236 - val_loss: 0.0180 - val_mape: 36.1886 - val_mse: 0.0180 - val_rmse: 0.1340\n",
      "Epoch 17/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162 - mape: 29.9691 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0164 - val_mape: 32.1717 - val_mse: 0.0165 - val_rmse: 0.1282\n",
      "Epoch 18/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162 - mape: 29.9334 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0178 - val_mape: 35.6552 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 19/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mape: 29.3695 - mse: 0.0155 - rmse: 0.1244 - val_loss: 0.0175 - val_mape: 35.2588 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 20/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mape: 28.7986 - mse: 0.0154 - rmse: 0.1241 - val_loss: 0.0175 - val_mape: 35.2295 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 21/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mape: 27.8282 - mse: 0.0152 - rmse: 0.1232 - val_loss: 0.0187 - val_mape: 36.8101 - val_mse: 0.0187 - val_rmse: 0.1369\n",
      "Epoch 22/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mape: 28.8985 - mse: 0.0153 - rmse: 0.1237 - val_loss: 0.0183 - val_mape: 35.1805 - val_mse: 0.0183 - val_rmse: 0.1353\n",
      "Epoch 23/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0154 - mape: 28.1268 - mse: 0.0154 - rmse: 0.1240 - val_loss: 0.0187 - val_mape: 38.1638 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 24/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - mape: 30.2480 - mse: 0.0160 - rmse: 0.1264 - val_loss: 0.0184 - val_mape: 36.5646 - val_mse: 0.0184 - val_rmse: 0.1357\n",
      "Epoch 25/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mape: 28.9511 - mse: 0.0155 - rmse: 0.1245 - val_loss: 0.0185 - val_mape: 37.6936 - val_mse: 0.0185 - val_rmse: 0.1360\n",
      "Epoch 26/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mape: 28.3341 - mse: 0.0153 - rmse: 0.1237 - val_loss: 0.0175 - val_mape: 35.6001 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 27/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mape: 28.7568 - mse: 0.0151 - rmse: 0.1229 - val_loss: 0.0180 - val_mape: 35.9142 - val_mse: 0.0180 - val_rmse: 0.1342\n",
      "Epoch 28/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mape: 28.6792 - mse: 0.0151 - rmse: 0.1230 - val_loss: 0.0174 - val_mape: 35.0970 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 29/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mape: 28.9505 - mse: 0.0153 - rmse: 0.1235 - val_loss: 0.0172 - val_mape: 35.3590 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 30/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0152 - mape: 28.8730 - mse: 0.0152 - rmse: 0.1232 - val_loss: 0.0181 - val_mape: 36.7283 - val_mse: 0.0182 - val_rmse: 0.1346\n",
      "Epoch 31/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mape: 27.4972 - mse: 0.0151 - rmse: 0.1229 - val_loss: 0.0177 - val_mape: 35.8730 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 32/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - mape: 28.3610 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0181 - val_mape: 35.7956 - val_mse: 0.0181 - val_rmse: 0.1345\n",
      "Epoch 33/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0148 - mape: 28.0451 - mse: 0.0148 - rmse: 0.1214 - val_loss: 0.0175 - val_mape: 35.0161 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 34/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mape: 28.2304 - mse: 0.0147 - rmse: 0.1212 - val_loss: 0.0170 - val_mape: 34.4433 - val_mse: 0.0171 - val_rmse: 0.1305\n",
      "Epoch 35/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mape: 28.0853 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0178 - val_mape: 36.3910 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 36/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0151 - mape: 28.4492 - mse: 0.0151 - rmse: 0.1227 - val_loss: 0.0172 - val_mape: 33.6411 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 37/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0145 - mape: 28.8100 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0176 - val_mape: 34.2033 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "PROCESANDO ARCHIVO: Populus ciliata\n",
      "(1182, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Populus ciliata_best_models.json\n",
      "(705, 4, 43) (156, 4, 43) (265, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m27,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │        \u001b[38;5;34m74,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">865,637</span> (3.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m865,637\u001b[0m (3.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288,545</span> (1.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m288,545\u001b[0m (1.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">577,092</span> (2.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m577,092\u001b[0m (2.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0245 - mape: 43.2212 - mse: 0.0245 - rmse: 0.1564 - val_loss: 0.0247 - val_mape: 41.9260 - val_mse: 0.0250 - val_rmse: 0.1572\n",
      "Epoch 2/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0204 - mape: 39.1989 - mse: 0.0204 - rmse: 0.1427 - val_loss: 0.0222 - val_mape: 38.7051 - val_mse: 0.0225 - val_rmse: 0.1492\n",
      "Epoch 3/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0191 - mape: 37.1774 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0214 - val_mape: 40.1973 - val_mse: 0.0217 - val_rmse: 0.1462\n",
      "Epoch 4/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0178 - mape: 35.7910 - mse: 0.0178 - rmse: 0.1332 - val_loss: 0.0212 - val_mape: 38.9255 - val_mse: 0.0214 - val_rmse: 0.1454\n",
      "Epoch 5/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - mape: 33.6670 - mse: 0.0171 - rmse: 0.1305 - val_loss: 0.0204 - val_mape: 39.3425 - val_mse: 0.0206 - val_rmse: 0.1430\n",
      "Epoch 6/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0173 - mape: 34.2231 - mse: 0.0173 - rmse: 0.1312 - val_loss: 0.0195 - val_mape: 39.5869 - val_mse: 0.0196 - val_rmse: 0.1397\n",
      "Epoch 7/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0170 - mape: 34.7495 - mse: 0.0170 - rmse: 0.1303 - val_loss: 0.0191 - val_mape: 37.8108 - val_mse: 0.0193 - val_rmse: 0.1381\n",
      "Epoch 8/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0172 - mape: 34.7424 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0188 - val_mape: 37.2627 - val_mse: 0.0191 - val_rmse: 0.1371\n",
      "Epoch 9/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0171 - mape: 33.6335 - mse: 0.0171 - rmse: 0.1305 - val_loss: 0.0189 - val_mape: 37.5195 - val_mse: 0.0192 - val_rmse: 0.1376\n",
      "Epoch 10/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0172 - mape: 35.7883 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0180 - val_mape: 36.6528 - val_mse: 0.0182 - val_rmse: 0.1341\n",
      "Epoch 11/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0166 - mape: 35.2172 - mse: 0.0166 - rmse: 0.1287 - val_loss: 0.0177 - val_mape: 37.8409 - val_mse: 0.0179 - val_rmse: 0.1331\n",
      "Epoch 12/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0160 - mape: 34.8656 - mse: 0.0160 - rmse: 0.1262 - val_loss: 0.0180 - val_mape: 35.0283 - val_mse: 0.0181 - val_rmse: 0.1343\n",
      "Epoch 13/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0160 - mape: 34.6753 - mse: 0.0160 - rmse: 0.1264 - val_loss: 0.0176 - val_mape: 35.2639 - val_mse: 0.0178 - val_rmse: 0.1327\n",
      "Epoch 14/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0152 - mape: 33.3917 - mse: 0.0152 - rmse: 0.1230 - val_loss: 0.0187 - val_mape: 35.7261 - val_mse: 0.0189 - val_rmse: 0.1369\n",
      "Epoch 15/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0154 - mape: 31.2920 - mse: 0.0154 - rmse: 0.1238 - val_loss: 0.0196 - val_mape: 38.9163 - val_mse: 0.0197 - val_rmse: 0.1399\n",
      "Epoch 16/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0154 - mape: 31.8079 - mse: 0.0154 - rmse: 0.1239 - val_loss: 0.0197 - val_mape: 38.4040 - val_mse: 0.0199 - val_rmse: 0.1405\n",
      "Epoch 17/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0154 - mape: 31.9595 - mse: 0.0154 - rmse: 0.1239 - val_loss: 0.0198 - val_mape: 40.5030 - val_mse: 0.0199 - val_rmse: 0.1406\n",
      "Epoch 18/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - mape: 32.1644 - mse: 0.0150 - rmse: 0.1223 - val_loss: 0.0196 - val_mape: 41.7089 - val_mse: 0.0197 - val_rmse: 0.1400\n",
      "Epoch 19/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0152 - mape: 33.2546 - mse: 0.0151 - rmse: 0.1229 - val_loss: 0.0178 - val_mape: 39.0591 - val_mse: 0.0179 - val_rmse: 0.1334\n",
      "Epoch 20/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0145 - mape: 31.9525 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0186 - val_mape: 38.6992 - val_mse: 0.0187 - val_rmse: 0.1364\n",
      "Epoch 21/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - mape: 33.5430 - mse: 0.0150 - rmse: 0.1223 - val_loss: 0.0177 - val_mape: 37.5711 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 22/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0148 - mape: 32.9069 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0170 - val_mape: 36.6739 - val_mse: 0.0171 - val_rmse: 0.1304\n",
      "Epoch 23/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0147 - mape: 32.6483 - mse: 0.0147 - rmse: 0.1210 - val_loss: 0.0174 - val_mape: 38.7223 - val_mse: 0.0175 - val_rmse: 0.1319\n",
      "Epoch 24/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0141 - mape: 32.7161 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0169 - val_mape: 35.3767 - val_mse: 0.0170 - val_rmse: 0.1299\n",
      "Epoch 25/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0142 - mape: 31.2692 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0170 - val_mape: 35.1931 - val_mse: 0.0172 - val_rmse: 0.1305\n",
      "Epoch 26/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0150 - mape: 32.3135 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0177 - val_mape: 36.9385 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 27/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0146 - mape: 31.1838 - mse: 0.0146 - rmse: 0.1207 - val_loss: 0.0175 - val_mape: 36.7240 - val_mse: 0.0176 - val_rmse: 0.1323\n",
      "Epoch 28/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0145 - mape: 31.8580 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0167 - val_mape: 36.6719 - val_mse: 0.0167 - val_rmse: 0.1290\n",
      "Epoch 29/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - mape: 31.5508 - mse: 0.0138 - rmse: 0.1173 - val_loss: 0.0171 - val_mape: 33.8204 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 30/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0142 - mape: 30.4654 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0171 - val_mape: 35.0363 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 31/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0144 - mape: 32.4427 - mse: 0.0144 - rmse: 0.1198 - val_loss: 0.0169 - val_mape: 35.6752 - val_mse: 0.0168 - val_rmse: 0.1299\n",
      "Epoch 32/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0144 - mape: 32.6156 - mse: 0.0144 - rmse: 0.1199 - val_loss: 0.0177 - val_mape: 41.1555 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 33/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - mape: 32.8432 - mse: 0.0136 - rmse: 0.1164 - val_loss: 0.0174 - val_mape: 34.6727 - val_mse: 0.0175 - val_rmse: 0.1319\n",
      "Epoch 34/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0143 - mape: 32.3413 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0165 - val_mape: 36.5605 - val_mse: 0.0166 - val_rmse: 0.1286\n",
      "Epoch 35/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - mape: 31.2047 - mse: 0.0130 - rmse: 0.1137 - val_loss: 0.0168 - val_mape: 36.8646 - val_mse: 0.0168 - val_rmse: 0.1294\n",
      "Epoch 36/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - mape: 31.2475 - mse: 0.0132 - rmse: 0.1147 - val_loss: 0.0168 - val_mape: 35.3967 - val_mse: 0.0168 - val_rmse: 0.1295\n",
      "Epoch 37/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0136 - mape: 30.7173 - mse: 0.0136 - rmse: 0.1165 - val_loss: 0.0165 - val_mape: 37.6242 - val_mse: 0.0166 - val_rmse: 0.1283\n",
      "Epoch 38/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - mape: 30.8898 - mse: 0.0135 - rmse: 0.1162 - val_loss: 0.0170 - val_mape: 35.5011 - val_mse: 0.0169 - val_rmse: 0.1303\n",
      "Epoch 39/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 - mape: 30.2240 - mse: 0.0131 - rmse: 0.1145 - val_loss: 0.0169 - val_mape: 38.5415 - val_mse: 0.0170 - val_rmse: 0.1302\n",
      "Epoch 40/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0134 - mape: 31.8048 - mse: 0.0134 - rmse: 0.1157 - val_loss: 0.0178 - val_mape: 42.1232 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 41/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0132 - mape: 32.9207 - mse: 0.0132 - rmse: 0.1147 - val_loss: 0.0167 - val_mape: 37.2630 - val_mse: 0.0168 - val_rmse: 0.1292\n",
      "Epoch 42/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0129 - mape: 30.6337 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0163 - val_mape: 38.1026 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 43/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - mape: 30.9473 - mse: 0.0125 - rmse: 0.1118 - val_loss: 0.0167 - val_mape: 37.3761 - val_mse: 0.0167 - val_rmse: 0.1291\n",
      "Epoch 44/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - mape: 31.4888 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0171 - val_mape: 38.4457 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 45/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - mape: 32.3510 - mse: 0.0129 - rmse: 0.1136 - val_loss: 0.0205 - val_mape: 41.2846 - val_mse: 0.0205 - val_rmse: 0.1432\n",
      "Epoch 46/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - mape: 30.3676 - mse: 0.0137 - rmse: 0.1168 - val_loss: 0.0174 - val_mape: 40.0913 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 47/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127 - mape: 31.3340 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0181 - val_mape: 40.2944 - val_mse: 0.0182 - val_rmse: 0.1347\n",
      "Epoch 48/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - mape: 31.7820 - mse: 0.0130 - rmse: 0.1137 - val_loss: 0.0174 - val_mape: 37.3500 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 49/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0129 - mape: 32.0702 - mse: 0.0129 - rmse: 0.1134 - val_loss: 0.0184 - val_mape: 42.5912 - val_mse: 0.0183 - val_rmse: 0.1356\n",
      "Epoch 50/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - mape: 33.2824 - mse: 0.0130 - rmse: 0.1140 - val_loss: 0.0176 - val_mape: 37.9543 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 51/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mape: 32.5320 - mse: 0.0130 - rmse: 0.1141 - val_loss: 0.0177 - val_mape: 39.2538 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 52/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - mape: 32.5615 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0170 - val_mape: 37.2693 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 53/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - mape: 30.2708 - mse: 0.0124 - rmse: 0.1113 - val_loss: 0.0177 - val_mape: 40.6882 - val_mse: 0.0176 - val_rmse: 0.1329\n",
      "Epoch 54/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0125 - mape: 32.0221 - mse: 0.0125 - rmse: 0.1115 - val_loss: 0.0170 - val_mape: 40.0044 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 55/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - mape: 31.8421 - mse: 0.0121 - rmse: 0.1097 - val_loss: 0.0175 - val_mape: 38.3333 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 56/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0126 - mape: 32.3418 - mse: 0.0126 - rmse: 0.1120 - val_loss: 0.0184 - val_mape: 38.7695 - val_mse: 0.0183 - val_rmse: 0.1356\n",
      "Epoch 57/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mape: 32.7663 - mse: 0.0131 - rmse: 0.1142 - val_loss: 0.0206 - val_mape: 44.5728 - val_mse: 0.0205 - val_rmse: 0.1436\n",
      "Epoch 58/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - mape: 32.1315 - mse: 0.0135 - rmse: 0.1159 - val_loss: 0.0196 - val_mape: 41.1856 - val_mse: 0.0195 - val_rmse: 0.1399\n",
      "Epoch 59/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mape: 30.4138 - mse: 0.0131 - rmse: 0.1143 - val_loss: 0.0202 - val_mape: 42.2470 - val_mse: 0.0202 - val_rmse: 0.1421\n",
      "Epoch 60/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - mape: 32.1493 - mse: 0.0141 - rmse: 0.1184 - val_loss: 0.0198 - val_mape: 41.2481 - val_mse: 0.0198 - val_rmse: 0.1407\n",
      "Epoch 61/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0131 - mape: 31.2468 - mse: 0.0131 - rmse: 0.1144 - val_loss: 0.0193 - val_mape: 40.2252 - val_mse: 0.0192 - val_rmse: 0.1388\n",
      "Epoch 62/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0130 - mape: 29.4613 - mse: 0.0130 - rmse: 0.1139 - val_loss: 0.0203 - val_mape: 40.9274 - val_mse: 0.0202 - val_rmse: 0.1424\n",
      "PROCESANDO ARCHIVO: Abies pindrow\n",
      "(16018, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Abies pindrow_best_models.json\n",
      "(9042, 4, 43) (3441, 4, 43) (2815, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m53,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m82,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │        \u001b[38;5;34m86,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m82,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m7,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m57\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,035,989</span> (3.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,035,989\u001b[0m (3.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">345,329</span> (1.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m345,329\u001b[0m (1.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">690,660</span> (2.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m690,660\u001b[0m (2.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0151 - mape: 26.1009 - mse: 0.0151 - rmse: 0.1229 - val_loss: 0.0125 - val_mape: 20.1037 - val_mse: 0.0125 - val_rmse: 0.1119\n",
      "Epoch 2/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0145 - mape: 25.6281 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0126 - val_mape: 20.4371 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 3/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0143 - mape: 25.2914 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0118 - val_mape: 20.7282 - val_mse: 0.0118 - val_rmse: 0.1085\n",
      "Epoch 4/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0143 - mape: 25.4909 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0125 - val_mape: 20.4723 - val_mse: 0.0125 - val_rmse: 0.1117\n",
      "Epoch 5/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0144 - mape: 25.5541 - mse: 0.0144 - rmse: 0.1199 - val_loss: 0.0119 - val_mape: 20.6555 - val_mse: 0.0119 - val_rmse: 0.1092\n",
      "Epoch 6/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0142 - mape: 25.3753 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0123 - val_mape: 20.5677 - val_mse: 0.0123 - val_rmse: 0.1109\n",
      "Epoch 7/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0140 - mape: 25.1715 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0122 - val_mape: 20.7490 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 8/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0140 - mape: 25.4098 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0117 - val_mape: 20.4850 - val_mse: 0.0117 - val_rmse: 0.1082\n",
      "Epoch 9/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0140 - mape: 25.2075 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0118 - val_mape: 21.2479 - val_mse: 0.0118 - val_rmse: 0.1086\n",
      "Epoch 10/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mape: 25.1248 - mse: 0.0139 - rmse: 0.1177 - val_loss: 0.0119 - val_mape: 21.0750 - val_mse: 0.0119 - val_rmse: 0.1090\n",
      "Epoch 11/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0137 - mape: 25.0534 - mse: 0.0137 - rmse: 0.1170 - val_loss: 0.0121 - val_mape: 20.6440 - val_mse: 0.0121 - val_rmse: 0.1102\n",
      "Epoch 12/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0135 - mape: 24.7996 - mse: 0.0135 - rmse: 0.1162 - val_loss: 0.0125 - val_mape: 20.1813 - val_mse: 0.0125 - val_rmse: 0.1118\n",
      "Epoch 13/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0137 - mape: 25.0173 - mse: 0.0137 - rmse: 0.1171 - val_loss: 0.0120 - val_mape: 20.3710 - val_mse: 0.0120 - val_rmse: 0.1097\n",
      "Epoch 14/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0138 - mape: 24.8845 - mse: 0.0138 - rmse: 0.1172 - val_loss: 0.0118 - val_mape: 20.5546 - val_mse: 0.0118 - val_rmse: 0.1088\n",
      "Epoch 15/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0137 - mape: 24.8571 - mse: 0.0137 - rmse: 0.1170 - val_loss: 0.0118 - val_mape: 20.9806 - val_mse: 0.0118 - val_rmse: 0.1086\n",
      "Epoch 16/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0138 - mape: 25.0818 - mse: 0.0138 - rmse: 0.1174 - val_loss: 0.0122 - val_mape: 20.4365 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 17/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0138 - mape: 25.0517 - mse: 0.0138 - rmse: 0.1174 - val_loss: 0.0121 - val_mape: 20.1990 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 18/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0137 - mape: 25.0591 - mse: 0.0137 - rmse: 0.1170 - val_loss: 0.0128 - val_mape: 19.6742 - val_mse: 0.0128 - val_rmse: 0.1133\n",
      "Epoch 19/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0139 - mape: 25.2476 - mse: 0.0139 - rmse: 0.1178 - val_loss: 0.0115 - val_mape: 20.3096 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 20/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0141 - mape: 25.5450 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0118 - val_mape: 20.5793 - val_mse: 0.0118 - val_rmse: 0.1085\n",
      "Epoch 21/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0138 - mape: 25.3382 - mse: 0.0138 - rmse: 0.1175 - val_loss: 0.0119 - val_mape: 20.7400 - val_mse: 0.0119 - val_rmse: 0.1090\n",
      "Epoch 22/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0137 - mape: 24.8389 - mse: 0.0137 - rmse: 0.1172 - val_loss: 0.0122 - val_mape: 22.8072 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 23/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0135 - mape: 24.9463 - mse: 0.0135 - rmse: 0.1163 - val_loss: 0.0118 - val_mape: 21.1312 - val_mse: 0.0118 - val_rmse: 0.1087\n",
      "Epoch 24/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0136 - mape: 25.1623 - mse: 0.0136 - rmse: 0.1166 - val_loss: 0.0125 - val_mape: 22.6518 - val_mse: 0.0125 - val_rmse: 0.1116\n",
      "Epoch 25/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0137 - mape: 25.2423 - mse: 0.0137 - rmse: 0.1169 - val_loss: 0.0119 - val_mape: 21.8030 - val_mse: 0.0119 - val_rmse: 0.1090\n",
      "Epoch 26/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0135 - mape: 24.9757 - mse: 0.0135 - rmse: 0.1160 - val_loss: 0.0119 - val_mape: 21.2894 - val_mse: 0.0119 - val_rmse: 0.1092\n",
      "Epoch 27/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0135 - mape: 25.1563 - mse: 0.0135 - rmse: 0.1162 - val_loss: 0.0118 - val_mape: 21.7714 - val_mse: 0.0118 - val_rmse: 0.1085\n",
      "Epoch 28/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0135 - mape: 24.7244 - mse: 0.0135 - rmse: 0.1160 - val_loss: 0.0117 - val_mape: 20.8482 - val_mse: 0.0117 - val_rmse: 0.1084\n",
      "Epoch 29/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0133 - mape: 24.6898 - mse: 0.0133 - rmse: 0.1153 - val_loss: 0.0119 - val_mape: 21.6538 - val_mse: 0.0119 - val_rmse: 0.1089\n",
      "Epoch 30/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0134 - mape: 24.6232 - mse: 0.0134 - rmse: 0.1156 - val_loss: 0.0118 - val_mape: 20.0378 - val_mse: 0.0118 - val_rmse: 0.1087\n",
      "Epoch 31/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0134 - mape: 25.1355 - mse: 0.0134 - rmse: 0.1159 - val_loss: 0.0118 - val_mape: 21.0109 - val_mse: 0.0119 - val_rmse: 0.1089\n",
      "Epoch 32/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0132 - mape: 24.5624 - mse: 0.0132 - rmse: 0.1150 - val_loss: 0.0120 - val_mape: 20.7209 - val_mse: 0.0120 - val_rmse: 0.1095\n",
      "Epoch 33/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0133 - mape: 24.5841 - mse: 0.0133 - rmse: 0.1151 - val_loss: 0.0117 - val_mape: 21.1135 - val_mse: 0.0117 - val_rmse: 0.1081\n",
      "Epoch 34/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0133 - mape: 24.5743 - mse: 0.0133 - rmse: 0.1151 - val_loss: 0.0116 - val_mape: 21.3939 - val_mse: 0.0116 - val_rmse: 0.1079\n",
      "Epoch 35/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0131 - mape: 24.6663 - mse: 0.0131 - rmse: 0.1144 - val_loss: 0.0117 - val_mape: 20.4686 - val_mse: 0.0117 - val_rmse: 0.1080\n",
      "Epoch 36/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0132 - mape: 24.5967 - mse: 0.0132 - rmse: 0.1148 - val_loss: 0.0118 - val_mape: 20.2662 - val_mse: 0.0118 - val_rmse: 0.1086\n",
      "Epoch 37/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0130 - mape: 24.2952 - mse: 0.0130 - rmse: 0.1142 - val_loss: 0.0120 - val_mape: 21.5107 - val_mse: 0.0120 - val_rmse: 0.1094\n",
      "Epoch 38/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0131 - mape: 24.4241 - mse: 0.0131 - rmse: 0.1145 - val_loss: 0.0119 - val_mape: 20.8874 - val_mse: 0.0119 - val_rmse: 0.1091\n",
      "Epoch 39/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0130 - mape: 24.3611 - mse: 0.0130 - rmse: 0.1138 - val_loss: 0.0121 - val_mape: 21.4365 - val_mse: 0.0121 - val_rmse: 0.1100\n"
     ]
    }
   ],
   "source": [
    "for archivo in os.listdir(\"models/LSTMMerged_22_10_24\"):\n",
    "\n",
    "    # Leemos solo los archivos json para obtener los nombres\n",
    "    if os.path.splitext(archivo)[1] == \".json\":\n",
    "        \n",
    "        # Obtenemos el nombre de archivo\n",
    "        nombreArchivo = archivo.split(\"_best_models.json\")[0]\n",
    "\n",
    "        print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "        # Cargamos el modelo entrenado\n",
    "        df = pd.read_csv(f'RCPMerged/{nombreArchivo}_merged.csv')\n",
    "        df = df[~df[\"nametag\"].str.startswith(\"INDI005\")]\n",
    "\n",
    "        # Codificamos, normalización y split de datos\n",
    "        df = codification(df)\n",
    "        print(df.shape)\n",
    "\n",
    "        df, valorNormalizacion = individualNormalization(df)\n",
    "        print(f\"SE HA NORMALIZADO EL ARCHIVO: {archivo}\")\n",
    "\n",
    "        temp_df = df\n",
    "        train_data, val_data, test_data = split_population_individuals(temp_df, train_pct=0.80, val_pct_in_train=0.20, details=False)\n",
    "        train_data.shape, val_data.shape, test_data.shape\n",
    "\n",
    "        # Obtenemos X e y para los datasets de train, val y test \n",
    "        WINDOWS_SIZE = 3\n",
    "        X_train, y_train = df_to_X_y_ind_3(train_data, WINDOWS_SIZE)\n",
    "        X_val, y_val = df_to_X_y_ind_3(val_data, WINDOWS_SIZE)\n",
    "        X_test, y_test = df_to_X_y_ind_3(test_data, WINDOWS_SIZE)\n",
    "        print(X_train.shape, X_test.shape, X_val.shape)\n",
    "\n",
    "        # Cargamos el modelo global\n",
    "        modelLSTM = tf.keras.models.load_model(f'models/LSTMMerged_22_10_24/{nombreArchivo}_model_1.keras')\n",
    "\n",
    "        print(modelLSTM.summary())\n",
    "\n",
    "        # Obtenemos el valor de batch size\n",
    "        with open(f'models/LSTMMerged_22_10_24/{archivo}') as f:\n",
    "            parameters = json.load(f)\n",
    "\n",
    "        batch_size_LSTM = parameters[0][\"batch_size\"]\n",
    "\n",
    "        historyLSTMTransfer = modelLSTM.fit(X_train, y_train, epochs=200, batch_size=batch_size_LSTM,\n",
    "                            validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss', patience=20)])\n",
    "        \n",
    "        modelLSTM.save(f\"models/LSTMMerged_22_10_24_Trained/{nombreArchivo}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: Pinus wallichiana\n",
      "(9365, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus wallichiana_best_models.json\n",
      "(5508, 4, 43) (1957, 4, 43) (1500, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0108 - mape: 20.3181 - mse: 0.0108 - rmse: 0.1038 - val_loss: 0.0109 - val_mape: 19.9513 - val_mse: 0.0109 - val_rmse: 0.1042\n",
      "Epoch 2/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0104 - mape: 19.7378 - mse: 0.0104 - rmse: 0.1018 - val_loss: 0.0108 - val_mape: 20.0018 - val_mse: 0.0109 - val_rmse: 0.1040\n",
      "Epoch 3/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.7699 - mse: 0.0104 - rmse: 0.1021 - val_loss: 0.0108 - val_mape: 19.8712 - val_mse: 0.0108 - val_rmse: 0.1038\n",
      "Epoch 4/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.3486 - mse: 0.0103 - rmse: 0.1014 - val_loss: 0.0108 - val_mape: 19.8540 - val_mse: 0.0108 - val_rmse: 0.1038\n",
      "Epoch 5/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0107 - mape: 19.7278 - mse: 0.0107 - rmse: 0.1034 - val_loss: 0.0108 - val_mape: 20.0030 - val_mse: 0.0109 - val_rmse: 0.1041\n",
      "Epoch 6/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0105 - mape: 19.5653 - mse: 0.0105 - rmse: 0.1024 - val_loss: 0.0108 - val_mape: 19.8932 - val_mse: 0.0108 - val_rmse: 0.1037\n",
      "Epoch 7/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.2315 - mse: 0.0103 - rmse: 0.1017 - val_loss: 0.0108 - val_mape: 20.1266 - val_mse: 0.0109 - val_rmse: 0.1041\n",
      "Epoch 8/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0105 - mape: 19.7712 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0107 - val_mape: 19.6943 - val_mse: 0.0108 - val_rmse: 0.1036\n",
      "Epoch 9/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.4295 - mse: 0.0104 - rmse: 0.1022 - val_loss: 0.0107 - val_mape: 19.9094 - val_mse: 0.0108 - val_rmse: 0.1037\n",
      "Epoch 10/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0101 - mape: 19.1519 - mse: 0.0101 - rmse: 0.1004 - val_loss: 0.0108 - val_mape: 19.7646 - val_mse: 0.0108 - val_rmse: 0.1038\n",
      "Epoch 11/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.0869 - mse: 0.0103 - rmse: 0.1014 - val_loss: 0.0108 - val_mape: 19.9660 - val_mse: 0.0109 - val_rmse: 0.1040\n",
      "Epoch 12/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.4058 - mse: 0.0104 - rmse: 0.1022 - val_loss: 0.0107 - val_mape: 19.7501 - val_mse: 0.0108 - val_rmse: 0.1035\n",
      "Epoch 13/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.5438 - mse: 0.0104 - rmse: 0.1021 - val_loss: 0.0107 - val_mape: 19.8941 - val_mse: 0.0108 - val_rmse: 0.1035\n",
      "Epoch 14/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.4436 - mse: 0.0102 - rmse: 0.1012 - val_loss: 0.0107 - val_mape: 19.8292 - val_mse: 0.0108 - val_rmse: 0.1036\n",
      "Epoch 15/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.6882 - mse: 0.0104 - rmse: 0.1017 - val_loss: 0.0107 - val_mape: 19.5306 - val_mse: 0.0107 - val_rmse: 0.1033\n",
      "Epoch 16/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.8442 - mse: 0.0104 - rmse: 0.1022 - val_loss: 0.0107 - val_mape: 19.7563 - val_mse: 0.0108 - val_rmse: 0.1034\n",
      "Epoch 17/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.4532 - mse: 0.0103 - rmse: 0.1017 - val_loss: 0.0107 - val_mape: 19.8490 - val_mse: 0.0108 - val_rmse: 0.1036\n",
      "Epoch 18/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.3525 - mse: 0.0103 - rmse: 0.1015 - val_loss: 0.0107 - val_mape: 19.5113 - val_mse: 0.0108 - val_rmse: 0.1034\n",
      "Epoch 19/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.3724 - mse: 0.0104 - rmse: 0.1017 - val_loss: 0.0107 - val_mape: 19.6262 - val_mse: 0.0107 - val_rmse: 0.1034\n",
      "Epoch 20/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.1015 - mse: 0.0103 - rmse: 0.1015 - val_loss: 0.0107 - val_mape: 19.6483 - val_mse: 0.0107 - val_rmse: 0.1033\n",
      "Epoch 21/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.2557 - mse: 0.0104 - rmse: 0.1019 - val_loss: 0.0107 - val_mape: 19.8248 - val_mse: 0.0108 - val_rmse: 0.1036\n",
      "Epoch 22/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.6335 - mse: 0.0103 - rmse: 0.1013 - val_loss: 0.0107 - val_mape: 19.8488 - val_mse: 0.0107 - val_rmse: 0.1034\n",
      "Epoch 23/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.2859 - mse: 0.0102 - rmse: 0.1009 - val_loss: 0.0107 - val_mape: 19.6283 - val_mse: 0.0108 - val_rmse: 0.1035\n",
      "Epoch 24/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.6109 - mse: 0.0102 - rmse: 0.1011 - val_loss: 0.0106 - val_mape: 19.5404 - val_mse: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 25/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0101 - mape: 19.3387 - mse: 0.0101 - rmse: 0.1006 - val_loss: 0.0106 - val_mape: 19.5910 - val_mse: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 26/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0104 - mape: 19.4350 - mse: 0.0104 - rmse: 0.1022 - val_loss: 0.0107 - val_mape: 19.7282 - val_mse: 0.0108 - val_rmse: 0.1034\n",
      "Epoch 27/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.5259 - mse: 0.0103 - rmse: 0.1015 - val_loss: 0.0107 - val_mape: 19.8353 - val_mse: 0.0107 - val_rmse: 0.1034\n",
      "Epoch 28/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.6442 - mse: 0.0103 - rmse: 0.1014 - val_loss: 0.0106 - val_mape: 19.4311 - val_mse: 0.0107 - val_rmse: 0.1029\n",
      "Epoch 29/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0101 - mape: 19.0254 - mse: 0.0101 - rmse: 0.1007 - val_loss: 0.0107 - val_mape: 19.7379 - val_mse: 0.0108 - val_rmse: 0.1034\n",
      "Epoch 30/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.3021 - mse: 0.0102 - rmse: 0.1011 - val_loss: 0.0106 - val_mape: 19.7659 - val_mse: 0.0107 - val_rmse: 0.1031\n",
      "Epoch 31/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0103 - mape: 19.4407 - mse: 0.0103 - rmse: 0.1013 - val_loss: 0.0106 - val_mape: 19.8771 - val_mse: 0.0107 - val_rmse: 0.1031\n",
      "Epoch 32/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.6539 - mse: 0.0102 - rmse: 0.1010 - val_loss: 0.0107 - val_mape: 19.5754 - val_mse: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 33/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.6370 - mse: 0.0102 - rmse: 0.1010 - val_loss: 0.0106 - val_mape: 19.7106 - val_mse: 0.0107 - val_rmse: 0.1031\n",
      "Epoch 34/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.7001 - mse: 0.0102 - rmse: 0.1009 - val_loss: 0.0107 - val_mape: 19.5811 - val_mse: 0.0107 - val_rmse: 0.1032\n",
      "Epoch 35/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.1456 - mse: 0.0102 - rmse: 0.1009 - val_loss: 0.0107 - val_mape: 19.7547 - val_mse: 0.0107 - val_rmse: 0.1033\n",
      "Epoch 36/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.4858 - mse: 0.0102 - rmse: 0.1011 - val_loss: 0.0106 - val_mape: 19.4417 - val_mse: 0.0107 - val_rmse: 0.1031\n",
      "Epoch 37/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.1740 - mse: 0.0102 - rmse: 0.1011 - val_loss: 0.0106 - val_mape: 19.5071 - val_mse: 0.0107 - val_rmse: 0.1030\n",
      "Epoch 38/200\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0102 - mape: 19.3623 - mse: 0.0102 - rmse: 0.1010 - val_loss: 0.0106 - val_mape: 19.5720 - val_mse: 0.0107 - val_rmse: 0.1030\n",
      "[MODELO CONGELADO]: 94.43665289878845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 6.121465170418535, 2.474159487668193, 0.9091929493359101, 14.227970213192243\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 5.848367371314177, 2.418339796495558, 0.9021739707723718, 15.69187719907856\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.068032541857075, 2.840428232125761, 0.8086495324397857, 18.949196142172305\n",
      "PROCESANDO ARCHIVO: Pinus gerardiana\n",
      "(10101, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus gerardiana_best_models.json\n",
      "(5767, 4, 43) (2181, 4, 43) (1745, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0150 - mape: 30.9217 - mse: 0.0150 - rmse: 0.1226 - val_loss: 0.0194 - val_mape: 38.3674 - val_mse: 0.0192 - val_rmse: 0.1393\n",
      "Epoch 2/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0150 - mape: 30.4411 - mse: 0.0150 - rmse: 0.1224 - val_loss: 0.0194 - val_mape: 38.0565 - val_mse: 0.0193 - val_rmse: 0.1393\n",
      "Epoch 3/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0150 - mape: 29.6629 - mse: 0.0150 - rmse: 0.1225 - val_loss: 0.0193 - val_mape: 37.4255 - val_mse: 0.0192 - val_rmse: 0.1390\n",
      "Epoch 4/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - mape: 29.6925 - mse: 0.0148 - rmse: 0.1217 - val_loss: 0.0193 - val_mape: 37.7977 - val_mse: 0.0192 - val_rmse: 0.1390\n",
      "Epoch 5/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0147 - mape: 29.2847 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0192 - val_mape: 37.4667 - val_mse: 0.0190 - val_rmse: 0.1386\n",
      "Epoch 6/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0145 - mape: 29.1049 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0193 - val_mape: 37.5960 - val_mse: 0.0191 - val_rmse: 0.1389\n",
      "Epoch 7/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0149 - mape: 30.0338 - mse: 0.0149 - rmse: 0.1219 - val_loss: 0.0192 - val_mape: 37.4282 - val_mse: 0.0191 - val_rmse: 0.1386\n",
      "Epoch 8/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0150 - mape: 29.7241 - mse: 0.0150 - rmse: 0.1225 - val_loss: 0.0192 - val_mape: 37.6288 - val_mse: 0.0190 - val_rmse: 0.1386\n",
      "Epoch 9/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0149 - mape: 29.4877 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0192 - val_mape: 37.4464 - val_mse: 0.0190 - val_rmse: 0.1384\n",
      "Epoch 10/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0150 - mape: 29.7366 - mse: 0.0150 - rmse: 0.1225 - val_loss: 0.0192 - val_mape: 37.3486 - val_mse: 0.0190 - val_rmse: 0.1384\n",
      "Epoch 11/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0146 - mape: 29.3457 - mse: 0.0146 - rmse: 0.1207 - val_loss: 0.0192 - val_mape: 37.2241 - val_mse: 0.0190 - val_rmse: 0.1384\n",
      "Epoch 12/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0150 - mape: 30.1493 - mse: 0.0150 - rmse: 0.1224 - val_loss: 0.0192 - val_mape: 37.4660 - val_mse: 0.0190 - val_rmse: 0.1384\n",
      "Epoch 13/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0147 - mape: 29.0646 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0193 - val_mape: 37.7514 - val_mse: 0.0191 - val_rmse: 0.1388\n",
      "Epoch 14/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0145 - mape: 29.2330 - mse: 0.0145 - rmse: 0.1206 - val_loss: 0.0192 - val_mape: 37.1605 - val_mse: 0.0190 - val_rmse: 0.1385\n",
      "Epoch 15/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0147 - mape: 29.2648 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0191 - val_mape: 37.2726 - val_mse: 0.0189 - val_rmse: 0.1382\n",
      "Epoch 16/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0145 - mape: 29.1971 - mse: 0.0145 - rmse: 0.1205 - val_loss: 0.0191 - val_mape: 37.4310 - val_mse: 0.0189 - val_rmse: 0.1381\n",
      "Epoch 17/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0147 - mape: 29.3995 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0191 - val_mape: 37.2520 - val_mse: 0.0189 - val_rmse: 0.1381\n",
      "Epoch 18/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0149 - mape: 29.8580 - mse: 0.0149 - rmse: 0.1219 - val_loss: 0.0190 - val_mape: 37.0199 - val_mse: 0.0189 - val_rmse: 0.1379\n",
      "Epoch 19/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - mape: 29.6949 - mse: 0.0148 - rmse: 0.1218 - val_loss: 0.0191 - val_mape: 37.4285 - val_mse: 0.0189 - val_rmse: 0.1381\n",
      "Epoch 20/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - mape: 29.2486 - mse: 0.0148 - rmse: 0.1215 - val_loss: 0.0191 - val_mape: 37.4188 - val_mse: 0.0190 - val_rmse: 0.1383\n",
      "Epoch 21/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0146 - mape: 29.9268 - mse: 0.0146 - rmse: 0.1206 - val_loss: 0.0191 - val_mape: 37.2808 - val_mse: 0.0189 - val_rmse: 0.1381\n",
      "Epoch 22/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0147 - mape: 29.5012 - mse: 0.0147 - rmse: 0.1213 - val_loss: 0.0191 - val_mape: 37.1890 - val_mse: 0.0190 - val_rmse: 0.1383\n",
      "Epoch 23/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0144 - mape: 29.1404 - mse: 0.0144 - rmse: 0.1200 - val_loss: 0.0192 - val_mape: 37.5115 - val_mse: 0.0190 - val_rmse: 0.1385\n",
      "Epoch 24/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - mape: 30.1511 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0191 - val_mape: 37.2008 - val_mse: 0.0189 - val_rmse: 0.1381\n",
      "Epoch 25/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - mape: 29.5134 - mse: 0.0148 - rmse: 0.1216 - val_loss: 0.0191 - val_mape: 37.2954 - val_mse: 0.0190 - val_rmse: 0.1383\n",
      "Epoch 26/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0148 - mape: 29.7788 - mse: 0.0148 - rmse: 0.1218 - val_loss: 0.0192 - val_mape: 37.2560 - val_mse: 0.0190 - val_rmse: 0.1384\n",
      "Epoch 27/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0146 - mape: 29.1262 - mse: 0.0146 - rmse: 0.1209 - val_loss: 0.0192 - val_mape: 37.2918 - val_mse: 0.0190 - val_rmse: 0.1384\n",
      "Epoch 28/200\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0147 - mape: 29.4013 - mse: 0.0147 - rmse: 0.1214 - val_loss: 0.0192 - val_mape: 37.7853 - val_mse: 0.0191 - val_rmse: 0.1387\n",
      "[MODELO CONGELADO]: 72.17138648033142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 6.051764715796212, 2.46003347859256, 0.844095497177946, 19.31026214769602\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 10.556041233049728, 3.2490061915991677, 0.7332310743298152, 23.27716508352816\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.518140532158116, 2.918585364891374, 0.7879764608064388, 22.22331630156465\n",
      "PROCESANDO ARCHIVO: Betula utilis\n",
      "(3473, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Betula utilis_best_models.json\n",
      "(2059, 4, 43) (665, 4, 43) (593, 4, 43)\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> False\n",
      "<LSTM name=lstm_5, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<LSTM name=lstm_6, built=True> False\n",
      "<LSTM name=lstm_7, built=True> True\n",
      "<Dense name=dense_2, built=True> True\n",
      "<Dropout name=dropout_3, built=True> True\n",
      "<Dense name=dense_3, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0108 - mape: 38.8665 - mse: 0.0108 - rmse: 0.1039 - val_loss: 0.0111 - val_mape: 24.0085 - val_mse: 0.0108 - val_rmse: 0.1054\n",
      "Epoch 2/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mape: 35.6147 - mse: 0.0095 - rmse: 0.0976 - val_loss: 0.0110 - val_mape: 23.9116 - val_mse: 0.0107 - val_rmse: 0.1050\n",
      "Epoch 3/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0093 - mape: 35.3089 - mse: 0.0093 - rmse: 0.0965 - val_loss: 0.0111 - val_mape: 23.9498 - val_mse: 0.0108 - val_rmse: 0.1052\n",
      "Epoch 4/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mape: 37.2174 - mse: 0.0094 - rmse: 0.0970 - val_loss: 0.0111 - val_mape: 23.8202 - val_mse: 0.0108 - val_rmse: 0.1055\n",
      "Epoch 5/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mape: 37.5127 - mse: 0.0094 - rmse: 0.0969 - val_loss: 0.0111 - val_mape: 23.9286 - val_mse: 0.0108 - val_rmse: 0.1054\n",
      "Epoch 6/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mape: 36.4602 - mse: 0.0094 - rmse: 0.0967 - val_loss: 0.0111 - val_mape: 24.0480 - val_mse: 0.0108 - val_rmse: 0.1054\n",
      "Epoch 7/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mape: 35.9688 - mse: 0.0094 - rmse: 0.0971 - val_loss: 0.0111 - val_mape: 24.1161 - val_mse: 0.0109 - val_rmse: 0.1055\n",
      "Epoch 8/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0096 - mape: 38.2196 - mse: 0.0096 - rmse: 0.0978 - val_loss: 0.0112 - val_mape: 23.9659 - val_mse: 0.0109 - val_rmse: 0.1056\n",
      "Epoch 9/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mape: 35.7858 - mse: 0.0094 - rmse: 0.0967 - val_loss: 0.0112 - val_mape: 23.9741 - val_mse: 0.0109 - val_rmse: 0.1057\n",
      "Epoch 10/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - mape: 36.4883 - mse: 0.0095 - rmse: 0.0976 - val_loss: 0.0111 - val_mape: 24.1639 - val_mse: 0.0109 - val_rmse: 0.1054\n",
      "Epoch 11/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0093 - mape: 35.5082 - mse: 0.0093 - rmse: 0.0962 - val_loss: 0.0112 - val_mape: 23.9697 - val_mse: 0.0109 - val_rmse: 0.1057\n",
      "Epoch 12/200\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0094 - mape: 36.0561 - mse: 0.0094 - rmse: 0.0969 - val_loss: 0.0112 - val_mape: 24.0484 - val_mse: 0.0109 - val_rmse: 0.1058\n",
      "[MODELO CONGELADO]: 12.33405351638794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 1.1275925421850308, 1.0618816045986628, 0.8335388252193242, 22.868666612205647\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.3001039973604722, 0.5478174854460857, 0.8437159719522567, 19.272614106771854\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.35692818812883215, 0.5974346726871752, 0.8636000025823003, 21.062249409233406\n",
      "PROCESANDO ARCHIVO: Picea smithiana\n",
      "(34476, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Picea smithiana_best_models.json\n",
      "(19933, 4, 43) (7272, 4, 43) (5863, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0113 - mape: 23.4943 - mse: 0.0113 - rmse: 0.1063 - val_loss: 0.0124 - val_mape: 25.5159 - val_mse: 0.0124 - val_rmse: 0.1112\n",
      "Epoch 2/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0112 - mape: 23.1360 - mse: 0.0112 - rmse: 0.1059 - val_loss: 0.0123 - val_mape: 25.5361 - val_mse: 0.0123 - val_rmse: 0.1111\n",
      "Epoch 3/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0111 - mape: 23.1335 - mse: 0.0111 - rmse: 0.1053 - val_loss: 0.0123 - val_mape: 25.3071 - val_mse: 0.0123 - val_rmse: 0.1110\n",
      "Epoch 4/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0111 - mape: 23.3168 - mse: 0.0111 - rmse: 0.1054 - val_loss: 0.0123 - val_mape: 25.3624 - val_mse: 0.0123 - val_rmse: 0.1109\n",
      "Epoch 5/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.9532 - mse: 0.0110 - rmse: 0.1049 - val_loss: 0.0123 - val_mape: 25.3692 - val_mse: 0.0123 - val_rmse: 0.1109\n",
      "Epoch 6/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.9553 - mse: 0.0110 - rmse: 0.1050 - val_loss: 0.0123 - val_mape: 25.3999 - val_mse: 0.0123 - val_rmse: 0.1107\n",
      "Epoch 7/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8020 - mse: 0.0110 - rmse: 0.1047 - val_loss: 0.0123 - val_mape: 24.8965 - val_mse: 0.0123 - val_rmse: 0.1108\n",
      "Epoch 8/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8588 - mse: 0.0110 - rmse: 0.1049 - val_loss: 0.0123 - val_mape: 25.4143 - val_mse: 0.0123 - val_rmse: 0.1107\n",
      "Epoch 9/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8388 - mse: 0.0110 - rmse: 0.1051 - val_loss: 0.0123 - val_mape: 25.1907 - val_mse: 0.0123 - val_rmse: 0.1107\n",
      "Epoch 10/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0111 - mape: 22.8115 - mse: 0.0111 - rmse: 0.1051 - val_loss: 0.0122 - val_mape: 25.3159 - val_mse: 0.0123 - val_rmse: 0.1106\n",
      "Epoch 11/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8543 - mse: 0.0110 - rmse: 0.1048 - val_loss: 0.0122 - val_mape: 25.0924 - val_mse: 0.0122 - val_rmse: 0.1106\n",
      "Epoch 12/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.9109 - mse: 0.0110 - rmse: 0.1049 - val_loss: 0.0122 - val_mape: 25.0046 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 13/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8609 - mse: 0.0110 - rmse: 0.1050 - val_loss: 0.0122 - val_mape: 25.3415 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 14/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.6270 - mse: 0.0110 - rmse: 0.1049 - val_loss: 0.0122 - val_mape: 25.4033 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 15/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.7500 - mse: 0.0110 - rmse: 0.1048 - val_loss: 0.0122 - val_mape: 25.4207 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 16/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.9249 - mse: 0.0109 - rmse: 0.1043 - val_loss: 0.0122 - val_mape: 25.5140 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 17/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8592 - mse: 0.0110 - rmse: 0.1047 - val_loss: 0.0122 - val_mape: 25.1924 - val_mse: 0.0122 - val_rmse: 0.1105\n",
      "Epoch 18/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.7446 - mse: 0.0110 - rmse: 0.1046 - val_loss: 0.0122 - val_mape: 25.4101 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 19/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.7278 - mse: 0.0109 - rmse: 0.1044 - val_loss: 0.0122 - val_mape: 25.2975 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 20/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.7658 - mse: 0.0109 - rmse: 0.1045 - val_loss: 0.0122 - val_mape: 25.4279 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 21/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.5507 - mse: 0.0109 - rmse: 0.1042 - val_loss: 0.0122 - val_mape: 24.7512 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 22/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0110 - mape: 22.8009 - mse: 0.0110 - rmse: 0.1047 - val_loss: 0.0122 - val_mape: 24.7863 - val_mse: 0.0122 - val_rmse: 0.1104\n",
      "Epoch 23/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.6959 - mse: 0.0108 - rmse: 0.1041 - val_loss: 0.0122 - val_mape: 25.1874 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 24/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.6239 - mse: 0.0109 - rmse: 0.1041 - val_loss: 0.0122 - val_mape: 25.2282 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 25/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.5922 - mse: 0.0109 - rmse: 0.1041 - val_loss: 0.0122 - val_mape: 25.1866 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 26/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.7920 - mse: 0.0108 - rmse: 0.1041 - val_loss: 0.0122 - val_mape: 24.8002 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 27/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.7133 - mse: 0.0108 - rmse: 0.1041 - val_loss: 0.0121 - val_mape: 25.3059 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 28/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0109 - mape: 22.7289 - mse: 0.0109 - rmse: 0.1043 - val_loss: 0.0122 - val_mape: 24.8924 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 29/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.5693 - mse: 0.0107 - rmse: 0.1035 - val_loss: 0.0122 - val_mape: 24.9457 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 30/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.4459 - mse: 0.0108 - rmse: 0.1037 - val_loss: 0.0122 - val_mape: 24.7878 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 31/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.5218 - mse: 0.0108 - rmse: 0.1039 - val_loss: 0.0121 - val_mape: 25.0439 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 32/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.8451 - mse: 0.0108 - rmse: 0.1037 - val_loss: 0.0122 - val_mape: 25.2823 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 33/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.6047 - mse: 0.0107 - rmse: 0.1037 - val_loss: 0.0121 - val_mape: 25.2554 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 34/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.6370 - mse: 0.0108 - rmse: 0.1038 - val_loss: 0.0121 - val_mape: 24.9326 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 35/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.5920 - mse: 0.0107 - rmse: 0.1035 - val_loss: 0.0121 - val_mape: 24.8215 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 36/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0108 - mape: 22.3557 - mse: 0.0108 - rmse: 0.1038 - val_loss: 0.0121 - val_mape: 25.0409 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 37/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.3419 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0121 - val_mape: 25.2503 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 38/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.3690 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0121 - val_mape: 25.2289 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 39/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.4477 - mse: 0.0107 - rmse: 0.1036 - val_loss: 0.0121 - val_mape: 25.7148 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 40/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0106 - mape: 22.4108 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0121 - val_mape: 25.0685 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 41/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.6153 - mse: 0.0107 - rmse: 0.1036 - val_loss: 0.0121 - val_mape: 24.7923 - val_mse: 0.0122 - val_rmse: 0.1102\n",
      "Epoch 42/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0106 - mape: 22.5383 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0122 - val_mape: 24.5465 - val_mse: 0.0122 - val_rmse: 0.1103\n",
      "Epoch 43/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.4924 - mse: 0.0107 - rmse: 0.1035 - val_loss: 0.0121 - val_mape: 25.3497 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 44/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.4322 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0121 - val_mape: 25.2145 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 45/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0106 - mape: 22.2556 - mse: 0.0106 - rmse: 0.1029 - val_loss: 0.0121 - val_mape: 24.8907 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 46/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0106 - mape: 22.1017 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0121 - val_mape: 25.1662 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 47/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.4809 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0121 - val_mape: 24.8330 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 48/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0107 - mape: 22.3567 - mse: 0.0107 - rmse: 0.1034 - val_loss: 0.0121 - val_mape: 25.0290 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "Epoch 49/200\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0106 - mape: 22.3483 - mse: 0.0106 - rmse: 0.1032 - val_loss: 0.0121 - val_mape: 25.1815 - val_mse: 0.0121 - val_rmse: 0.1101\n",
      "[MODELO CONGELADO]: 360.9185607433319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 45.02062167835109, 6.709740805601293, 0.8680637482232844, 18.28583608050403\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 53.54601114212445, 7.317514000131769, 0.8454804188627123, 20.221117442230934\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 48.59032411100673, 6.970676015352222, 0.835912561192643, 20.761277951250204\n",
      "PROCESANDO ARCHIVO: Abies spectabilis\n",
      "(96429, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Abies spectabilis_best_models.json\n",
      "(56618, 4, 43) (19637, 4, 43) (15689, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_2, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0132 - mape: 30.6678 - mse: 0.0132 - rmse: 0.1151 - val_loss: 0.0130 - val_mape: 28.3358 - val_mse: 0.0130 - val_rmse: 0.1139\n",
      "Epoch 2/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0130 - mape: 29.3501 - mse: 0.0130 - rmse: 0.1139 - val_loss: 0.0129 - val_mape: 27.8532 - val_mse: 0.0129 - val_rmse: 0.1136\n",
      "Epoch 3/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0129 - mape: 29.3975 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0129 - val_mape: 27.7426 - val_mse: 0.0129 - val_rmse: 0.1134\n",
      "Epoch 4/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0129 - mape: 29.3848 - mse: 0.0129 - rmse: 0.1136 - val_loss: 0.0128 - val_mape: 27.9009 - val_mse: 0.0128 - val_rmse: 0.1133\n",
      "Epoch 5/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0129 - mape: 29.1627 - mse: 0.0129 - rmse: 0.1135 - val_loss: 0.0128 - val_mape: 27.6709 - val_mse: 0.0128 - val_rmse: 0.1132\n",
      "Epoch 6/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0128 - mape: 29.2084 - mse: 0.0128 - rmse: 0.1133 - val_loss: 0.0128 - val_mape: 28.2765 - val_mse: 0.0128 - val_rmse: 0.1131\n",
      "Epoch 7/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0128 - mape: 29.0619 - mse: 0.0128 - rmse: 0.1130 - val_loss: 0.0128 - val_mape: 27.4300 - val_mse: 0.0128 - val_rmse: 0.1131\n",
      "Epoch 8/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0128 - mape: 28.9165 - mse: 0.0128 - rmse: 0.1130 - val_loss: 0.0128 - val_mape: 27.4876 - val_mse: 0.0128 - val_rmse: 0.1130\n",
      "Epoch 9/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0127 - mape: 29.0213 - mse: 0.0127 - rmse: 0.1129 - val_loss: 0.0128 - val_mape: 27.1307 - val_mse: 0.0128 - val_rmse: 0.1129\n",
      "Epoch 10/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0127 - mape: 29.2515 - mse: 0.0127 - rmse: 0.1127 - val_loss: 0.0128 - val_mape: 27.0145 - val_mse: 0.0128 - val_rmse: 0.1129\n",
      "Epoch 11/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0127 - mape: 28.9381 - mse: 0.0127 - rmse: 0.1127 - val_loss: 0.0127 - val_mape: 26.6398 - val_mse: 0.0127 - val_rmse: 0.1128\n",
      "Epoch 12/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0127 - mape: 29.0342 - mse: 0.0127 - rmse: 0.1127 - val_loss: 0.0127 - val_mape: 27.4867 - val_mse: 0.0127 - val_rmse: 0.1129\n",
      "Epoch 13/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0126 - mape: 28.7660 - mse: 0.0126 - rmse: 0.1124 - val_loss: 0.0127 - val_mape: 27.1020 - val_mse: 0.0127 - val_rmse: 0.1128\n",
      "Epoch 14/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0126 - mape: 28.6361 - mse: 0.0126 - rmse: 0.1124 - val_loss: 0.0127 - val_mape: 27.0957 - val_mse: 0.0127 - val_rmse: 0.1127\n",
      "Epoch 15/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0127 - mape: 28.5855 - mse: 0.0127 - rmse: 0.1125 - val_loss: 0.0127 - val_mape: 26.7326 - val_mse: 0.0127 - val_rmse: 0.1127\n",
      "Epoch 16/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0126 - mape: 28.7249 - mse: 0.0126 - rmse: 0.1123 - val_loss: 0.0127 - val_mape: 27.0688 - val_mse: 0.0127 - val_rmse: 0.1126\n",
      "Epoch 17/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0126 - mape: 28.4606 - mse: 0.0126 - rmse: 0.1121 - val_loss: 0.0127 - val_mape: 27.0100 - val_mse: 0.0127 - val_rmse: 0.1126\n",
      "Epoch 18/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0126 - mape: 28.3986 - mse: 0.0126 - rmse: 0.1123 - val_loss: 0.0127 - val_mape: 26.9450 - val_mse: 0.0127 - val_rmse: 0.1126\n",
      "Epoch 19/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0126 - mape: 28.7817 - mse: 0.0126 - rmse: 0.1121 - val_loss: 0.0127 - val_mape: 26.7232 - val_mse: 0.0127 - val_rmse: 0.1125\n",
      "Epoch 20/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.6859 - mse: 0.0125 - rmse: 0.1120 - val_loss: 0.0127 - val_mape: 27.2449 - val_mse: 0.0127 - val_rmse: 0.1126\n",
      "Epoch 21/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.3599 - mse: 0.0125 - rmse: 0.1118 - val_loss: 0.0127 - val_mape: 26.9867 - val_mse: 0.0127 - val_rmse: 0.1125\n",
      "Epoch 22/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.6128 - mse: 0.0125 - rmse: 0.1118 - val_loss: 0.0127 - val_mape: 26.9091 - val_mse: 0.0126 - val_rmse: 0.1125\n",
      "Epoch 23/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.2144 - mse: 0.0125 - rmse: 0.1118 - val_loss: 0.0127 - val_mape: 26.8753 - val_mse: 0.0126 - val_rmse: 0.1125\n",
      "Epoch 24/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.1611 - mse: 0.0125 - rmse: 0.1117 - val_loss: 0.0127 - val_mape: 27.0591 - val_mse: 0.0127 - val_rmse: 0.1125\n",
      "Epoch 25/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.0475 - mse: 0.0125 - rmse: 0.1116 - val_loss: 0.0126 - val_mape: 26.9887 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 26/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0125 - mape: 28.2580 - mse: 0.0125 - rmse: 0.1116 - val_loss: 0.0126 - val_mape: 26.9289 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 27/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0124 - mape: 28.2571 - mse: 0.0124 - rmse: 0.1116 - val_loss: 0.0126 - val_mape: 26.5479 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 28/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0124 - mape: 28.4815 - mse: 0.0124 - rmse: 0.1115 - val_loss: 0.0126 - val_mape: 26.4713 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 29/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0124 - mape: 28.1726 - mse: 0.0124 - rmse: 0.1113 - val_loss: 0.0126 - val_mape: 26.8665 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 30/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0124 - mape: 28.3297 - mse: 0.0124 - rmse: 0.1114 - val_loss: 0.0126 - val_mape: 26.1415 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 31/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0124 - mape: 27.9245 - mse: 0.0124 - rmse: 0.1113 - val_loss: 0.0126 - val_mape: 26.3136 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 32/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0124 - mape: 28.0522 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0126 - val_mape: 26.4488 - val_mse: 0.0126 - val_rmse: 0.1124\n",
      "Epoch 33/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0124 - mape: 28.3752 - mse: 0.0124 - rmse: 0.1113 - val_loss: 0.0126 - val_mape: 26.9582 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 34/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0123 - mape: 28.3564 - mse: 0.0123 - rmse: 0.1111 - val_loss: 0.0126 - val_mape: 26.8915 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 35/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0123 - mape: 28.0203 - mse: 0.0123 - rmse: 0.1111 - val_loss: 0.0126 - val_mape: 26.5746 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 36/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0123 - mape: 27.8207 - mse: 0.0123 - rmse: 0.1111 - val_loss: 0.0126 - val_mape: 26.9605 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 37/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0123 - mape: 27.7024 - mse: 0.0123 - rmse: 0.1109 - val_loss: 0.0126 - val_mape: 27.0247 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 38/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0123 - mape: 27.9339 - mse: 0.0123 - rmse: 0.1109 - val_loss: 0.0126 - val_mape: 27.1224 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 39/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0123 - mape: 28.3357 - mse: 0.0123 - rmse: 0.1107 - val_loss: 0.0126 - val_mape: 25.9500 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 40/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0123 - mape: 28.4381 - mse: 0.0123 - rmse: 0.1111 - val_loss: 0.0126 - val_mape: 26.8588 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 41/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0123 - mape: 27.7376 - mse: 0.0123 - rmse: 0.1107 - val_loss: 0.0126 - val_mape: 26.5057 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 42/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0123 - mape: 27.9486 - mse: 0.0123 - rmse: 0.1107 - val_loss: 0.0126 - val_mape: 26.3380 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 43/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0122 - mape: 27.8844 - mse: 0.0122 - rmse: 0.1105 - val_loss: 0.0126 - val_mape: 26.9034 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 44/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0122 - mape: 27.7347 - mse: 0.0122 - rmse: 0.1104 - val_loss: 0.0126 - val_mape: 26.1873 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 45/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0122 - mape: 27.9562 - mse: 0.0122 - rmse: 0.1105 - val_loss: 0.0126 - val_mape: 26.0919 - val_mse: 0.0126 - val_rmse: 0.1123\n",
      "Epoch 46/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0122 - mape: 27.5542 - mse: 0.0122 - rmse: 0.1103 - val_loss: 0.0126 - val_mape: 26.7942 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 47/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0122 - mape: 27.6788 - mse: 0.0122 - rmse: 0.1102 - val_loss: 0.0126 - val_mape: 26.1330 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 48/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.7835 - mse: 0.0121 - rmse: 0.1102 - val_loss: 0.0126 - val_mape: 26.6933 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 49/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.4850 - mse: 0.0121 - rmse: 0.1102 - val_loss: 0.0126 - val_mape: 26.6619 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 50/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.9552 - mse: 0.0121 - rmse: 0.1100 - val_loss: 0.0126 - val_mape: 26.9631 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 51/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.6860 - mse: 0.0121 - rmse: 0.1101 - val_loss: 0.0126 - val_mape: 26.7850 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 52/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.7578 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0126 - val_mape: 26.7057 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 53/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.6835 - mse: 0.0121 - rmse: 0.1101 - val_loss: 0.0126 - val_mape: 26.3349 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 54/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.7230 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0126 - val_mape: 26.1718 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 55/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.4156 - mse: 0.0121 - rmse: 0.1101 - val_loss: 0.0126 - val_mape: 25.9943 - val_mse: 0.0126 - val_rmse: 0.1120\n",
      "Epoch 56/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.5959 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0126 - val_mape: 26.7175 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 57/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0121 - mape: 27.7862 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0126 - val_mape: 26.4991 - val_mse: 0.0126 - val_rmse: 0.1122\n",
      "Epoch 58/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0120 - mape: 27.4599 - mse: 0.0120 - rmse: 0.1096 - val_loss: 0.0126 - val_mape: 26.3666 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 59/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0120 - mape: 27.6850 - mse: 0.0120 - rmse: 0.1097 - val_loss: 0.0125 - val_mape: 26.7406 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 60/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0120 - mape: 27.5457 - mse: 0.0120 - rmse: 0.1095 - val_loss: 0.0126 - val_mape: 26.8859 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 61/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0120 - mape: 27.4460 - mse: 0.0120 - rmse: 0.1095 - val_loss: 0.0126 - val_mape: 26.8110 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 62/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0120 - mape: 27.4729 - mse: 0.0120 - rmse: 0.1095 - val_loss: 0.0125 - val_mape: 26.2075 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 63/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0120 - mape: 27.5933 - mse: 0.0120 - rmse: 0.1094 - val_loss: 0.0125 - val_mape: 26.5083 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 64/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0119 - mape: 27.4136 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0125 - val_mape: 26.5439 - val_mse: 0.0125 - val_rmse: 0.1119\n",
      "Epoch 65/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0119 - mape: 27.4115 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0126 - val_mape: 27.0664 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 66/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0119 - mape: 27.6582 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0125 - val_mape: 26.8970 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 67/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 0.0119 - mape: 27.4920 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0126 - val_mape: 26.8699 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 68/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0119 - mape: 27.5552 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0125 - val_mape: 26.5156 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 69/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0119 - mape: 27.4426 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0126 - val_mape: 26.7188 - val_mse: 0.0126 - val_rmse: 0.1121\n",
      "Epoch 70/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0118 - mape: 27.3923 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0125 - val_mape: 26.6346 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 71/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0118 - mape: 27.2101 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0125 - val_mape: 26.4099 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 72/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0118 - mape: 27.4093 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0125 - val_mape: 26.7346 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 73/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0118 - mape: 27.3352 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0125 - val_mape: 27.0034 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "Epoch 74/200\n",
      "\u001b[1m3539/3539\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - loss: 0.0118 - mape: 27.4754 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0125 - val_mape: 26.6343 - val_mse: 0.0125 - val_rmse: 0.1120\n",
      "[MODELO CONGELADO]: 1007.5431914329529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 16.471618056522185, 4.058524122944471, 0.8554869639685316, 19.78982405918577\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 18.14359266662044, 4.259529629738528, 0.8346820222737222, 20.963753793194762\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 18.574878004094487, 4.30985823480245, 0.8622439507412254, 20.36332973303549\n",
      "PROCESANDO ARCHIVO: Juniperus excelsa M.-Bieb\n",
      "(7449, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus excelsa M.-Bieb_best_models.json\n",
      "(4189, 4, 43) (1707, 4, 43) (1228, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_2, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0118 - mape: 31.3436 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0120 - val_mape: 31.4839 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 2/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - mape: 31.0957 - mse: 0.0114 - rmse: 0.1067 - val_loss: 0.0120 - val_mape: 31.1134 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 3/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - mape: 30.1397 - mse: 0.0114 - rmse: 0.1069 - val_loss: 0.0120 - val_mape: 30.7789 - val_mse: 0.0121 - val_rmse: 0.1096\n",
      "Epoch 4/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - mape: 30.5933 - mse: 0.0114 - rmse: 0.1069 - val_loss: 0.0121 - val_mape: 30.3892 - val_mse: 0.0121 - val_rmse: 0.1099\n",
      "Epoch 5/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mape: 30.6059 - mse: 0.0112 - rmse: 0.1059 - val_loss: 0.0120 - val_mape: 30.4280 - val_mse: 0.0120 - val_rmse: 0.1096\n",
      "Epoch 6/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - mape: 30.5707 - mse: 0.0114 - rmse: 0.1066 - val_loss: 0.0120 - val_mape: 30.1718 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 7/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0113 - mape: 29.8899 - mse: 0.0113 - rmse: 0.1064 - val_loss: 0.0120 - val_mape: 30.3163 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 8/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mape: 30.2878 - mse: 0.0112 - rmse: 0.1058 - val_loss: 0.0120 - val_mape: 30.4917 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 9/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0110 - mape: 29.9226 - mse: 0.0110 - rmse: 0.1047 - val_loss: 0.0121 - val_mape: 30.5343 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 10/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0112 - mape: 30.4590 - mse: 0.0112 - rmse: 0.1057 - val_loss: 0.0120 - val_mape: 30.2046 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 11/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0113 - mape: 30.9269 - mse: 0.0113 - rmse: 0.1064 - val_loss: 0.0120 - val_mape: 29.9852 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 12/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0111 - mape: 29.9437 - mse: 0.0111 - rmse: 0.1052 - val_loss: 0.0120 - val_mape: 30.3301 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 13/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0111 - mape: 30.5666 - mse: 0.0111 - rmse: 0.1054 - val_loss: 0.0120 - val_mape: 30.2669 - val_mse: 0.0121 - val_rmse: 0.1097\n",
      "Epoch 14/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0110 - mape: 30.2825 - mse: 0.0110 - rmse: 0.1048 - val_loss: 0.0121 - val_mape: 29.9467 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "Epoch 15/200\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0109 - mape: 30.5272 - mse: 0.0109 - rmse: 0.1041 - val_loss: 0.0121 - val_mape: 30.2775 - val_mse: 0.0121 - val_rmse: 0.1098\n",
      "[MODELO CONGELADO]: 17.474933624267578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 3.950020873501605, 1.9874659427274735, 0.8394395409129721, 19.738812759945485\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 4.5779596640512885, 2.139616709612095, 0.8254138013432348, 22.371169208810194\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.291552865520774, 3.048204859506784, 0.8622450075588215, 23.24196301299907\n",
      "PROCESANDO ARCHIVO: Cedrus deodara\n",
      "(37273, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Cedrus deodara_best_models.json\n",
      "(22017, 4, 43) (7410, 4, 43) (6282, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0179 - mape: 39.3389 - mse: 0.0179 - rmse: 0.1337 - val_loss: 0.0173 - val_mape: 38.1521 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 2/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0176 - mape: 38.5987 - mse: 0.0176 - rmse: 0.1326 - val_loss: 0.0173 - val_mape: 38.1388 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 3/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.2866 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0172 - val_mape: 38.2279 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 4/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 37.9688 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0172 - val_mape: 37.9577 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 5/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.4278 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0172 - val_mape: 37.8018 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 6/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.7331 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 38.3983 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 7/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.1781 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0172 - val_mape: 37.0308 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 8/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 37.7381 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0172 - val_mape: 38.1964 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 9/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.1377 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 37.7901 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 10/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 37.9834 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0171 - val_mape: 37.8561 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 11/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 38.0547 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 37.6991 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 12/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0176 - mape: 38.3370 - mse: 0.0176 - rmse: 0.1326 - val_loss: 0.0171 - val_mape: 38.0997 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 13/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.8584 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 37.9842 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 14/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.8632 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0171 - val_mape: 37.8888 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 15/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 38.0695 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0171 - val_mape: 37.9565 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 16/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.1772 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0171 - val_mape: 37.8868 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 17/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.0117 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0171 - val_mape: 37.4091 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 18/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.2970 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0171 - val_mape: 37.8290 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 19/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.1567 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0171 - val_mape: 37.6660 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 20/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.8555 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0171 - val_mape: 37.4588 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 21/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.1830 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0171 - val_mape: 37.4146 - val_mse: 0.0171 - val_rmse: 0.1308\n",
      "Epoch 22/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.9412 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0171 - val_mape: 37.6652 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 23/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.0675 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0171 - val_mape: 37.4180 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 24/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.0889 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0171 - val_mape: 37.9187 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 25/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.9699 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0171 - val_mape: 38.1196 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 26/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.7711 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 37.5036 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 27/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.6347 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0171 - val_mape: 37.5597 - val_mse: 0.0171 - val_rmse: 0.1307\n",
      "Epoch 28/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.0388 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0171 - val_mape: 37.7789 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 29/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.2652 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0171 - val_mape: 37.1731 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 30/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.6316 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0171 - val_mape: 37.7210 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 31/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.7422 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 37.4325 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 32/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.0988 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0171 - val_mape: 37.5077 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 33/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.8963 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0171 - val_mape: 37.2576 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 34/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.7400 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0171 - val_mape: 37.4084 - val_mse: 0.0170 - val_rmse: 0.1306\n",
      "Epoch 35/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.6654 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0170 - val_mape: 37.3443 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 36/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.7331 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0170 - val_mape: 37.3244 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 37/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.6467 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0171 - val_mape: 37.2445 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 38/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.7367 - mse: 0.0173 - rmse: 0.1313 - val_loss: 0.0170 - val_mape: 37.1389 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 39/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.5093 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0171 - val_mape: 38.1614 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 40/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.5071 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0170 - val_mape: 37.4064 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 41/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 38.0764 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0170 - val_mape: 37.2986 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 42/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.9347 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0170 - val_mape: 37.9349 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 43/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.8317 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0170 - val_mape: 37.3752 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 44/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.7011 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0170 - val_mape: 37.2642 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 45/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.9901 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0170 - val_mape: 37.3577 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 46/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.7879 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0170 - val_mape: 37.7111 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 47/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.5058 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0170 - val_mape: 37.2437 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 48/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.3273 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0170 - val_mape: 37.1383 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 49/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.5098 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0170 - val_mape: 37.2105 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 50/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.6324 - mse: 0.0171 - rmse: 0.1309 - val_loss: 0.0170 - val_mape: 37.5814 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 51/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.6481 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0170 - val_mape: 37.0724 - val_mse: 0.0170 - val_rmse: 0.1305\n",
      "Epoch 52/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.6406 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0170 - val_mape: 37.2089 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 53/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.6462 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0170 - val_mape: 37.7529 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 54/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.6270 - mse: 0.0172 - rmse: 0.1311 - val_loss: 0.0170 - val_mape: 37.6444 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 55/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.4331 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0170 - val_mape: 37.4232 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 56/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.6550 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0170 - val_mape: 37.2586 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 57/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.8303 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0170 - val_mape: 36.8832 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 58/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4168 - mse: 0.0172 - rmse: 0.1311 - val_loss: 0.0170 - val_mape: 37.8127 - val_mse: 0.0170 - val_rmse: 0.1302\n",
      "Epoch 59/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.7263 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0170 - val_mape: 36.8760 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 60/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.6646 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 37.1891 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 61/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.6955 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0170 - val_mape: 37.5769 - val_mse: 0.0170 - val_rmse: 0.1302\n",
      "Epoch 62/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0175 - mape: 38.0452 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0169 - val_mape: 37.2967 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 63/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.2176 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0169 - val_mape: 37.3584 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 64/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.8710 - mse: 0.0171 - rmse: 0.1309 - val_loss: 0.0169 - val_mape: 37.6179 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 65/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.5093 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 37.9707 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 66/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.7177 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0169 - val_mape: 37.9142 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 67/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0174 - mape: 37.7514 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0169 - val_mape: 37.1033 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 68/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.2750 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0169 - val_mape: 37.1097 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 69/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4430 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 37.6113 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 70/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4647 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0169 - val_mape: 37.1522 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 71/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.4738 - mse: 0.0171 - rmse: 0.1309 - val_loss: 0.0169 - val_mape: 37.5214 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 72/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.5852 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 37.0836 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 73/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.4591 - mse: 0.0171 - rmse: 0.1309 - val_loss: 0.0170 - val_mape: 37.4425 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 74/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 38.1118 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0170 - val_mape: 38.0989 - val_mse: 0.0170 - val_rmse: 0.1302\n",
      "Epoch 75/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.3242 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0169 - val_mape: 36.7133 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 76/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4728 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0169 - val_mape: 37.2746 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 77/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4572 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0169 - val_mape: 37.0207 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 78/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4572 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 36.8718 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 79/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.5358 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 37.2387 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 80/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.7409 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0169 - val_mape: 36.6582 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 81/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.5801 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 37.0493 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 82/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.5173 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0169 - val_mape: 36.9603 - val_mse: 0.0169 - val_rmse: 0.1299\n",
      "Epoch 83/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4366 - mse: 0.0172 - rmse: 0.1311 - val_loss: 0.0169 - val_mape: 37.3197 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 84/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.2326 - mse: 0.0172 - rmse: 0.1311 - val_loss: 0.0169 - val_mape: 36.5763 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 85/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.1669 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0169 - val_mape: 36.9146 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 86/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.3620 - mse: 0.0171 - rmse: 0.1307 - val_loss: 0.0169 - val_mape: 37.1186 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 87/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0172 - mape: 37.4710 - mse: 0.0172 - rmse: 0.1312 - val_loss: 0.0169 - val_mape: 36.9070 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 88/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.8675 - mse: 0.0171 - rmse: 0.1309 - val_loss: 0.0169 - val_mape: 37.3332 - val_mse: 0.0169 - val_rmse: 0.1301\n",
      "Epoch 89/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0173 - mape: 37.4272 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0169 - val_mape: 37.5496 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 90/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.4563 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0169 - val_mape: 37.1626 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 91/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.7325 - mse: 0.0171 - rmse: 0.1308 - val_loss: 0.0169 - val_mape: 36.9157 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "Epoch 92/200\n",
      "\u001b[1m1377/1377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0171 - mape: 37.1679 - mse: 0.0171 - rmse: 0.1306 - val_loss: 0.0169 - val_mape: 37.3838 - val_mse: 0.0169 - val_rmse: 0.1300\n",
      "[MODELO CONGELADO]: 803.0302400588989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 81.48095507405868, 9.026680180113766, 0.8092361083335531, 22.81921139314644\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 105.28588599159389, 10.260891091498529, 0.7640071838112907, 24.073530599774895\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 69.94575429313383, 8.36335783600904, 0.8015317468836681, 22.631535801604926\n",
      "PROCESANDO ARCHIVO: Tsuga dumosa\n",
      "(20493, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Tsuga dumosa_best_models.json\n",
      "(11935, 4, 43) (4144, 4, 43) (3469, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> False\n",
      "<LSTM name=lstm_5, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0169 - mape: 35.2257 - mse: 0.0169 - rmse: 0.1299 - val_loss: 0.0164 - val_mape: 31.5220 - val_mse: 0.0164 - val_rmse: 0.1282\n",
      "Epoch 2/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0167 - mape: 34.6902 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0164 - val_mape: 31.3228 - val_mse: 0.0164 - val_rmse: 0.1282\n",
      "Epoch 3/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0167 - mape: 34.3907 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0164 - val_mape: 31.5143 - val_mse: 0.0164 - val_rmse: 0.1281\n",
      "Epoch 4/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 35.1630 - mse: 0.0168 - rmse: 0.1296 - val_loss: 0.0164 - val_mape: 31.1371 - val_mse: 0.0164 - val_rmse: 0.1281\n",
      "Epoch 5/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0164 - mape: 34.1768 - mse: 0.0164 - rmse: 0.1281 - val_loss: 0.0164 - val_mape: 31.2513 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 6/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0165 - mape: 33.6788 - mse: 0.0165 - rmse: 0.1284 - val_loss: 0.0164 - val_mape: 31.3685 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 7/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 34.1543 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0164 - val_mape: 31.2124 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 8/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0165 - mape: 34.3882 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0164 - val_mape: 31.6590 - val_mse: 0.0164 - val_rmse: 0.1281\n",
      "Epoch 9/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 34.0494 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0164 - val_mape: 31.5079 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 10/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0164 - mape: 34.1062 - mse: 0.0164 - rmse: 0.1280 - val_loss: 0.0164 - val_mape: 31.5581 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 11/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0167 - mape: 34.4352 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0164 - val_mape: 31.3227 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 12/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 33.9662 - mse: 0.0166 - rmse: 0.1290 - val_loss: 0.0164 - val_mape: 31.6739 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 13/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0165 - mape: 33.5923 - mse: 0.0165 - rmse: 0.1282 - val_loss: 0.0164 - val_mape: 31.0712 - val_mse: 0.0164 - val_rmse: 0.1281\n",
      "Epoch 14/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 34.5384 - mse: 0.0166 - rmse: 0.1290 - val_loss: 0.0164 - val_mape: 31.7271 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 15/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 34.0906 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0164 - val_mape: 31.0717 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 16/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0167 - mape: 33.8645 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0164 - val_mape: 31.5958 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 17/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 33.8729 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0164 - val_mape: 31.2900 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 18/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 34.4170 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0164 - val_mape: 31.5806 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 19/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 33.9579 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0164 - val_mape: 31.0852 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 20/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 34.5869 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0164 - val_mape: 31.3980 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 21/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 34.6404 - mse: 0.0168 - rmse: 0.1294 - val_loss: 0.0164 - val_mape: 31.0460 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 22/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 33.9314 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0164 - val_mape: 31.3976 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 23/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0164 - mape: 33.9779 - mse: 0.0164 - rmse: 0.1282 - val_loss: 0.0163 - val_mape: 31.0944 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 24/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0165 - mape: 34.1635 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0163 - val_mape: 31.4528 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 25/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0165 - mape: 33.9919 - mse: 0.0165 - rmse: 0.1285 - val_loss: 0.0163 - val_mape: 31.2672 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 26/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 33.8392 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0164 - val_mape: 31.1160 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 27/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 34.4079 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0164 - val_mape: 31.0848 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 28/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0167 - mape: 34.7830 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0163 - val_mape: 31.1610 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 29/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0168 - mape: 34.9152 - mse: 0.0168 - rmse: 0.1297 - val_loss: 0.0164 - val_mape: 31.0512 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 30/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 33.9150 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0164 - val_mape: 31.3012 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 31/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0167 - mape: 34.2056 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0164 - val_mape: 31.1884 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 32/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0166 - mape: 33.9997 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0164 - val_mape: 31.4452 - val_mse: 0.0164 - val_rmse: 0.1280\n",
      "Epoch 33/200\n",
      "\u001b[1m746/746\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0165 - mape: 34.0827 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0164 - val_mape: 31.2885 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "[MODELO CONGELADO]: 141.45241594314575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 84.50374525486396, 9.192591868176459, 0.7830120394300837, 23.559046609783447\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 79.10851890765439, 8.894296987826209, 0.7489606558807014, 23.64486441384476\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 121.00172166082642, 11.000078257031921, 0.8024936321933167, 23.589880400540014\n",
      "PROCESANDO ARCHIVO: Juniperus spp. \n",
      "(17976, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus spp. _best_models.json\n",
      "(10218, 4, 43) (3900, 4, 43) (3018, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<LSTM name=lstm_3, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0170 - mape: 38.2446 - mse: 0.0170 - rmse: 0.1304 - val_loss: 0.0189 - val_mape: 37.6022 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 2/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169 - mape: 38.3585 - mse: 0.0169 - rmse: 0.1299 - val_loss: 0.0190 - val_mape: 37.6740 - val_mse: 0.0189 - val_rmse: 0.1377\n",
      "Epoch 3/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169 - mape: 37.0375 - mse: 0.0169 - rmse: 0.1299 - val_loss: 0.0189 - val_mape: 37.8660 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 4/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169 - mape: 38.3003 - mse: 0.0169 - rmse: 0.1298 - val_loss: 0.0189 - val_mape: 37.7107 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 5/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169 - mape: 37.6578 - mse: 0.0169 - rmse: 0.1298 - val_loss: 0.0189 - val_mape: 37.7460 - val_mse: 0.0189 - val_rmse: 0.1375\n",
      "Epoch 6/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169 - mape: 38.2740 - mse: 0.0169 - rmse: 0.1299 - val_loss: 0.0189 - val_mape: 37.6049 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 7/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 37.7852 - mse: 0.0168 - rmse: 0.1297 - val_loss: 0.0189 - val_mape: 37.6315 - val_mse: 0.0189 - val_rmse: 0.1375\n",
      "Epoch 8/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.6810 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0189 - val_mape: 37.7630 - val_mse: 0.0189 - val_rmse: 0.1374\n",
      "Epoch 9/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 35.9029 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0189 - val_mape: 37.5704 - val_mse: 0.0188 - val_rmse: 0.1374\n",
      "Epoch 10/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 35.5878 - mse: 0.0167 - rmse: 0.1294 - val_loss: 0.0189 - val_mape: 37.7704 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 11/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 37.4452 - mse: 0.0168 - rmse: 0.1294 - val_loss: 0.0189 - val_mape: 37.7477 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 12/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.9433 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0189 - val_mape: 37.6200 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 13/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 36.9307 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0189 - val_mape: 37.5363 - val_mse: 0.0188 - val_rmse: 0.1374\n",
      "Epoch 14/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.3880 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.6432 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 15/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 36.8235 - mse: 0.0168 - rmse: 0.1295 - val_loss: 0.0189 - val_mape: 37.5471 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 16/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.6912 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0188 - val_mape: 37.5704 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 17/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.1949 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0188 - val_mape: 37.2592 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 18/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 37.0286 - mse: 0.0168 - rmse: 0.1294 - val_loss: 0.0188 - val_mape: 37.7381 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 19/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.1596 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0188 - val_mape: 37.4559 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 20/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 36.2014 - mse: 0.0168 - rmse: 0.1294 - val_loss: 0.0188 - val_mape: 37.4778 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 21/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.7717 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0188 - val_mape: 37.2336 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 22/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.6096 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0188 - val_mape: 37.4181 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 23/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.7179 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0188 - val_mape: 37.5919 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 24/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.8575 - mse: 0.0167 - rmse: 0.1294 - val_loss: 0.0188 - val_mape: 37.7430 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 25/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.3419 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0188 - val_mape: 37.7405 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 26/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mape: 35.9520 - mse: 0.0168 - rmse: 0.1294 - val_loss: 0.0188 - val_mape: 37.5524 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 27/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.4149 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.7790 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 28/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.1089 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0188 - val_mape: 37.3886 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 29/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.3473 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0188 - val_mape: 37.6034 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 30/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.4837 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.7627 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 31/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.9896 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.7057 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 32/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.5103 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.4907 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 33/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.3165 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0188 - val_mape: 37.6032 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 34/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.2645 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.6884 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 35/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 37.1883 - mse: 0.0166 - rmse: 0.1290 - val_loss: 0.0188 - val_mape: 37.4043 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 36/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 38.1174 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0188 - val_mape: 37.3296 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 37/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 37.3015 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0188 - val_mape: 37.6310 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 38/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.1426 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0188 - val_mape: 37.5712 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 39/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.6714 - mse: 0.0167 - rmse: 0.1294 - val_loss: 0.0188 - val_mape: 37.6131 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 40/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.7258 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0188 - val_mape: 37.6634 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 41/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.3618 - mse: 0.0166 - rmse: 0.1288 - val_loss: 0.0188 - val_mape: 37.6841 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 42/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.8697 - mse: 0.0166 - rmse: 0.1286 - val_loss: 0.0188 - val_mape: 38.0043 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 43/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.2772 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0188 - val_mape: 37.3709 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 44/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 35.9620 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0188 - val_mape: 37.5775 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 45/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0165 - mape: 36.1722 - mse: 0.0165 - rmse: 0.1285 - val_loss: 0.0188 - val_mape: 37.4182 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 46/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 36.7507 - mse: 0.0166 - rmse: 0.1289 - val_loss: 0.0188 - val_mape: 37.6189 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 47/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.7495 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0188 - val_mape: 37.4969 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 48/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 37.6169 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0188 - val_mape: 37.4779 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 49/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.1388 - mse: 0.0167 - rmse: 0.1293 - val_loss: 0.0188 - val_mape: 37.3951 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 50/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 36.3277 - mse: 0.0167 - rmse: 0.1290 - val_loss: 0.0189 - val_mape: 37.5252 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 51/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mape: 37.3618 - mse: 0.0166 - rmse: 0.1290 - val_loss: 0.0188 - val_mape: 37.6685 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 52/200\n",
      "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mape: 35.8961 - mse: 0.0167 - rmse: 0.1291 - val_loss: 0.0188 - val_mape: 37.3643 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "[MODELO CONGELADO]: 157.1437063217163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 6.607640486577486, 2.570533113301108, 0.8922339109336529, 20.183042826617054\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 2.9075966039724364, 1.7051676175591761, 0.8522017404637868, 23.02995827870032\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 8.845769216512297, 2.9741837899686523, 0.915348511898651, 20.355991909121222\n",
      "PROCESANDO ARCHIVO: Juniperus recurva\n",
      "(5316, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus recurva_best_models.json\n",
      "(3188, 4, 43) (1082, 4, 43) (810, 4, 43)\n",
      "<LSTM name=lstm_4, built=True> False\n",
      "<LSTM name=lstm_5, built=True> False\n",
      "<LSTM name=lstm_6, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<LSTM name=lstm_7, built=True> False\n",
      "<LSTM name=lstm_8, built=True> True\n",
      "<Dense name=dense_2, built=True> True\n",
      "<Dropout name=dropout_3, built=True> True\n",
      "<Dense name=dense_3, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0119 - mape: 21.1560 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0140 - val_mape: 23.0734 - val_mse: 0.0140 - val_rmse: 0.1185\n",
      "Epoch 2/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 21.1585 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0140 - val_mape: 23.0825 - val_mse: 0.0140 - val_rmse: 0.1182\n",
      "Epoch 3/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 21.0230 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0140 - val_mape: 22.9991 - val_mse: 0.0140 - val_rmse: 0.1183\n",
      "Epoch 4/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.9205 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0140 - val_mape: 22.9552 - val_mse: 0.0140 - val_rmse: 0.1182\n",
      "Epoch 5/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mape: 20.9172 - mse: 0.0107 - rmse: 0.1032 - val_loss: 0.0139 - val_mape: 23.0162 - val_mse: 0.0139 - val_rmse: 0.1181\n",
      "Epoch 6/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mape: 21.0339 - mse: 0.0107 - rmse: 0.1032 - val_loss: 0.0139 - val_mape: 23.0484 - val_mse: 0.0139 - val_rmse: 0.1180\n",
      "Epoch 7/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6076 - mse: 0.0105 - rmse: 0.1022 - val_loss: 0.0139 - val_mape: 23.0079 - val_mse: 0.0139 - val_rmse: 0.1180\n",
      "Epoch 8/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mape: 20.7705 - mse: 0.0104 - rmse: 0.1021 - val_loss: 0.0139 - val_mape: 22.9590 - val_mse: 0.0139 - val_rmse: 0.1181\n",
      "Epoch 9/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.8060 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0139 - val_mape: 23.0186 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 10/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7047 - mse: 0.0105 - rmse: 0.1023 - val_loss: 0.0139 - val_mape: 22.9285 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 11/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.8732 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0139 - val_mape: 23.0420 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 12/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mape: 20.9706 - mse: 0.0107 - rmse: 0.1032 - val_loss: 0.0139 - val_mape: 22.8992 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 13/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mape: 20.7554 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0139 - val_mape: 22.8931 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 14/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7492 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0139 - val_mape: 22.9671 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 15/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mape: 20.9214 - mse: 0.0107 - rmse: 0.1032 - val_loss: 0.0139 - val_mape: 22.9451 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 16/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7670 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0139 - val_mape: 23.0188 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 17/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.9034 - mse: 0.0106 - rmse: 0.1029 - val_loss: 0.0139 - val_mape: 22.9439 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 18/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.8509 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0139 - val_mape: 22.9110 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 19/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6933 - mse: 0.0105 - rmse: 0.1024 - val_loss: 0.0139 - val_mape: 22.8847 - val_mse: 0.0139 - val_rmse: 0.1178\n",
      "Epoch 20/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7309 - mse: 0.0105 - rmse: 0.1024 - val_loss: 0.0139 - val_mape: 22.9794 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 21/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7846 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0139 - val_mape: 22.9449 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 22/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7818 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0139 - val_mape: 22.8091 - val_mse: 0.0139 - val_rmse: 0.1179\n",
      "Epoch 23/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.6122 - mse: 0.0106 - rmse: 0.1030 - val_loss: 0.0139 - val_mape: 22.8427 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 24/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7531 - mse: 0.0106 - rmse: 0.1028 - val_loss: 0.0139 - val_mape: 22.9518 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 25/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6296 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0139 - val_mape: 22.9636 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 26/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0106 - mape: 20.6799 - mse: 0.0106 - rmse: 0.1032 - val_loss: 0.0139 - val_mape: 22.8724 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 27/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0104 - mape: 20.5948 - mse: 0.0104 - rmse: 0.1020 - val_loss: 0.0139 - val_mape: 22.8899 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 28/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.5822 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0139 - val_mape: 22.8827 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 29/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.8989 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0139 - val_mape: 22.9516 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 30/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.6964 - mse: 0.0106 - rmse: 0.1028 - val_loss: 0.0139 - val_mape: 22.7706 - val_mse: 0.0138 - val_rmse: 0.1178\n",
      "Epoch 31/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7669 - mse: 0.0106 - rmse: 0.1028 - val_loss: 0.0139 - val_mape: 22.8513 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 32/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.8259 - mse: 0.0105 - rmse: 0.1024 - val_loss: 0.0138 - val_mape: 22.9273 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 33/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7629 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0138 - val_mape: 22.9437 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 34/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7203 - mse: 0.0106 - rmse: 0.1029 - val_loss: 0.0138 - val_mape: 22.7729 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 35/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.5899 - mse: 0.0105 - rmse: 0.1023 - val_loss: 0.0138 - val_mape: 22.8425 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 36/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.8639 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0138 - val_mape: 22.8448 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 37/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.6165 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0138 - val_mape: 22.8683 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 38/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7167 - mse: 0.0106 - rmse: 0.1028 - val_loss: 0.0138 - val_mape: 22.8079 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 39/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7040 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0138 - val_mape: 22.8727 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 40/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.8411 - mse: 0.0106 - rmse: 0.1030 - val_loss: 0.0138 - val_mape: 22.9049 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 41/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7761 - mse: 0.0106 - rmse: 0.1030 - val_loss: 0.0138 - val_mape: 22.7654 - val_mse: 0.0138 - val_rmse: 0.1177\n",
      "Epoch 42/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7056 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0138 - val_mape: 22.8715 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 43/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.5798 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0138 - val_mape: 22.8590 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 44/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7944 - mse: 0.0105 - rmse: 0.1023 - val_loss: 0.0138 - val_mape: 22.9014 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 45/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6261 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0138 - val_mape: 22.9271 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 46/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6882 - mse: 0.0105 - rmse: 0.1027 - val_loss: 0.0138 - val_mape: 22.7563 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 47/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mape: 20.6013 - mse: 0.0107 - rmse: 0.1033 - val_loss: 0.0138 - val_mape: 22.8362 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 48/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6635 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0138 - val_mape: 22.8752 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 49/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6202 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0138 - val_mape: 22.8656 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 50/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.4851 - mse: 0.0105 - rmse: 0.1022 - val_loss: 0.0138 - val_mape: 22.8637 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 51/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6854 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0138 - val_mape: 22.8813 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 52/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7004 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0138 - val_mape: 22.9248 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 53/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.5286 - mse: 0.0105 - rmse: 0.1024 - val_loss: 0.0138 - val_mape: 22.8353 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 54/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.4978 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0138 - val_mape: 22.8132 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 55/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.5608 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0138 - val_mape: 22.7370 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 56/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.6235 - mse: 0.0106 - rmse: 0.1028 - val_loss: 0.0138 - val_mape: 22.8857 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 57/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0106 - mape: 20.8822 - mse: 0.0106 - rmse: 0.1031 - val_loss: 0.0138 - val_mape: 22.7532 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 58/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7634 - mse: 0.0106 - rmse: 0.1029 - val_loss: 0.0138 - val_mape: 22.8607 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 59/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.6086 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0138 - val_mape: 22.8549 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 60/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0106 - mape: 20.7841 - mse: 0.0106 - rmse: 0.1027 - val_loss: 0.0138 - val_mape: 22.7686 - val_mse: 0.0138 - val_rmse: 0.1176\n",
      "Epoch 61/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7443 - mse: 0.0105 - rmse: 0.1026 - val_loss: 0.0138 - val_mape: 22.8950 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "Epoch 62/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0105 - mape: 20.7214 - mse: 0.0105 - rmse: 0.1025 - val_loss: 0.0138 - val_mape: 22.8387 - val_mse: 0.0138 - val_rmse: 0.1175\n",
      "[MODELO CONGELADO]: 83.14625406265259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 1.9899621781625634, 1.4106601923080424, 0.9209262611724958, 15.428294266798245\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 2.7607136434968282, 1.6615395401545003, 0.8997545771792735, 17.964327365868286\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.836137342490637, 0.9144054584759634, 0.911108358621128, 13.51407045089876\n",
      "PROCESANDO ARCHIVO: Juniperus spp. L.\n",
      "(7264, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus spp. L._best_models.json\n",
      "(4216, 4, 43) (1524, 4, 43) (1188, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0172 - mape: 50.7666 - mse: 0.0172 - rmse: 0.1310 - val_loss: 0.0202 - val_mape: 43.0349 - val_mse: 0.0202 - val_rmse: 0.1423\n",
      "Epoch 2/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0169 - mape: 48.8196 - mse: 0.0169 - rmse: 0.1301 - val_loss: 0.0202 - val_mape: 42.9950 - val_mse: 0.0202 - val_rmse: 0.1420\n",
      "Epoch 3/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0165 - mape: 41.3292 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0201 - val_mape: 42.7001 - val_mse: 0.0201 - val_rmse: 0.1419\n",
      "Epoch 4/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166 - mape: 43.2960 - mse: 0.0166 - rmse: 0.1287 - val_loss: 0.0201 - val_mape: 42.9004 - val_mse: 0.0201 - val_rmse: 0.1419\n",
      "Epoch 5/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0165 - mape: 39.9362 - mse: 0.0165 - rmse: 0.1282 - val_loss: 0.0201 - val_mape: 42.8158 - val_mse: 0.0201 - val_rmse: 0.1419\n",
      "Epoch 6/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0167 - mape: 46.0837 - mse: 0.0167 - rmse: 0.1292 - val_loss: 0.0201 - val_mape: 42.8727 - val_mse: 0.0201 - val_rmse: 0.1417\n",
      "Epoch 7/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - mape: 40.9715 - mse: 0.0164 - rmse: 0.1279 - val_loss: 0.0201 - val_mape: 42.5663 - val_mse: 0.0200 - val_rmse: 0.1416\n",
      "Epoch 8/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0165 - mape: 40.8125 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0201 - val_mape: 42.7606 - val_mse: 0.0201 - val_rmse: 0.1416\n",
      "Epoch 9/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - mape: 44.8852 - mse: 0.0164 - rmse: 0.1280 - val_loss: 0.0200 - val_mape: 42.5862 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 10/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166 - mape: 40.7490 - mse: 0.0166 - rmse: 0.1287 - val_loss: 0.0201 - val_mape: 42.7119 - val_mse: 0.0200 - val_rmse: 0.1416\n",
      "Epoch 11/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163 - mape: 45.2705 - mse: 0.0163 - rmse: 0.1277 - val_loss: 0.0200 - val_mape: 43.0265 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 12/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - mape: 43.4824 - mse: 0.0164 - rmse: 0.1279 - val_loss: 0.0200 - val_mape: 42.7857 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 13/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163 - mape: 51.5041 - mse: 0.0163 - rmse: 0.1276 - val_loss: 0.0200 - val_mape: 42.4833 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 14/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - mape: 39.7623 - mse: 0.0164 - rmse: 0.1282 - val_loss: 0.0200 - val_mape: 42.9779 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 15/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 41.1545 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0200 - val_mape: 42.6955 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 16/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - mape: 43.9097 - mse: 0.0164 - rmse: 0.1278 - val_loss: 0.0200 - val_mape: 42.4080 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 17/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 43.6473 - mse: 0.0162 - rmse: 0.1271 - val_loss: 0.0200 - val_mape: 42.6709 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 18/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 39.8803 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0200 - val_mape: 42.8589 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 19/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164 - mape: 45.8281 - mse: 0.0164 - rmse: 0.1281 - val_loss: 0.0200 - val_mape: 43.0474 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 20/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0165 - mape: 40.5507 - mse: 0.0165 - rmse: 0.1286 - val_loss: 0.0199 - val_mape: 42.6112 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 21/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163 - mape: 41.3558 - mse: 0.0163 - rmse: 0.1275 - val_loss: 0.0200 - val_mape: 42.8780 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 22/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163 - mape: 39.6130 - mse: 0.0163 - rmse: 0.1275 - val_loss: 0.0200 - val_mape: 42.9026 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 23/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166 - mape: 45.7280 - mse: 0.0166 - rmse: 0.1286 - val_loss: 0.0200 - val_mape: 42.9628 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 24/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 44.4665 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0200 - val_mape: 43.0962 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 25/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0161 - mape: 57.2528 - mse: 0.0161 - rmse: 0.1268 - val_loss: 0.0200 - val_mape: 42.8505 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 26/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 43.0847 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0200 - val_mape: 42.5572 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 27/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 50.2422 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0199 - val_mape: 42.6528 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 28/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 44.0577 - mse: 0.0162 - rmse: 0.1273 - val_loss: 0.0199 - val_mape: 42.2195 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 29/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0161 - mape: 39.6276 - mse: 0.0161 - rmse: 0.1268 - val_loss: 0.0199 - val_mape: 42.5701 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 30/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 53.1039 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0199 - val_mape: 42.4758 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 31/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0161 - mape: 43.6456 - mse: 0.0161 - rmse: 0.1270 - val_loss: 0.0200 - val_mape: 42.2778 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 32/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 39.2614 - mse: 0.0162 - rmse: 0.1274 - val_loss: 0.0199 - val_mape: 42.5660 - val_mse: 0.0199 - val_rmse: 0.1411\n",
      "Epoch 33/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0159 - mape: 41.1169 - mse: 0.0159 - rmse: 0.1262 - val_loss: 0.0199 - val_mape: 42.8736 - val_mse: 0.0199 - val_rmse: 0.1412\n",
      "Epoch 34/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0160 - mape: 43.6831 - mse: 0.0160 - rmse: 0.1265 - val_loss: 0.0200 - val_mape: 42.6165 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 35/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 48.1516 - mse: 0.0162 - rmse: 0.1271 - val_loss: 0.0200 - val_mape: 42.6307 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 36/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0161 - mape: 42.9539 - mse: 0.0161 - rmse: 0.1270 - val_loss: 0.0199 - val_mape: 42.7407 - val_mse: 0.0199 - val_rmse: 0.1411\n",
      "Epoch 37/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 50.6784 - mse: 0.0162 - rmse: 0.1272 - val_loss: 0.0200 - val_mape: 42.5569 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 38/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0157 - mape: 47.6920 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0200 - val_mape: 42.5924 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 39/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0160 - mape: 38.9615 - mse: 0.0160 - rmse: 0.1267 - val_loss: 0.0200 - val_mape: 42.9196 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 40/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0159 - mape: 39.5192 - mse: 0.0159 - rmse: 0.1260 - val_loss: 0.0200 - val_mape: 42.8850 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 41/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0159 - mape: 39.7529 - mse: 0.0159 - rmse: 0.1259 - val_loss: 0.0200 - val_mape: 42.8228 - val_mse: 0.0200 - val_rmse: 0.1415\n",
      "Epoch 42/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mape: 38.6495 - mse: 0.0162 - rmse: 0.1273 - val_loss: 0.0200 - val_mape: 42.6912 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 43/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0160 - mape: 39.6000 - mse: 0.0160 - rmse: 0.1265 - val_loss: 0.0200 - val_mape: 42.6411 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 44/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0161 - mape: 38.8551 - mse: 0.0161 - rmse: 0.1270 - val_loss: 0.0200 - val_mape: 42.6255 - val_mse: 0.0199 - val_rmse: 0.1413\n",
      "Epoch 45/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0159 - mape: 39.4319 - mse: 0.0159 - rmse: 0.1260 - val_loss: 0.0200 - val_mape: 43.1497 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 46/200\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163 - mape: 43.8723 - mse: 0.0163 - rmse: 0.1277 - val_loss: 0.0200 - val_mape: 42.9370 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "[MODELO CONGELADO]: 75.29930067062378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 1.346176267588002, 1.160248364613371, 0.8925978954862633, 20.037726095368527\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.5877845979927986, 0.7666711146200818, 0.7391862382880681, 25.172557362061234\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 2.733154019129528, 1.6532253382795485, 0.8558245202625242, 24.48314793139152\n",
      "PROCESANDO ARCHIVO: Pinus roxburghii\n",
      "(10635, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus roxburghii_best_models.json\n",
      "(6309, 4, 43) (2167, 4, 43) (1647, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> False\n",
      "<LSTM name=lstm_5, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0159 - mape: 33.4186 - mse: 0.0159 - rmse: 0.1261 - val_loss: 0.0158 - val_mape: 27.5463 - val_mse: 0.0158 - val_rmse: 0.1259\n",
      "Epoch 2/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0158 - mape: 33.7639 - mse: 0.0158 - rmse: 0.1256 - val_loss: 0.0159 - val_mape: 27.4123 - val_mse: 0.0159 - val_rmse: 0.1259\n",
      "Epoch 3/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0158 - mape: 33.4298 - mse: 0.0158 - rmse: 0.1256 - val_loss: 0.0158 - val_mape: 27.4400 - val_mse: 0.0158 - val_rmse: 0.1259\n",
      "Epoch 4/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.8378 - mse: 0.0157 - rmse: 0.1255 - val_loss: 0.0158 - val_mape: 27.3789 - val_mse: 0.0158 - val_rmse: 0.1259\n",
      "Epoch 5/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0158 - mape: 33.3011 - mse: 0.0158 - rmse: 0.1256 - val_loss: 0.0158 - val_mape: 27.5282 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 6/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0156 - mape: 33.1244 - mse: 0.0156 - rmse: 0.1250 - val_loss: 0.0158 - val_mape: 27.5029 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 7/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0158 - mape: 33.9637 - mse: 0.0158 - rmse: 0.1255 - val_loss: 0.0158 - val_mape: 27.5802 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 8/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.3845 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0159 - val_mape: 27.6063 - val_mse: 0.0159 - val_rmse: 0.1259\n",
      "Epoch 9/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0158 - mape: 33.9183 - mse: 0.0158 - rmse: 0.1258 - val_loss: 0.0158 - val_mape: 27.4579 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 10/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.0245 - mse: 0.0157 - rmse: 0.1253 - val_loss: 0.0158 - val_mape: 27.4786 - val_mse: 0.0158 - val_rmse: 0.1259\n",
      "Epoch 11/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 32.9772 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0158 - val_mape: 27.3892 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 12/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 32.9808 - mse: 0.0157 - rmse: 0.1251 - val_loss: 0.0158 - val_mape: 27.6136 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 13/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.2391 - mse: 0.0157 - rmse: 0.1253 - val_loss: 0.0158 - val_mape: 27.5826 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 14/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0158 - mape: 33.2740 - mse: 0.0158 - rmse: 0.1256 - val_loss: 0.0158 - val_mape: 27.3598 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 15/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 32.8545 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0158 - val_mape: 27.4908 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 16/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0156 - mape: 33.2843 - mse: 0.0156 - rmse: 0.1250 - val_loss: 0.0158 - val_mape: 27.4614 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 17/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0156 - mape: 33.1876 - mse: 0.0156 - rmse: 0.1247 - val_loss: 0.0158 - val_mape: 27.5115 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 18/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.9921 - mse: 0.0157 - rmse: 0.1251 - val_loss: 0.0158 - val_mape: 27.4674 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 19/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0157 - mape: 32.6502 - mse: 0.0157 - rmse: 0.1252 - val_loss: 0.0158 - val_mape: 27.4142 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 20/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0155 - mape: 33.3578 - mse: 0.0155 - rmse: 0.1244 - val_loss: 0.0158 - val_mape: 27.5715 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 21/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0156 - mape: 32.7156 - mse: 0.0156 - rmse: 0.1248 - val_loss: 0.0158 - val_mape: 27.4531 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 22/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.0036 - mse: 0.0157 - rmse: 0.1252 - val_loss: 0.0158 - val_mape: 27.5097 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 23/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 32.7420 - mse: 0.0157 - rmse: 0.1252 - val_loss: 0.0158 - val_mape: 27.5627 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 24/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0158 - mape: 33.1327 - mse: 0.0157 - rmse: 0.1255 - val_loss: 0.0158 - val_mape: 27.5661 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 25/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.1339 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0158 - val_mape: 27.4022 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 26/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0157 - mape: 33.2160 - mse: 0.0157 - rmse: 0.1254 - val_loss: 0.0158 - val_mape: 27.5313 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 27/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0156 - mape: 33.0744 - mse: 0.0156 - rmse: 0.1247 - val_loss: 0.0158 - val_mape: 27.5341 - val_mse: 0.0158 - val_rmse: 0.1257\n",
      "Epoch 28/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0156 - mape: 32.8795 - mse: 0.0156 - rmse: 0.1248 - val_loss: 0.0158 - val_mape: 27.4248 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "Epoch 29/200\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0155 - mape: 33.4430 - mse: 0.0155 - rmse: 0.1246 - val_loss: 0.0158 - val_mape: 27.5422 - val_mse: 0.0158 - val_rmse: 0.1258\n",
      "[MODELO CONGELADO]: 77.10180568695068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 60.21135804027709, 7.759597801450607, 0.7742655089358006, 23.35092700852397\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 47.084878441791446, 6.861842204670073, 0.7898074722328535, 23.47754535608072\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 62.14862410774127, 7.883439865169346, 0.739211386730696, 24.675563541254565\n",
      "PROCESANDO ARCHIVO: Juniperus turkestanica Komar.\n",
      "(6305, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus turkestanica Komar._best_models.json\n",
      "(3664, 4, 43) (1368, 4, 43) (1001, 4, 43)\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> True\n",
      "<Dense name=dense_2, built=True> True\n",
      "<Dropout name=dropout_3, built=True> True\n",
      "<Dense name=dense_3, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0150 - mape: 28.2402 - mse: 0.0150 - rmse: 0.1224 - val_loss: 0.0165 - val_mape: 30.4551 - val_mse: 0.0165 - val_rmse: 0.1284\n",
      "Epoch 2/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0146 - mape: 27.1065 - mse: 0.0146 - rmse: 0.1209 - val_loss: 0.0165 - val_mape: 30.3557 - val_mse: 0.0165 - val_rmse: 0.1283\n",
      "Epoch 3/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0144 - mape: 27.4486 - mse: 0.0144 - rmse: 0.1199 - val_loss: 0.0163 - val_mape: 30.0066 - val_mse: 0.0163 - val_rmse: 0.1279\n",
      "Epoch 4/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0145 - mape: 26.6176 - mse: 0.0145 - rmse: 0.1204 - val_loss: 0.0163 - val_mape: 30.0076 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 5/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0146 - mape: 26.2476 - mse: 0.0146 - rmse: 0.1206 - val_loss: 0.0163 - val_mape: 29.9053 - val_mse: 0.0163 - val_rmse: 0.1276\n",
      "Epoch 6/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0145 - mape: 27.1602 - mse: 0.0145 - rmse: 0.1204 - val_loss: 0.0163 - val_mape: 30.0028 - val_mse: 0.0163 - val_rmse: 0.1277\n",
      "Epoch 7/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mape: 26.5743 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0163 - val_mape: 30.1408 - val_mse: 0.0163 - val_rmse: 0.1276\n",
      "Epoch 8/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0144 - mape: 26.4593 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0163 - val_mape: 29.7668 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 9/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0144 - mape: 27.0735 - mse: 0.0144 - rmse: 0.1199 - val_loss: 0.0163 - val_mape: 29.9513 - val_mse: 0.0163 - val_rmse: 0.1277\n",
      "Epoch 10/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mape: 26.9066 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0163 - val_mape: 30.2335 - val_mse: 0.0163 - val_rmse: 0.1278\n",
      "Epoch 11/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mape: 27.1592 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0163 - val_mape: 30.0329 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 12/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mape: 26.7885 - mse: 0.0143 - rmse: 0.1197 - val_loss: 0.0163 - val_mape: 29.9886 - val_mse: 0.0163 - val_rmse: 0.1277\n",
      "Epoch 13/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mape: 26.1973 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0163 - val_mape: 30.3338 - val_mse: 0.0163 - val_rmse: 0.1276\n",
      "Epoch 14/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mape: 27.4183 - mse: 0.0143 - rmse: 0.1197 - val_loss: 0.0162 - val_mape: 30.0865 - val_mse: 0.0162 - val_rmse: 0.1274\n",
      "Epoch 15/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mape: 26.2747 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0164 - val_mape: 30.3703 - val_mse: 0.0164 - val_rmse: 0.1279\n",
      "Epoch 16/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mape: 26.8103 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0163 - val_mape: 30.1280 - val_mse: 0.0163 - val_rmse: 0.1277\n",
      "Epoch 17/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mape: 25.5447 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0163 - val_mape: 30.0891 - val_mse: 0.0163 - val_rmse: 0.1276\n",
      "Epoch 18/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0141 - mape: 26.8490 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0163 - val_mape: 30.0395 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 19/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mape: 25.5000 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0163 - val_mape: 30.0495 - val_mse: 0.0163 - val_rmse: 0.1277\n",
      "Epoch 20/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mape: 26.0133 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0163 - val_mape: 30.0125 - val_mse: 0.0163 - val_rmse: 0.1275\n",
      "Epoch 21/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mape: 26.7785 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0162 - val_mape: 30.1948 - val_mse: 0.0162 - val_rmse: 0.1275\n",
      "Epoch 22/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mape: 27.1890 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0162 - val_mape: 30.1343 - val_mse: 0.0162 - val_rmse: 0.1275\n",
      "Epoch 23/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0142 - mape: 26.6683 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0162 - val_mape: 29.8717 - val_mse: 0.0162 - val_rmse: 0.1275\n",
      "Epoch 24/200\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0140 - mape: 27.0483 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0163 - val_mape: 30.3734 - val_mse: 0.0163 - val_rmse: 0.1276\n",
      "[MODELO CONGELADO]: 22.363587141036987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 2.610944396957065, 1.6158416992258446, 0.9418326603922483, 16.59673253155935\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 2.036629215490828, 1.427105187255245, 0.8815644927382139, 19.17263492296867\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.9520484685375733, 0.9757297107998574, 0.8248496731629177, 19.57369523421814\n",
      "PROCESANDO ARCHIVO: Populus ciliata\n",
      "(1182, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Populus ciliata_best_models.json\n",
      "(705, 4, 43) (156, 4, 43) (265, 4, 43)\n",
      "<LSTM name=lstm_4, built=True> False\n",
      "<LSTM name=lstm_5, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<LSTM name=lstm_6, built=True> False\n",
      "<LSTM name=lstm_7, built=True> True\n",
      "<Dense name=dense_2, built=True> True\n",
      "<Dropout name=dropout_3, built=True> True\n",
      "<Dense name=dense_3, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0127 - mape: 31.1091 - mse: 0.0127 - rmse: 0.1124 - val_loss: 0.0202 - val_mape: 40.6397 - val_mse: 0.0202 - val_rmse: 0.1423\n",
      "Epoch 2/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mape: 30.4237 - mse: 0.0126 - rmse: 0.1120 - val_loss: 0.0202 - val_mape: 40.3411 - val_mse: 0.0201 - val_rmse: 0.1422\n",
      "Epoch 3/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0127 - mape: 31.2507 - mse: 0.0126 - rmse: 0.1123 - val_loss: 0.0203 - val_mape: 40.2390 - val_mse: 0.0202 - val_rmse: 0.1423\n",
      "Epoch 4/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - mape: 30.8890 - mse: 0.0128 - rmse: 0.1130 - val_loss: 0.0203 - val_mape: 40.5759 - val_mse: 0.0202 - val_rmse: 0.1426\n",
      "Epoch 5/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - mape: 29.4272 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0204 - val_mape: 40.4893 - val_mse: 0.0203 - val_rmse: 0.1427\n",
      "Epoch 6/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - mape: 30.4972 - mse: 0.0123 - rmse: 0.1108 - val_loss: 0.0204 - val_mape: 40.2815 - val_mse: 0.0203 - val_rmse: 0.1428\n",
      "Epoch 7/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0128 - mape: 31.1266 - mse: 0.0128 - rmse: 0.1128 - val_loss: 0.0204 - val_mape: 40.2221 - val_mse: 0.0203 - val_rmse: 0.1427\n",
      "Epoch 8/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mape: 30.7263 - mse: 0.0127 - rmse: 0.1126 - val_loss: 0.0204 - val_mape: 40.2735 - val_mse: 0.0203 - val_rmse: 0.1428\n",
      "Epoch 9/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mape: 29.8972 - mse: 0.0125 - rmse: 0.1117 - val_loss: 0.0204 - val_mape: 39.7500 - val_mse: 0.0203 - val_rmse: 0.1428\n",
      "Epoch 10/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mape: 30.2197 - mse: 0.0124 - rmse: 0.1112 - val_loss: 0.0204 - val_mape: 40.1645 - val_mse: 0.0203 - val_rmse: 0.1428\n",
      "Epoch 11/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - mape: 30.7819 - mse: 0.0125 - rmse: 0.1116 - val_loss: 0.0204 - val_mape: 40.2769 - val_mse: 0.0203 - val_rmse: 0.1428\n",
      "Epoch 12/200\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - mape: 30.2772 - mse: 0.0125 - rmse: 0.1117 - val_loss: 0.0205 - val_mape: 40.5703 - val_mse: 0.0204 - val_rmse: 0.1431\n",
      "[MODELO CONGELADO]: 5.46165919303894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 82.66292570727003, 9.091915403657802, 0.7723993488441996, 22.919676872657604\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 102.85194358129758, 10.141594725746911, 0.5617689964123171, 30.312853700301613\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 55.45381489524232, 7.446731826462016, 0.7229108353410518, 27.483927656319207\n",
      "PROCESANDO ARCHIVO: Abies pindrow\n",
      "(16018, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Abies pindrow_best_models.json\n",
      "(9042, 4, 43) (3441, 4, 43) (2815, 4, 43)\n",
      "<LSTM name=lstm, built=True> False\n",
      "<LSTM name=lstm_1, built=True> False\n",
      "<LSTM name=lstm_2, built=True> False\n",
      "<Dropout name=dropout, built=True> True\n",
      "<LSTM name=lstm_3, built=True> False\n",
      "<LSTM name=lstm_4, built=True> False\n",
      "<LSTM name=lstm_5, built=True> True\n",
      "<Dense name=dense, built=True> True\n",
      "<Dropout name=dropout_1, built=True> True\n",
      "<Dense name=dense_1, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0123 - mape: 23.0604 - mse: 0.0123 - rmse: 0.1107 - val_loss: 0.0119 - val_mape: 20.7975 - val_mse: 0.0119 - val_rmse: 0.1090\n",
      "Epoch 2/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0122 - mape: 22.8626 - mse: 0.0122 - rmse: 0.1106 - val_loss: 0.0118 - val_mape: 20.5620 - val_mse: 0.0118 - val_rmse: 0.1088\n",
      "Epoch 3/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0122 - mape: 22.7891 - mse: 0.0122 - rmse: 0.1105 - val_loss: 0.0118 - val_mape: 20.4802 - val_mse: 0.0118 - val_rmse: 0.1087\n",
      "Epoch 4/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0122 - mape: 22.7984 - mse: 0.0122 - rmse: 0.1103 - val_loss: 0.0118 - val_mape: 20.4188 - val_mse: 0.0118 - val_rmse: 0.1085\n",
      "Epoch 5/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0122 - mape: 22.7556 - mse: 0.0122 - rmse: 0.1106 - val_loss: 0.0118 - val_mape: 20.3956 - val_mse: 0.0118 - val_rmse: 0.1084\n",
      "Epoch 6/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0122 - mape: 22.5846 - mse: 0.0122 - rmse: 0.1104 - val_loss: 0.0118 - val_mape: 20.2795 - val_mse: 0.0118 - val_rmse: 0.1084\n",
      "Epoch 7/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0121 - mape: 22.6732 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0117 - val_mape: 20.2360 - val_mse: 0.0117 - val_rmse: 0.1082\n",
      "Epoch 8/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0121 - mape: 22.6056 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0117 - val_mape: 20.1951 - val_mse: 0.0117 - val_rmse: 0.1082\n",
      "Epoch 9/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4947 - mse: 0.0120 - rmse: 0.1097 - val_loss: 0.0117 - val_mape: 20.1932 - val_mse: 0.0117 - val_rmse: 0.1081\n",
      "Epoch 10/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0121 - mape: 22.7234 - mse: 0.0121 - rmse: 0.1099 - val_loss: 0.0117 - val_mape: 20.0656 - val_mse: 0.0117 - val_rmse: 0.1081\n",
      "Epoch 11/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.5346 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0117 - val_mape: 20.0531 - val_mse: 0.0117 - val_rmse: 0.1080\n",
      "Epoch 12/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4020 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0117 - val_mape: 20.0815 - val_mse: 0.0117 - val_rmse: 0.1080\n",
      "Epoch 13/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0121 - mape: 22.6727 - mse: 0.0121 - rmse: 0.1100 - val_loss: 0.0116 - val_mape: 20.0571 - val_mse: 0.0116 - val_rmse: 0.1079\n",
      "Epoch 14/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3040 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0116 - val_mape: 20.0518 - val_mse: 0.0116 - val_rmse: 0.1078\n",
      "Epoch 15/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.6048 - mse: 0.0120 - rmse: 0.1097 - val_loss: 0.0116 - val_mape: 19.9745 - val_mse: 0.0116 - val_rmse: 0.1078\n",
      "Epoch 16/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3766 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 20.0658 - val_mse: 0.0116 - val_rmse: 0.1077\n",
      "Epoch 17/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3558 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0116 - val_mape: 19.9592 - val_mse: 0.0116 - val_rmse: 0.1078\n",
      "Epoch 18/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.6218 - mse: 0.0120 - rmse: 0.1095 - val_loss: 0.0116 - val_mape: 20.0484 - val_mse: 0.0116 - val_rmse: 0.1077\n",
      "Epoch 19/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.7463 - mse: 0.0120 - rmse: 0.1094 - val_loss: 0.0116 - val_mape: 20.0152 - val_mse: 0.0116 - val_rmse: 0.1077\n",
      "Epoch 20/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.3125 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 20.0662 - val_mse: 0.0116 - val_rmse: 0.1076\n",
      "Epoch 21/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3494 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 20.0358 - val_mse: 0.0116 - val_rmse: 0.1076\n",
      "Epoch 22/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3996 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0116 - val_mape: 19.9466 - val_mse: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 23/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.6057 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 19.8775 - val_mse: 0.0116 - val_rmse: 0.1076\n",
      "Epoch 24/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.2925 - mse: 0.0120 - rmse: 0.1095 - val_loss: 0.0116 - val_mape: 19.9585 - val_mse: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 25/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4410 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 19.9721 - val_mse: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 26/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4614 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 19.9103 - val_mse: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 27/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4087 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0116 - val_mape: 19.8286 - val_mse: 0.0116 - val_rmse: 0.1076\n",
      "Epoch 28/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.7136 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0116 - val_mape: 19.8646 - val_mse: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 29/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.3474 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0115 - val_mape: 19.8410 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 30/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4515 - mse: 0.0120 - rmse: 0.1096 - val_loss: 0.0115 - val_mape: 19.9489 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 31/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2292 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0115 - val_mape: 19.8162 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 32/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4590 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0115 - val_mape: 19.8217 - val_mse: 0.0115 - val_rmse: 0.1075\n",
      "Epoch 33/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4965 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0115 - val_mape: 19.9636 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 34/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1915 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8597 - val_mse: 0.0116 - val_rmse: 0.1075\n",
      "Epoch 35/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4630 - mse: 0.0120 - rmse: 0.1096 - val_loss: 0.0115 - val_mape: 19.8825 - val_mse: 0.0115 - val_rmse: 0.1075\n",
      "Epoch 36/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4082 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0115 - val_mape: 19.8696 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 37/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4339 - mse: 0.0120 - rmse: 0.1097 - val_loss: 0.0115 - val_mape: 19.8721 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 38/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0121 - mape: 22.6415 - mse: 0.0121 - rmse: 0.1101 - val_loss: 0.0115 - val_mape: 19.8460 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 39/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1803 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0115 - val_mape: 19.7604 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 40/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0119 - mape: 22.3606 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.9071 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 41/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2739 - mse: 0.0119 - rmse: 0.1093 - val_loss: 0.0115 - val_mape: 19.8665 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 42/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2957 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0115 - val_mape: 19.8358 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 43/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.3114 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0115 - val_mape: 19.9111 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 44/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2804 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0115 - val_mape: 19.8856 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 45/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2300 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.9181 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 46/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2530 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8425 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 47/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1508 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8348 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 48/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.5020 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8311 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 49/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3841 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.8293 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 50/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.3584 - mse: 0.0120 - rmse: 0.1096 - val_loss: 0.0115 - val_mape: 19.8003 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 51/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2476 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8369 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 52/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.4239 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0115 - val_mape: 19.7273 - val_mse: 0.0115 - val_rmse: 0.1074\n",
      "Epoch 53/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.1940 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0115 - val_mape: 19.8287 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 54/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1972 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 20.0196 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 55/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4791 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.9463 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 56/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.4919 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0115 - val_mape: 19.7618 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 57/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3652 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.7817 - val_mse: 0.0115 - val_rmse: 0.1073\n",
      "Epoch 58/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1100 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8480 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 59/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4028 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0115 - val_mape: 19.9178 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 60/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2644 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.8922 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 61/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0117 - mape: 22.1961 - mse: 0.0117 - rmse: 0.1084 - val_loss: 0.0115 - val_mape: 19.7573 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 62/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3127 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.7134 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 63/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2019 - mse: 0.0119 - rmse: 0.1088 - val_loss: 0.0115 - val_mape: 19.7663 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 64/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1299 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8679 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 65/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3517 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8305 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 66/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4162 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.9469 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 67/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2838 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.7624 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 68/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4154 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8068 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 69/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.5471 - mse: 0.0120 - rmse: 0.1097 - val_loss: 0.0115 - val_mape: 19.7955 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 70/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.3028 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0115 - val_mape: 19.8829 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 71/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0117 - mape: 22.0197 - mse: 0.0117 - rmse: 0.1080 - val_loss: 0.0115 - val_mape: 19.8143 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 72/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.0778 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0115 - val_mape: 19.8434 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 73/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0120 - mape: 22.1559 - mse: 0.0120 - rmse: 0.1094 - val_loss: 0.0115 - val_mape: 19.8432 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 74/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1658 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8552 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 75/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2574 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0115 - val_mape: 19.7359 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 76/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3919 - mse: 0.0119 - rmse: 0.1088 - val_loss: 0.0115 - val_mape: 19.8770 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 77/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4641 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8421 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 78/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0117 - mape: 22.1140 - mse: 0.0117 - rmse: 0.1083 - val_loss: 0.0115 - val_mape: 19.6615 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 79/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4721 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8135 - val_mse: 0.0115 - val_rmse: 0.1072\n",
      "Epoch 80/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3824 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0115 - val_mape: 19.8637 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 81/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0119 - mape: 22.2995 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8132 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 82/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3429 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.7607 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 83/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.0921 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0115 - val_mape: 19.7867 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 84/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3078 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.7487 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 85/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3536 - mse: 0.0119 - rmse: 0.1088 - val_loss: 0.0115 - val_mape: 19.8271 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 86/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.4818 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0114 - val_mape: 19.8425 - val_mse: 0.0114 - val_rmse: 0.1070\n",
      "Epoch 87/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3500 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.8070 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 88/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4202 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.7958 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 89/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3779 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0115 - val_mape: 19.7219 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 90/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.3134 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0115 - val_mape: 19.8972 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 91/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2318 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0115 - val_mape: 19.7238 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 92/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2506 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0115 - val_mape: 19.7616 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 93/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0121 - mape: 22.4468 - mse: 0.0121 - rmse: 0.1098 - val_loss: 0.0114 - val_mape: 19.7831 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 94/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3073 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0114 - val_mape: 19.7804 - val_mse: 0.0114 - val_rmse: 0.1070\n",
      "Epoch 95/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2879 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0115 - val_mape: 19.7918 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 96/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2561 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0115 - val_mape: 19.7133 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 97/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.2100 - mse: 0.0119 - rmse: 0.1091 - val_loss: 0.0115 - val_mape: 19.6384 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 98/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.1763 - mse: 0.0118 - rmse: 0.1084 - val_loss: 0.0114 - val_mape: 19.7767 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 99/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4084 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0114 - val_mape: 19.8171 - val_mse: 0.0114 - val_rmse: 0.1070\n",
      "Epoch 100/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0117 - mape: 22.3129 - mse: 0.0117 - rmse: 0.1083 - val_loss: 0.0115 - val_mape: 19.7965 - val_mse: 0.0115 - val_rmse: 0.1071\n",
      "Epoch 101/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4088 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0115 - val_mape: 19.7351 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 102/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4034 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0114 - val_mape: 19.7123 - val_mse: 0.0114 - val_rmse: 0.1070\n",
      "Epoch 103/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.3385 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0115 - val_mape: 19.7905 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 104/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.0634 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0114 - val_mape: 19.7763 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 105/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.4135 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0114 - val_mape: 19.8514 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 106/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0118 - mape: 22.1613 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0114 - val_mape: 19.8885 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 107/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0120 - mape: 22.4688 - mse: 0.0120 - rmse: 0.1096 - val_loss: 0.0114 - val_mape: 19.8509 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 108/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.1654 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0114 - val_mape: 19.8585 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 109/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3267 - mse: 0.0119 - rmse: 0.1092 - val_loss: 0.0114 - val_mape: 19.7176 - val_mse: 0.0115 - val_rmse: 0.1070\n",
      "Epoch 110/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.1950 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0114 - val_mape: 19.7979 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 111/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.3364 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0114 - val_mape: 19.8605 - val_mse: 0.0114 - val_rmse: 0.1070\n",
      "Epoch 112/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.1805 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0114 - val_mape: 19.8063 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 113/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3749 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0114 - val_mape: 19.7594 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 114/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2619 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0114 - val_mape: 19.8619 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 115/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.1035 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0114 - val_mape: 19.8208 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 116/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3859 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0114 - val_mape: 19.7652 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 117/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4266 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0114 - val_mape: 19.7044 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 118/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.2776 - mse: 0.0118 - rmse: 0.1085 - val_loss: 0.0114 - val_mape: 19.7506 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 119/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.3396 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0114 - val_mape: 19.8086 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 120/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0118 - mape: 22.4540 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0114 - val_mape: 19.6858 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 121/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.3402 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0114 - val_mape: 19.7116 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 122/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.4066 - mse: 0.0119 - rmse: 0.1090 - val_loss: 0.0114 - val_mape: 19.7695 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 123/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0120 - mape: 22.3017 - mse: 0.0120 - rmse: 0.1093 - val_loss: 0.0114 - val_mape: 19.8034 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 124/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.3871 - mse: 0.0118 - rmse: 0.1086 - val_loss: 0.0114 - val_mape: 19.6946 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 125/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0118 - mape: 22.3118 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0114 - val_mape: 19.8000 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 126/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0118 - mape: 22.1875 - mse: 0.0118 - rmse: 0.1088 - val_loss: 0.0114 - val_mape: 19.6869 - val_mse: 0.0114 - val_rmse: 0.1068\n",
      "Epoch 127/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0119 - mape: 22.0834 - mse: 0.0119 - rmse: 0.1089 - val_loss: 0.0114 - val_mape: 19.7535 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "Epoch 128/200\n",
      "\u001b[1m566/566\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0118 - mape: 22.2431 - mse: 0.0118 - rmse: 0.1087 - val_loss: 0.0114 - val_mape: 19.7499 - val_mse: 0.0114 - val_rmse: 0.1069\n",
      "[MODELO CONGELADO]: 542.706116437912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 43.852303891892724, 6.622107209332444, 0.811771901779304, 20.04436864533362\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 35.49411745545523, 5.957693971282448, 0.7975242259421406, 18.86939277300311\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 47.760894465168526, 6.910925731417501, 0.6623439720754176, 20.120572543870928\n"
     ]
    }
   ],
   "source": [
    "# Creamos un df que contiene los resultados de los modelos freeze de cada especie\n",
    "df_Freeze = pd.DataFrame(columns = [\"File\", \"Time\", \"TrainMSE\", \"TrainRMSE\", \"TrainR2\", \"TrainMAPE\", \n",
    "                                    \"ValidationMSE\", \"ValidationRMSE\", \"ValidationR2\", \"ValidationMAPE\",\n",
    "                                    \"TestMSE\", \"TestRMSE\", \"TestR2\", \"TestMAPE\"])\n",
    "\n",
    "for archivo in os.listdir(\"models/LSTMMerged_22_10_24\"):\n",
    "\n",
    "    # Leemos solo los archivos json para obtener los nombres\n",
    "    if os.path.splitext(archivo)[1] == \".json\":\n",
    "        \n",
    "        # Obtenemos el nombre de archivo\n",
    "        nombreArchivo = archivo.split(\"_best_models.json\")[0]\n",
    "\n",
    "        print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "        # Cargamos el modelo entrenado\n",
    "        df = pd.read_csv(f'RCPMerged/{nombreArchivo}_merged.csv')\n",
    "        df = df[~df[\"nametag\"].str.startswith(\"INDI005\")]\n",
    "\n",
    "        # Codificamos, normalización y split de datos\n",
    "        df = codification(df)\n",
    "        print(df.shape)\n",
    "\n",
    "        df, valorNormalizacion = individualNormalization(df)\n",
    "        print(f\"SE HA NORMALIZADO EL ARCHIVO: {archivo}\")\n",
    "\n",
    "        temp_df = df\n",
    "        train_data, val_data, test_data = split_population_individuals(temp_df, train_pct=0.80, val_pct_in_train=0.20, details=False)\n",
    "        train_data.shape, val_data.shape, test_data.shape\n",
    "\n",
    "        # Obtenemos X e y para los datasets de train, val y test \n",
    "        WINDOWS_SIZE = 3\n",
    "        X_train, y_train = df_to_X_y_ind_3(train_data, WINDOWS_SIZE)\n",
    "        X_val, y_val = df_to_X_y_ind_3(val_data, WINDOWS_SIZE)\n",
    "        X_test, y_test = df_to_X_y_ind_3(test_data, WINDOWS_SIZE)\n",
    "        print(X_train.shape, X_test.shape, X_val.shape)\n",
    "\n",
    "        # Cargamos el modelo global\n",
    "        modelLSTM = tf.keras.models.load_model(f'models/LSTMMerged_22_10_24_Trained/{nombreArchivo}.keras')\n",
    "        modelLSTMFreeze = modelLSTM\n",
    "\n",
    "        # Obtener el optimizador del modelo\n",
    "        optimizer = modelLSTMFreeze.optimizer\n",
    "\n",
    "        # Obtenemos el valor de batch size\n",
    "        with open(f'models/LSTMMerged_22_10_24/{archivo}') as f:\n",
    "            parameters = json.load(f)\n",
    "\n",
    "        batch_size_LSTM = parameters[0][\"batch_size\"]\n",
    "\n",
    "        # Indicamos el numero de layers a entrenar\n",
    "        NUM_TRAINABLE = 1\n",
    "\n",
    "        numLSTM_layers = sum(1 for layer in modelLSTMFreeze.layers if \"lstm\" in layer.name)\n",
    "\n",
    "        numFreezeLayers = numLSTM_layers - NUM_TRAINABLE # Congelamos todas menos la útlima capa\n",
    "\n",
    "        numberLayersFreezed = 0\n",
    "\n",
    "        # Congelar las primeras 'numFreezeLayers' capas LSTM\n",
    "        for i, layer in enumerate(modelLSTMFreeze.layers):\n",
    "\n",
    "            if \"lstm\" in layer.name and numFreezeLayers>numberLayersFreezed:\n",
    "                numberLayersFreezed += 1\n",
    "                layer.trainable = False\n",
    "\n",
    "            print(layer, layer.trainable)\n",
    "\n",
    "        # Compilamos el modelo con los nuevos datos\n",
    "        modelLSTMFreeze.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[\n",
    "                                    MeanSquaredError(name='mse'),\n",
    "                                    RootMeanSquaredError(name='rmse'),\n",
    "                                    MeanAbsolutePercentageError(name='mape')\n",
    "                                ])\n",
    "\n",
    "        # Comienza a medir el tiempo de entrenamiento\n",
    "        start_time = time.time()\n",
    "\n",
    "        historyLSTMTransfer = modelLSTMFreeze.fit(X_train, y_train, epochs=200, batch_size=batch_size_LSTM,\n",
    "                                validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "        \n",
    "        # Finaliza la medición del tiempo de entrenamiento\n",
    "        end_time = time.time()\n",
    "        print(f\"[MODELO CONGELADO]: {end_time-start_time}\")\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de entrenamiento\n",
    "        predictions_train = predictionForIndividuals(X_train, y_train, modelLSTMFreeze, batch_size_LSTM)\n",
    "        predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"],predictions_train[\"PredictionsDenormalize\"])\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        train_mape = (np.sum(np.abs(predictions_train[\"PredictionsDenormalize\"] - predictions_train[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_train[\"ActualDenormalize\"]))) * 100\n",
    "        train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de validación\n",
    "        predictions_val = predictionForIndividuals(X_val, y_val, modelLSTMFreeze, batch_size_LSTM)\n",
    "        predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"],predictions_val[\"PredictionsDenormalize\"])\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_mape = (np.sum(np.abs(predictions_val[\"PredictionsDenormalize\"] - predictions_val[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_val[\"ActualDenormalize\"]))) * 100\n",
    "        val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de prueba\n",
    "        predictions_test = predictionForIndividuals(X_test, y_test, modelLSTMFreeze, batch_size_LSTM)\n",
    "        predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"],predictions_test[\"PredictionsDenormalize\"])\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mape = (np.sum(np.abs(predictions_test[\"PredictionsDenormalize\"] - predictions_test[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_test[\"ActualDenormalize\"]))) * 100\n",
    "        test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "        # Guardamos los datos calculados\n",
    "        df_Freeze.loc[len(df_Freeze)] = [nombreArchivo, end_time-start_time,train_mse, train_rmse, train_r2, train_mape, val_mse, val_rmse, val_r2, val_mape, test_mse, test_rmse, test_r2, test_mape]\n",
    "\n",
    "df_Freeze.to_csv(f'resultsTransferOption2/resultados_Option2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
