{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b9d4a9",
   "metadata": {},
   "source": [
    "# Creamos la estructura de datos para la opción 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a352587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 12:32:37.047126: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 12:32:37.168283: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 12:32:37.283993: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-10 12:32:37.389318: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-10 12:32:37.420192: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-10 12:32:37.738482: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-10 12:32:39.654503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import os\n",
    "import json\n",
    "\n",
    "import random as python_random\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras import layers, models\n",
    "\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "from keras_tuner import HyperModel, HyperParameters\n",
    "from keras_tuner.tuners import Hyperband\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D\n",
    "\n",
    "from funcionesComunes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d22a85",
   "metadata": {},
   "source": [
    "## Hiperparametros de TCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9eab114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNNModel(HyperModel):\n",
    "\n",
    "    def __init__(self, input_shape, num_tcnn_layers_input=3, num_tcnn_layers_after_input=3):\n",
    "        self.input_shape = input_shape # (SEQ_LENGTH, num_features)\n",
    "        self.num_tcnn_layers_input = num_tcnn_layers_input\n",
    "        self.num_tcnn_layers_after_input = num_tcnn_layers_after_input\n",
    "\n",
    "        # Para controlar las dimensiones temporales\n",
    "        self.temporalDimension = self.input_shape[0]\n",
    "\n",
    "    def build(self, hp):\n",
    "        \n",
    "        # Podemos ver como \"hp.Int\" permite ir modificando los parámetros del modelo con INT\n",
    "        # Con \"hp.Float\" lo hace pero para valores decimales \n",
    "        # IMPORTANTE!!! Tenemos que controlar las dimensionalidad temporal teniendo en cuenta la reducción que se hace en kernel y Pooling\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        # Numero de capas de TCNN\n",
    "        num_tcnn_layers_input = hp.Int(\"num_tcnn_layers_input\", min_value = 1, \n",
    "                                       max_value = self.num_tcnn_layers_input, default = self.num_tcnn_layers_input)\n",
    "\n",
    "        for i in range(num_tcnn_layers_input):\n",
    "\n",
    "            # Añadiendo capas TCNN\n",
    "            # Solo la primera capa necesita input_shape\n",
    "\n",
    "            if i == 0:\n",
    "                    \n",
    "                # Primera capa de convolución con padding 'same'\n",
    "                model.add(layers.Conv1D(filters=hp.Int(f'units_tcnn_{i}', min_value=32, max_value=128, step=32),\n",
    "                                        kernel_size=3, activation='relu', \n",
    "                                        padding='same', input_shape=self.input_shape)) # Dimensión temporal despues de la convolución: 4 (3+1) (USAMOS PADDING 'SAME')\n",
    "                model.add(layers.BatchNormalization())\n",
    "                model.add(layers.MaxPooling1D(pool_size=2)) # Reducción de la dimensión temporal a la mitad: 4/2=2 (REDONDEA HACIA ABAJO)\n",
    "\n",
    "                # Obtenemos el redondeo hacia abajo\n",
    "                self.temporalDimension = math.floor(self.temporalDimension / 2)\n",
    "    \n",
    "            else:\n",
    "\n",
    "                # Segunda capa de convolución con padding 'same'\n",
    "                model.add(layers.Conv1D(filters=hp.Int(f'units_tcnn_{i}', min_value=32, max_value=128, step=32),\n",
    "                                        kernel_size=3, activation='relu', \n",
    "                                        padding='same')) # Dimensión temporal despues de la convolución: 2 (USAMOS PADDING 'SAME')\n",
    "                model.add(layers.BatchNormalization())\n",
    "\n",
    "                if self.temporalDimension >= 2:\n",
    "                    model.add(layers.MaxPooling1D(pool_size=1)) # Reducción de la dimensión temporal a la mitad: 2/2=1 (REDONDEA HACIA ABAJO)\n",
    "                    self.temporalDimension = math.floor(self.temporalDimension / 2)\n",
    "                else:\n",
    "                    model.add(layers.MaxPooling1D(pool_size=1)) # Reducción de la dimensión temporal a la mitad: 2/1=2 (REDONDEA HACIA ABAJO)\n",
    "\n",
    "        # Se modifica la capa Dropout desde 0.0 hasta 0.5 con un step de 0.05\n",
    "        model.add(Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.25, step=0.05)))\n",
    "        \n",
    "        # Creamos un bucle que permite incrementar las capas TCNN destras de la capa Dropout\n",
    "        num_tcnn_layers_after_input = hp.Int(\"num_tcnn_layers_after_input\", min_value = 1, \n",
    "                                       max_value = self.num_tcnn_layers_after_input, default = self.num_tcnn_layers_after_input)\n",
    "\n",
    "        for i in range(num_tcnn_layers_input):\n",
    "\n",
    "            # Segunda capa de convolución con padding 'same'\n",
    "            model.add(layers.Conv1D(filters=hp.Int(f'units_tcnn_{i}', min_value=32, max_value=128, step=32),\n",
    "                                    kernel_size=3, activation='relu',\n",
    "                                    padding='same')) # USAMOS PADDING 'SAME'\n",
    "            model.add(layers.BatchNormalization())\n",
    "\n",
    "            if self.temporalDimension >= 2:\n",
    "                model.add(layers.MaxPooling1D(pool_size=2)) # REDONDEA HACIA ABAJO\n",
    "                self.temporalDimension = math.floor(self.temporalDimension / 2)\n",
    "            else:\n",
    "                model.add(layers.MaxPooling1D(pool_size=1)) # REDONDEA HACIA ABAJO\n",
    "\n",
    "        # Capa final de convolución con padding 'same'\n",
    "        model.add(layers.Conv1D(filters=hp.Int(f'units_tcnn_{i}', min_value=32, max_value=128, step=32),\n",
    "                                kernel_size=3, activation='relu', padding='same')) # Dimensión temporal despues de la convolución: 1 (USAMOS PADDING 'SAME')\t\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.GlobalAveragePooling1D()) # Promedio global de la dimensión temporal\n",
    "    \n",
    "        # Capa densa\n",
    "        model.add(layers.Dense(hp.Int('dense_units', min_value=4, max_value=64, step=4), \n",
    "                               activation=hp.Choice('dense_activation',values=['relu', 'sigmoid', 'tanh', 'elu', 'relu'])))\n",
    "        \n",
    "        # Capa de salida\n",
    "        model.add(layers.Dense(1, activation=hp.Choice('dense_activation',values=['relu', 'sigmoid', 'tanh', 'elu', 'relu'],default='relu')))\n",
    "        \n",
    "        # Variaciones de los optimizadores\n",
    "        optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "        \n",
    "        if optimizer == 'adam':\n",
    "            opt = Adam(\n",
    "                learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            )\n",
    "        elif optimizer == 'sgd':\n",
    "            opt = SGD(\n",
    "                learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            )\n",
    "        else: # rmsprop\n",
    "            opt = RMSprop(\n",
    "                learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "            )\n",
    "        \n",
    "        \n",
    "        model.compile(optimizer=opt,\n",
    "                        loss=MeanSquaredError(),\n",
    "                        metrics=[RootMeanSquaredError()])\n",
    "            \n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(*args,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 24, 32]),\n",
    "            **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46505f0d",
   "metadata": {},
   "source": [
    "Ajuste de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b0d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from best_models_26_11_24/TCNN_Option3/hyperparameter_tuning_totalMerged/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 37.69391932443064, 6.139537386841996, 0.8447621429766812, 30.714720688274582\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 41.742366455395484, 6.460833263240546, 0.8460422259436728, 30.657899404459314\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 39.8437506796274, 6.312190640310811, 0.8395951685382154, 30.4647682060158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 40.149226175566454, 6.336341702872916, 0.8346502580696119, 32.608209972473375\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 41.47446311760228, 6.440067011887554, 0.84703032999841, 32.41297925703394\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 41.26124638924332, 6.423491759879771, 0.8338885481392728, 31.929180218425813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 39.811170560655135, 6.309609382573151, 0.8360424993157888, 34.09369201421242\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 41.85913379706983, 6.469863506834579, 0.8456115546249812, 33.421291992451266\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 41.98070895576918, 6.479252191091899, 0.8309921021531862, 33.506120775938626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 40.817632937621966, 6.388867891702095, 0.831897505497816, 33.91346676628279\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 42.98781188487128, 6.556509123372839, 0.8414486673528916, 33.64715461949499\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 43.13799980535728, 6.567952481965539, 0.82633302662656, 33.517849762254556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 42.71652854405226, 6.53578828788481, 0.8240771331423689, 33.50361226156917\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 44.64977224201155, 6.682048506409659, 0.8353188827028385, 33.04076928826976\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 44.79546092092528, 6.6929411263603145, 0.819660342294332, 33.046461462359495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 66 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 41.5727230335285, 6.447691294837905, 0.8287877580783671, 29.92330279272292\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 43.87314036619723, 6.6236802735486275, 0.8381833229589828, 29.51455786572894\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 43.01185715692549, 6.558342561724379, 0.8268408575891755, 29.298557468153625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 44.428242317017535, 6.665451396343501, 0.8170276465749106, 34.59208934640519\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 46.126518474879994, 6.791650644348544, 0.8298722206622128, 34.34247534525637\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 46.483137888227475, 6.817854346363486, 0.812866013575664, 34.66835209234273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 48.39446503269742, 6.9566130431911635, 0.8006932370495978, 44.895937856865345\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 48.56472630221678, 6.968839666846755, 0.8208794135537656, 43.19317599902323\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 50.283225849620926, 7.091066622844615, 0.7975674420659555, 42.19310751862318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 43.96312573519754, 6.630469495834933, 0.8189431730768456, 30.231333029592832\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 45.590205270409385, 6.752051930369714, 0.8318502969949368, 29.99487648332308\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 45.36252320974017, 6.73517061474616, 0.8173774364605649, 30.112046897045836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 44.36569404375674, 6.6607577679838155, 0.8172852440886619, 34.971865707958905\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 46.17355686741609, 6.795112719257576, 0.8296987296307978, 33.711627447583275\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 45.71197362372402, 6.761063054263288, 0.8159706026709943, 33.172010347866795\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "data_train_global = np.load(f'RCPMergedTransferTotal/totalMerged_train_transfer.npz', allow_pickle=True)\n",
    "data_val_global = np.load(f'RCPMergedTransferTotal/totalMerged_val_transfer.npz', allow_pickle=True)\n",
    "data_val = np.load(\"RCPMergedTransferTotal/totalMerged_val.npz\", allow_pickle=True)\n",
    "\n",
    "X_train_transfer = data_train_global['X_train_transfer']\n",
    "y_train_transfer = data_train_global['y_train_transfer']\n",
    "X_val_transfer = data_val_global['X_val_transfer']\n",
    "y_val_transfer = data_val_global['y_val_transfer']\n",
    "X_val = data_val['X_val']\n",
    "y_val = data_val['y_val']\n",
    "\n",
    "valorNormalizacion = data_train_global[\"valorNormalizacion\"].item()\n",
    "\n",
    "WINDOWS_SIZE = 3\n",
    "\n",
    "# Crear modelo de hiperparámetros\n",
    "hypermodel = TCNNModel(input_shape=(WINDOWS_SIZE + 1, X_train_transfer.shape[2]), num_tcnn_layers_input=3, num_tcnn_layers_after_input=3)\n",
    "\n",
    "tuner = Hyperband(\n",
    "            hypermodel,\n",
    "            objective='val_loss',\n",
    "            max_epochs=50,\n",
    "            factor=3,\n",
    "            directory='best_models_26_11_24/TCNN_Option3',\n",
    "            project_name=f'hyperparameter_tuning_totalMerged'\n",
    "        )\n",
    "\n",
    "tuner.search(X_train_transfer, y_train_transfer, epochs=50, validation_data=(X_val_transfer, y_val_transfer))\n",
    "\n",
    "top_models_data = []\n",
    "\n",
    "best_trials = tuner.oracle.get_best_trials(num_trials=10)\n",
    "\n",
    "for i, trial in enumerate(best_trials):\n",
    "    hyperparameters = trial.hyperparameters.values\n",
    "    model = tuner.hypermodel.build(trial.hyperparameters)\n",
    "    model.load_weights(tuner.get_trial_dir(trial.trial_id) + \"/checkpoint.weights.h5\")\n",
    "    \n",
    "    # Guardamos el modelo\n",
    "    model.save(f\"models/TCNNMerged_Option3/totalMerged_model_{i+1}.keras\")\n",
    "\n",
    "    # Entrenamiento\n",
    "    predictions_train = predictionForIndividuals(X_train_transfer, y_train_transfer, model, hyperparameters[\"batch_size\"])\n",
    "    predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "    predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "    train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mape = mean_absolute_percentage_error(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"]) *100\n",
    "    train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "    # Validación\n",
    "    predictions_val = predictionForIndividuals(X_val_transfer, y_val_transfer, model, hyperparameters[\"batch_size\"])\n",
    "    predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "    predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "    val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "    val_rmse = np.sqrt(val_mse)\n",
    "    val_mape = mean_absolute_percentage_error(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"]) *100\n",
    "    val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "    # Prueba\n",
    "    predictions_test = predictionForIndividuals(X_val, y_val, model, hyperparameters[\"batch_size\"])\n",
    "    predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "    predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "    test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mape = mean_absolute_percentage_error(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"]) *100\n",
    "    test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "    # Almacenar la información del modelo\n",
    "    model_info = {\n",
    "        'Model Rank': i+1,\n",
    "        'Trial ID': trial.trial_id,\n",
    "        # Métricas del conjunto de entrenamiento\n",
    "        'train_mse': train_mse,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_mape': train_mape,\n",
    "        'train_r2': train_r2,\n",
    "        # Métricas del conjunto de validación\n",
    "        'val_mse': val_mse,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_mape': val_mape,\n",
    "        'val_r2': val_r2,\n",
    "        # Métricas del conjunto de prueba\n",
    "        'test_mse': test_mse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mape': test_mape,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "\n",
    "    print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "    print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "    print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "    # Agregamos los hyperparametros\n",
    "    model_info.update(hyperparameters)\n",
    "    top_models_data.append(model_info)\n",
    "\n",
    "with open(f\"models/TCNNMerged_Option3/totalMerged_best_models.json\", 'w') as file:\n",
    "    json.dump(top_models_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49082251",
   "metadata": {},
   "source": [
    "# Aplicamos transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf7d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: Juniperus spp. L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733830406.612721   17657 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733830406.613009   17657 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-10 12:33:26.649376: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6930 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0194 - val_mape: 36.4047 - val_mse: 0.0194 - val_rmse: 0.1392\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.7729 - mse: 0.0144 - rmse: 0.1202 - val_loss: 0.0195 - val_mape: 36.2386 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3789 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0191 - val_mape: 36.0787 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.0854 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0190 - val_mape: 35.7350 - val_mse: 0.0191 - val_rmse: 0.1380\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0603 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0190 - val_mape: 35.8714 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9322 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0191 - val_mape: 36.0156 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8398 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0191 - val_mape: 36.0352 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5939 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0190 - val_mape: 36.3399 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7703 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0188 - val_mape: 36.5539 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7220 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0190 - val_mape: 36.9101 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7168 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0189 - val_mape: 36.7949 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5878 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0194 - val_mape: 37.2838 - val_mse: 0.0194 - val_rmse: 0.1393\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6674 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0191 - val_mape: 36.4440 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4699 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0191 - val_mape: 37.0011 - val_mse: 0.0191 - val_rmse: 0.1384\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5287 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0188 - val_mape: 35.8484 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4761 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0188 - val_mape: 36.3810 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5755 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0188 - val_mape: 36.8211 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6425 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0189 - val_mape: 36.2762 - val_mse: 0.0189 - val_rmse: 0.1373\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5233 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0189 - val_mape: 36.6805 - val_mse: 0.0189 - val_rmse: 0.1374\n",
      "[MODELO CONGELADO]: 248.9244430065155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.51202404611968, 5.9591965940149745, 0.853748015322271, 21.57585216884064\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.86064757458852, 2.9766839897087696, 0.9076355507633913, 23.59143880531827\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.67064281401741, 3.1097657169017427, 0.8925192530578188, 24.357056334146513\n",
      "PROCESANDO ARCHIVO: Cedrus deodara\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6876 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0195 - val_mape: 37.5049 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6825 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0196 - val_mape: 37.6055 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.5196 - mse: 0.0143 - rmse: 0.1197 - val_loss: 0.0192 - val_mape: 37.4836 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.2213 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0196 - val_mape: 37.5321 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9052 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0196 - val_mape: 37.7213 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0049 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0189 - val_mape: 36.9815 - val_mse: 0.0189 - val_rmse: 0.1375\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8096 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0185 - val_mape: 36.6589 - val_mse: 0.0185 - val_rmse: 0.1360\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6050 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0191 - val_mape: 38.0298 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6224 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0194 - val_mape: 38.5976 - val_mse: 0.0194 - val_rmse: 0.1391\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6262 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0194 - val_mape: 38.1734 - val_mse: 0.0194 - val_rmse: 0.1394\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6411 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0187 - val_mape: 37.2196 - val_mse: 0.0187 - val_rmse: 0.1369\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5566 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0187 - val_mape: 37.6072 - val_mse: 0.0187 - val_rmse: 0.1368\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5209 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0188 - val_mape: 37.2652 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4862 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0189 - val_mape: 37.8463 - val_mse: 0.0189 - val_rmse: 0.1374\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5438 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0190 - val_mape: 37.1531 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4864 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0188 - val_mape: 37.8477 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4846 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0188 - val_mape: 37.6328 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "[MODELO CONGELADO]: 186.98026514053345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.51287247236035, 5.959267779883729, 0.853744521181205, 21.550249337624187\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.422819543702984, 2.9022094245079875, 0.8979940764077936, 23.87102736846969\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 11.559719432940499, 3.399958739887956, 0.888405322409952, 24.572929045210522\n",
      "PROCESANDO ARCHIVO: Abies pindrow\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7627 - mse: 0.0149 - rmse: 0.1220 - val_loss: 0.0197 - val_mape: 38.0973 - val_mse: 0.0198 - val_rmse: 0.1402\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0145 - mape: 30.6585 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0191 - val_mape: 37.6546 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.2726 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0196 - val_mape: 38.6547 - val_mse: 0.0197 - val_rmse: 0.1401\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0630 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0194 - val_mape: 37.9669 - val_mse: 0.0194 - val_rmse: 0.1392\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9275 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0191 - val_mape: 38.4668 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.9603 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0191 - val_mape: 38.3787 - val_mse: 0.0192 - val_rmse: 0.1383\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9097 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0193 - val_mape: 38.1218 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8175 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0190 - val_mape: 38.3429 - val_mse: 0.0191 - val_rmse: 0.1380\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8254 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0192 - val_mape: 39.1953 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6501 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0191 - val_mape: 38.5035 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7118 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0191 - val_mape: 38.1558 - val_mse: 0.0192 - val_rmse: 0.1383\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8078 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0194 - val_mape: 39.4639 - val_mse: 0.0195 - val_rmse: 0.1392\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6955 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0195 - val_mape: 39.7727 - val_mse: 0.0197 - val_rmse: 0.1398\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6566 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0192 - val_mape: 39.4970 - val_mse: 0.0192 - val_rmse: 0.1385\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5206 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0191 - val_mape: 38.2539 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6347 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0193 - val_mape: 38.9647 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6153 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0195 - val_mape: 39.1697 - val_mse: 0.0196 - val_rmse: 0.1398\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6243 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0196 - val_mape: 38.6624 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "[MODELO CONGELADO]: 199.6386330127716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.662701119203966, 5.971825610247168, 0.853127469983729, 21.521973769170817\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 9.341011410459386, 3.0563068253137455, 0.8982017665627533, 24.688997248084636\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 11.104797823525463, 3.3323862056378553, 0.8840837242598754, 25.241383975181268\n",
      "PROCESANDO ARCHIVO: Abies spectabilis\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7294 - mse: 0.0149 - rmse: 0.1219 - val_loss: 0.0218 - val_mape: 39.7429 - val_mse: 0.0219 - val_rmse: 0.1477\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6640 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0220 - val_mape: 39.6231 - val_mse: 0.0220 - val_rmse: 0.1482\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3437 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0218 - val_mape: 39.6399 - val_mse: 0.0218 - val_rmse: 0.1477\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1377 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0221 - val_mape: 39.5269 - val_mse: 0.0222 - val_rmse: 0.1486\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0236 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0218 - val_mape: 39.8176 - val_mse: 0.0219 - val_rmse: 0.1476\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8568 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0220 - val_mape: 39.3922 - val_mse: 0.0221 - val_rmse: 0.1484\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7643 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0216 - val_mape: 40.2131 - val_mse: 0.0217 - val_rmse: 0.1469\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7670 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0212 - val_mape: 39.8380 - val_mse: 0.0213 - val_rmse: 0.1457\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6967 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0210 - val_mape: 39.7210 - val_mse: 0.0210 - val_rmse: 0.1449\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7409 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0209 - val_mape: 40.4216 - val_mse: 0.0210 - val_rmse: 0.1447\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7346 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0208 - val_mape: 40.1337 - val_mse: 0.0209 - val_rmse: 0.1444\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5541 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0208 - val_mape: 40.0763 - val_mse: 0.0208 - val_rmse: 0.1441\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5997 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0210 - val_mape: 39.9721 - val_mse: 0.0210 - val_rmse: 0.1449\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5960 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0210 - val_mape: 40.2054 - val_mse: 0.0210 - val_rmse: 0.1448\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4786 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0208 - val_mape: 39.9803 - val_mse: 0.0208 - val_rmse: 0.1442\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6814 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0209 - val_mape: 40.7131 - val_mse: 0.0209 - val_rmse: 0.1445\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.4864 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0208 - val_mape: 39.8710 - val_mse: 0.0208 - val_rmse: 0.1441\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6511 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0208 - val_mape: 39.7983 - val_mse: 0.0209 - val_rmse: 0.1444\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5011 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0210 - val_mape: 39.9364 - val_mse: 0.0210 - val_rmse: 0.1448\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5325 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0213 - val_mape: 39.3098 - val_mse: 0.0214 - val_rmse: 0.1459\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3992 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0211 - val_mape: 39.8407 - val_mse: 0.0211 - val_rmse: 0.1451\n",
      "Epoch 22/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4008 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0210 - val_mape: 39.8974 - val_mse: 0.0210 - val_rmse: 0.1448\n",
      "[MODELO CONGELADO]: 232.46477699279785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.53988936579224, 5.9615341453179855, 0.8536332553665866, 21.511813087052932\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 13.177589932021663, 3.63009503071499, 0.8991561918497935, 23.827808815859587\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 13.988644240060859, 3.7401396016807795, 0.8789695281177811, 24.719482058560565\n",
      "PROCESANDO ARCHIVO: Pinus roxburghii\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7747 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0196 - val_mape: 37.5858 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0145 - mape: 30.7224 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0192 - val_mape: 37.0919 - val_mse: 0.0192 - val_rmse: 0.1386\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3476 - mse: 0.0143 - rmse: 0.1198 - val_loss: 0.0193 - val_mape: 37.6665 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0845 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0190 - val_mape: 37.3530 - val_mse: 0.0190 - val_rmse: 0.1379\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0765 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0193 - val_mape: 38.0991 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9596 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0193 - val_mape: 38.1304 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8489 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 38.2243 - val_mse: 0.0192 - val_rmse: 0.1385\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6352 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0194 - val_mape: 37.9215 - val_mse: 0.0194 - val_rmse: 0.1393\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6865 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0192 - val_mape: 38.2300 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6527 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 38.3313 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.7394 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0189 - val_mape: 38.6789 - val_mse: 0.0189 - val_rmse: 0.1375\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6423 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0188 - val_mape: 38.1324 - val_mse: 0.0189 - val_rmse: 0.1373\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7240 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0191 - val_mape: 38.1973 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5608 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0192 - val_mape: 38.4562 - val_mse: 0.0192 - val_rmse: 0.1386\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5649 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0192 - val_mape: 37.6524 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5615 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0193 - val_mape: 37.7360 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5436 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0194 - val_mape: 37.9403 - val_mse: 0.0194 - val_rmse: 0.1393\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4393 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0194 - val_mape: 38.6399 - val_mse: 0.0194 - val_rmse: 0.1393\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6524 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0194 - val_mape: 37.8977 - val_mse: 0.0194 - val_rmse: 0.1391\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6459 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0196 - val_mape: 38.7983 - val_mse: 0.0196 - val_rmse: 0.1399\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5185 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0195 - val_mape: 38.6011 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 22/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5015 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0196 - val_mape: 38.3785 - val_mse: 0.0196 - val_rmse: 0.1399\n",
      "[MODELO CONGELADO]: 245.4742021560669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.580470426938895, 5.964936749617626, 0.853466127164451, 21.56461247635443\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 9.272413266623042, 3.0450637541146888, 0.9057840225275868, 23.80507720557487\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.566992205530726, 3.093055480512874, 0.8917330321548723, 24.39190534715197\n",
      "PROCESANDO ARCHIVO: Juniperus spp.\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7688 - mse: 0.0149 - rmse: 0.1222 - val_loss: 0.0187 - val_mape: 36.8440 - val_mse: 0.0187 - val_rmse: 0.1369\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0145 - mape: 30.6536 - mse: 0.0145 - rmse: 0.1203 - val_loss: 0.0187 - val_mape: 36.7378 - val_mse: 0.0187 - val_rmse: 0.1369\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3284 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0187 - val_mape: 36.3313 - val_mse: 0.0187 - val_rmse: 0.1368\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1354 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0186 - val_mape: 36.3832 - val_mse: 0.0186 - val_rmse: 0.1362\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0961 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0186 - val_mape: 36.2723 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8473 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0186 - val_mape: 37.0813 - val_mse: 0.0186 - val_rmse: 0.1362\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7917 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0184 - val_mape: 37.1891 - val_mse: 0.0184 - val_rmse: 0.1357\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7002 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0187 - val_mape: 37.0737 - val_mse: 0.0187 - val_rmse: 0.1368\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6781 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0185 - val_mape: 37.1525 - val_mse: 0.0185 - val_rmse: 0.1362\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6820 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0186 - val_mape: 37.1196 - val_mse: 0.0186 - val_rmse: 0.1365\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6821 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0184 - val_mape: 36.5459 - val_mse: 0.0184 - val_rmse: 0.1356\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6206 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0183 - val_mape: 36.9839 - val_mse: 0.0183 - val_rmse: 0.1352\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5092 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0185 - val_mape: 37.1906 - val_mse: 0.0185 - val_rmse: 0.1360\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5268 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0185 - val_mape: 37.8767 - val_mse: 0.0185 - val_rmse: 0.1362\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5882 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0184 - val_mape: 37.2637 - val_mse: 0.0184 - val_rmse: 0.1356\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6886 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0187 - val_mape: 36.5207 - val_mse: 0.0187 - val_rmse: 0.1366\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4354 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0187 - val_mape: 38.1015 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6234 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0187 - val_mape: 37.5628 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4510 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0186 - val_mape: 36.8786 - val_mse: 0.0186 - val_rmse: 0.1364\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5976 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0182 - val_mape: 37.1318 - val_mse: 0.0182 - val_rmse: 0.1350\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4997 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0182 - val_mape: 36.5320 - val_mse: 0.0182 - val_rmse: 0.1350\n",
      "Epoch 22/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3131 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0183 - val_mape: 37.1748 - val_mse: 0.0183 - val_rmse: 0.1351\n",
      "Epoch 23/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5396 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0183 - val_mape: 36.7959 - val_mse: 0.0183 - val_rmse: 0.1353\n",
      "Epoch 24/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4307 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0182 - val_mape: 37.0368 - val_mse: 0.0182 - val_rmse: 0.1350\n",
      "Epoch 25/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5199 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0184 - val_mape: 37.4072 - val_mse: 0.0184 - val_rmse: 0.1358\n",
      "Epoch 26/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6489 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0183 - val_mape: 36.7466 - val_mse: 0.0183 - val_rmse: 0.1354\n",
      "Epoch 27/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5013 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0185 - val_mape: 36.9788 - val_mse: 0.0185 - val_rmse: 0.1359\n",
      "Epoch 28/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4596 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0184 - val_mape: 36.9837 - val_mse: 0.0184 - val_rmse: 0.1356\n",
      "Epoch 29/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4659 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0186 - val_mape: 37.1402 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 30/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5221 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0184 - val_mape: 37.0653 - val_mse: 0.0184 - val_rmse: 0.1357\n",
      "Epoch 31/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5612 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0186 - val_mape: 37.5060 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 32/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0139 - mape: 29.4111 - mse: 0.0139 - rmse: 0.1181 - val_loss: 0.0187 - val_mape: 37.2531 - val_mse: 0.0187 - val_rmse: 0.1366\n",
      "Epoch 33/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0139 - mape: 29.4072 - mse: 0.0139 - rmse: 0.1181 - val_loss: 0.0187 - val_mape: 37.5710 - val_mse: 0.0187 - val_rmse: 0.1369\n",
      "Epoch 34/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4975 - mse: 0.0140 - rmse: 0.1181 - val_loss: 0.0184 - val_mape: 36.9826 - val_mse: 0.0184 - val_rmse: 0.1356\n",
      "[MODELO CONGELADO]: 379.84084939956665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.45507878538206, 5.954416746028284, 0.8539825375052378, 21.503615701291253\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.9335436156105186, 0.9662006083679096, 0.892432964443111, 23.816923212367012\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 1.0790389026537042, 1.0387679734443607, 0.8963961787550849, 23.662577678252813\n",
      "PROCESANDO ARCHIVO: Tsuga dumosa\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6658 - mse: 0.0149 - rmse: 0.1220 - val_loss: 0.0200 - val_mape: 37.8463 - val_mse: 0.0200 - val_rmse: 0.1413\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.5299 - mse: 0.0144 - rmse: 0.1202 - val_loss: 0.0197 - val_mape: 38.2699 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3466 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0197 - val_mape: 37.9578 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1908 - mse: 0.0142 - rmse: 0.1194 - val_loss: 0.0194 - val_mape: 37.1808 - val_mse: 0.0194 - val_rmse: 0.1394\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1385 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0196 - val_mape: 37.7236 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9200 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0194 - val_mape: 37.9706 - val_mse: 0.0194 - val_rmse: 0.1391\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8688 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0196 - val_mape: 38.1937 - val_mse: 0.0196 - val_rmse: 0.1400\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7633 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0197 - val_mape: 39.2239 - val_mse: 0.0198 - val_rmse: 0.1405\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8635 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0191 - val_mape: 38.6676 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7074 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0195 - val_mape: 38.4991 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6508 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0196 - val_mape: 38.8827 - val_mse: 0.0196 - val_rmse: 0.1400\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6828 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0197 - val_mape: 38.5806 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6493 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0199 - val_mape: 38.6497 - val_mse: 0.0199 - val_rmse: 0.1410\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6109 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0197 - val_mape: 39.2058 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6087 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0196 - val_mape: 37.9299 - val_mse: 0.0196 - val_rmse: 0.1401\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5237 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0197 - val_mape: 38.7634 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4070 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0193 - val_mape: 38.2450 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3662 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0195 - val_mape: 39.1428 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4277 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0195 - val_mape: 38.6931 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "[MODELO CONGELADO]: 210.0029742717743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.52469968020346, 5.960260034612874, 0.8536958122532655, 21.592482126251376\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 9.411104344056039, 3.067752327691406, 0.9069558332020848, 23.900779717587422\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.940278538492283, 3.1528207272999653, 0.8953942170816082, 24.330232238471087\n",
      "PROCESANDO ARCHIVO: Juniperus excelsa M\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6611 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0200 - val_mape: 37.3234 - val_mse: 0.0200 - val_rmse: 0.1414\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0145 - mape: 30.6633 - mse: 0.0145 - rmse: 0.1202 - val_loss: 0.0199 - val_mape: 36.3565 - val_mse: 0.0200 - val_rmse: 0.1411\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.2596 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0196 - val_mape: 36.8209 - val_mse: 0.0196 - val_rmse: 0.1398\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.1793 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0194 - val_mape: 36.7140 - val_mse: 0.0195 - val_rmse: 0.1393\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8566 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0192 - val_mape: 36.1371 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8941 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0191 - val_mape: 36.3617 - val_mse: 0.0192 - val_rmse: 0.1383\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8415 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0193 - val_mape: 37.1040 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6563 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0192 - val_mape: 37.7446 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7722 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0194 - val_mape: 36.9878 - val_mse: 0.0195 - val_rmse: 0.1393\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7065 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0192 - val_mape: 37.0574 - val_mse: 0.0193 - val_rmse: 0.1386\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6627 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0191 - val_mape: 37.3455 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6267 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0192 - val_mape: 37.2825 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7428 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0192 - val_mape: 37.2546 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5305 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0193 - val_mape: 37.2696 - val_mse: 0.0194 - val_rmse: 0.1390\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4852 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0194 - val_mape: 37.5411 - val_mse: 0.0195 - val_rmse: 0.1393\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4553 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0192 - val_mape: 37.3831 - val_mse: 0.0193 - val_rmse: 0.1385\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5249 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0193 - val_mape: 37.8654 - val_mse: 0.0194 - val_rmse: 0.1390\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6635 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0196 - val_mape: 37.7522 - val_mse: 0.0196 - val_rmse: 0.1398\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4593 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0193 - val_mape: 37.4175 - val_mse: 0.0194 - val_rmse: 0.1388\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4759 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0196 - val_mape: 37.5323 - val_mse: 0.0197 - val_rmse: 0.1401\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6034 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0194 - val_mape: 38.3263 - val_mse: 0.0195 - val_rmse: 0.1393\n",
      "[MODELO CONGELADO]: 236.5371069908142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.65450915302208, 5.971139686276154, 0.8531612076076661, 21.745839763164042\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.794716307390281, 2.9655886949120713, 0.908297666758201, 23.577752674303685\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.475436024745232, 3.2365778261529927, 0.8909449107698951, 24.502498473422502\n",
      "PROCESANDO ARCHIVO: Juniperus turkestanica Komar\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7162 - mse: 0.0149 - rmse: 0.1222 - val_loss: 0.0196 - val_mape: 37.9583 - val_mse: 0.0196 - val_rmse: 0.1399\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6672 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0196 - val_mape: 36.8801 - val_mse: 0.0196 - val_rmse: 0.1398\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.4318 - mse: 0.0143 - rmse: 0.1197 - val_loss: 0.0192 - val_mape: 37.6672 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0628 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0191 - val_mape: 37.5121 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0611 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0189 - val_mape: 37.7975 - val_mse: 0.0189 - val_rmse: 0.1376\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8623 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0190 - val_mape: 37.6055 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8441 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0188 - val_mape: 37.4496 - val_mse: 0.0188 - val_rmse: 0.1369\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7048 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0188 - val_mape: 38.3373 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7179 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0188 - val_mape: 37.8492 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7052 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0188 - val_mape: 37.9971 - val_mse: 0.0188 - val_rmse: 0.1373\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.4799 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0189 - val_mape: 37.8094 - val_mse: 0.0189 - val_rmse: 0.1374\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5155 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0188 - val_mape: 38.0236 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5717 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0191 - val_mape: 38.9229 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6028 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0190 - val_mape: 37.4931 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5330 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0188 - val_mape: 38.6411 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4516 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0188 - val_mape: 38.0841 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5824 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0188 - val_mape: 37.8020 - val_mse: 0.0188 - val_rmse: 0.1372\n",
      "[MODELO CONGELADO]: 194.75068712234497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.518129043901105, 5.9597088052941904, 0.8537228726257908, 21.51885430830191\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.695096781620562, 2.9487449502492686, 0.9056551247377931, 23.81151876629205\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.008677898754751, 3.163649458893123, 0.8853959610578578, 24.761916982909753\n",
      "PROCESANDO ARCHIVO: Betula utilis\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7771 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0199 - val_mape: 36.9320 - val_mse: 0.0200 - val_rmse: 0.1412\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6964 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0196 - val_mape: 35.4152 - val_mse: 0.0196 - val_rmse: 0.1398\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3418 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0194 - val_mape: 36.7053 - val_mse: 0.0194 - val_rmse: 0.1392\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.2092 - mse: 0.0142 - rmse: 0.1194 - val_loss: 0.0192 - val_mape: 36.5923 - val_mse: 0.0193 - val_rmse: 0.1386\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0212 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0193 - val_mape: 36.7157 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8239 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0191 - val_mape: 37.0367 - val_mse: 0.0191 - val_rmse: 0.1380\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.7766 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0192 - val_mape: 38.0094 - val_mse: 0.0192 - val_rmse: 0.1385\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.7260 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0191 - val_mape: 37.3267 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6682 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0192 - val_mape: 37.5551 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6530 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0187 - val_mape: 36.3867 - val_mse: 0.0188 - val_rmse: 0.1368\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6133 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0187 - val_mape: 37.4241 - val_mse: 0.0187 - val_rmse: 0.1368\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7623 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0190 - val_mape: 37.3895 - val_mse: 0.0191 - val_rmse: 0.1379\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5849 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0190 - val_mape: 37.5747 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5535 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0190 - val_mape: 37.4676 - val_mse: 0.0190 - val_rmse: 0.1377\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5324 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0187 - val_mape: 37.5152 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5834 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0187 - val_mape: 37.6888 - val_mse: 0.0188 - val_rmse: 0.1368\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6326 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0189 - val_mape: 38.1932 - val_mse: 0.0190 - val_rmse: 0.1375\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6077 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0187 - val_mape: 37.5868 - val_mse: 0.0188 - val_rmse: 0.1369\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4912 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0188 - val_mape: 38.1579 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5012 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0191 - val_mape: 36.9925 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5156 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0189 - val_mape: 37.4604 - val_mse: 0.0189 - val_rmse: 0.1374\n",
      "Epoch 22/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5202 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0191 - val_mape: 37.1561 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 23/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3866 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0189 - val_mape: 37.4294 - val_mse: 0.0189 - val_rmse: 0.1373\n",
      "Epoch 24/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6124 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0187 - val_mape: 37.6307 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 25/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3403 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0187 - val_mape: 37.1513 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 26/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4002 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0191 - val_mape: 37.2618 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 27/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4307 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0192 - val_mape: 37.0699 - val_mse: 0.0193 - val_rmse: 0.1385\n",
      "Epoch 28/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3532 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0192 - val_mape: 36.8425 - val_mse: 0.0192 - val_rmse: 0.1385\n",
      "Epoch 29/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4348 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0189 - val_mape: 37.9519 - val_mse: 0.0189 - val_rmse: 0.1375\n",
      "Epoch 30/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4047 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0189 - val_mape: 37.5588 - val_mse: 0.0190 - val_rmse: 0.1376\n",
      "Epoch 31/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4178 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0189 - val_mape: 38.1167 - val_mse: 0.0190 - val_rmse: 0.1376\n",
      "Epoch 32/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3897 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0188 - val_mape: 36.8934 - val_mse: 0.0188 - val_rmse: 0.1370\n",
      "Epoch 33/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3722 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0191 - val_mape: 37.1982 - val_mse: 0.0192 - val_rmse: 0.1381\n",
      "Epoch 34/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3128 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0193 - val_mape: 37.4092 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "[MODELO CONGELADO]: 391.9744837284088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.44368128177619, 5.953459606126189, 0.8540294767481422, 21.547840398407107\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.948832368022, 2.991459905802182, 0.9070861525343696, 23.623804432615945\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.538675795963421, 3.0884746714136124, 0.896793113122928, 23.97823346119175\n",
      "PROCESANDO ARCHIVO: Pinus gerardiana\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6178 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0191 - val_mape: 37.1936 - val_mse: 0.0192 - val_rmse: 0.1381\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.5795 - mse: 0.0144 - rmse: 0.1200 - val_loss: 0.0187 - val_mape: 37.0497 - val_mse: 0.0188 - val_rmse: 0.1367\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3951 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0186 - val_mape: 36.8975 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0281 - mse: 0.0142 - rmse: 0.1194 - val_loss: 0.0187 - val_mape: 37.4925 - val_mse: 0.0188 - val_rmse: 0.1368\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8974 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0187 - val_mape: 37.6999 - val_mse: 0.0188 - val_rmse: 0.1368\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.9408 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0187 - val_mape: 38.4604 - val_mse: 0.0188 - val_rmse: 0.1368\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8491 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0189 - val_mape: 36.9523 - val_mse: 0.0190 - val_rmse: 0.1375\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6088 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0188 - val_mape: 38.1871 - val_mse: 0.0190 - val_rmse: 0.1373\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5859 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0188 - val_mape: 37.9493 - val_mse: 0.0189 - val_rmse: 0.1371\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7147 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0187 - val_mape: 38.3130 - val_mse: 0.0188 - val_rmse: 0.1369\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7764 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0186 - val_mape: 38.5124 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7151 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0187 - val_mape: 37.8904 - val_mse: 0.0188 - val_rmse: 0.1366\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6135 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0188 - val_mape: 38.4726 - val_mse: 0.0189 - val_rmse: 0.1371\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5503 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0186 - val_mape: 38.2260 - val_mse: 0.0187 - val_rmse: 0.1364\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5722 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0187 - val_mape: 38.0865 - val_mse: 0.0188 - val_rmse: 0.1368\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5366 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0189 - val_mape: 38.1983 - val_mse: 0.0190 - val_rmse: 0.1375\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5666 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0187 - val_mape: 38.0333 - val_mse: 0.0189 - val_rmse: 0.1369\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4799 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0187 - val_mape: 37.5389 - val_mse: 0.0188 - val_rmse: 0.1369\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5207 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0186 - val_mape: 38.3704 - val_mse: 0.0187 - val_rmse: 0.1364\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4608 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0187 - val_mape: 37.4190 - val_mse: 0.0188 - val_rmse: 0.1366\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4954 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0186 - val_mape: 38.3289 - val_mse: 0.0187 - val_rmse: 0.1365\n",
      "[MODELO CONGELADO]: 238.67983889579773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.602288283862826, 5.966765311612551, 0.8533762729541589, 21.599369020438928\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.63313414049966, 2.9382195528073902, 0.9076008685592815, 23.609853142612756\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 9.057115040127304, 3.0095041186426883, 0.8873813425438206, 24.30752358968789\n",
      "PROCESANDO ARCHIVO: Picea smithiana\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.5933 - mse: 0.0149 - rmse: 0.1220 - val_loss: 0.0196 - val_mape: 38.1233 - val_mse: 0.0198 - val_rmse: 0.1401\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6761 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0192 - val_mape: 38.0678 - val_mse: 0.0193 - val_rmse: 0.1386\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3925 - mse: 0.0143 - rmse: 0.1195 - val_loss: 0.0193 - val_mape: 37.7078 - val_mse: 0.0194 - val_rmse: 0.1390\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.1651 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0192 - val_mape: 37.5787 - val_mse: 0.0193 - val_rmse: 0.1385\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1150 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0193 - val_mape: 37.9535 - val_mse: 0.0195 - val_rmse: 0.1388\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9898 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0188 - val_mape: 37.2123 - val_mse: 0.0190 - val_rmse: 0.1373\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7979 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0188 - val_mape: 38.1851 - val_mse: 0.0189 - val_rmse: 0.1373\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8079 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0190 - val_mape: 38.6858 - val_mse: 0.0191 - val_rmse: 0.1378\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6086 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0190 - val_mape: 39.1319 - val_mse: 0.0191 - val_rmse: 0.1378\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5190 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0191 - val_mape: 38.8989 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6627 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0190 - val_mape: 38.6884 - val_mse: 0.0191 - val_rmse: 0.1377\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5657 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0191 - val_mape: 38.3981 - val_mse: 0.0192 - val_rmse: 0.1381\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5633 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0193 - val_mape: 39.0045 - val_mse: 0.0194 - val_rmse: 0.1389\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5897 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0193 - val_mape: 38.7176 - val_mse: 0.0194 - val_rmse: 0.1388\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4868 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0192 - val_mape: 38.9951 - val_mse: 0.0194 - val_rmse: 0.1386\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5906 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0192 - val_mape: 39.1124 - val_mse: 0.0194 - val_rmse: 0.1386\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4728 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0195 - val_mape: 38.1616 - val_mse: 0.0197 - val_rmse: 0.1397\n",
      "[MODELO CONGELADO]: 192.0736813545227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.57120019235018, 5.964159638402562, 0.8535043055066729, 21.53465586444221\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 9.394955231334423, 3.0651191218832627, 0.8994159257570757, 24.153297003320223\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 11.564143257995836, 3.400609248060682, 0.8879105918399397, 24.67685221376313\n",
      "PROCESANDO ARCHIVO: Populus ciliata\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.7307 - mse: 0.0149 - rmse: 0.1220 - val_loss: 0.0199 - val_mape: 36.9651 - val_mse: 0.0199 - val_rmse: 0.1411\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6668 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0197 - val_mape: 37.8685 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.2953 - mse: 0.0143 - rmse: 0.1197 - val_loss: 0.0197 - val_mape: 37.0639 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9942 - mse: 0.0142 - rmse: 0.1193 - val_loss: 0.0193 - val_mape: 37.5895 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.0322 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0191 - val_mape: 37.7548 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.8358 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0193 - val_mape: 37.7828 - val_mse: 0.0194 - val_rmse: 0.1391\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8986 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0193 - val_mape: 38.2346 - val_mse: 0.0194 - val_rmse: 0.1391\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6718 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0191 - val_mape: 38.2644 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8383 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 37.7569 - val_mse: 0.0192 - val_rmse: 0.1386\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6479 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0191 - val_mape: 38.2437 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6070 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 38.1322 - val_mse: 0.0192 - val_rmse: 0.1386\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6740 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0190 - val_mape: 37.7906 - val_mse: 0.0191 - val_rmse: 0.1380\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5825 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0191 - val_mape: 38.2771 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7071 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0201 - val_mape: 38.2014 - val_mse: 0.0202 - val_rmse: 0.1419\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6105 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0197 - val_mape: 38.1529 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5064 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0197 - val_mape: 38.1399 - val_mse: 0.0197 - val_rmse: 0.1402\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4322 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0191 - val_mape: 37.7693 - val_mse: 0.0191 - val_rmse: 0.1383\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4769 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0195 - val_mape: 37.9044 - val_mse: 0.0196 - val_rmse: 0.1398\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3730 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0192 - val_mape: 38.2819 - val_mse: 0.0192 - val_rmse: 0.1384\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4439 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0195 - val_mape: 38.1226 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4680 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0195 - val_mape: 37.3400 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 22/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5658 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0196 - val_mape: 37.9341 - val_mse: 0.0196 - val_rmse: 0.1399\n",
      "[MODELO CONGELADO]: 253.4444556236267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.58748315027946, 5.965524549465827, 0.8534372461098194, 21.5659913197926\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 9.086887565556436, 3.014446477474171, 0.9055993928789798, 23.810772654324854\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.42577768385197, 3.228897286048593, 0.8895640351767495, 24.588954595497466\n",
      "PROCESANDO ARCHIVO: Juniperus recurva\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6875 - mse: 0.0149 - rmse: 0.1221 - val_loss: 0.0194 - val_mape: 38.1534 - val_mse: 0.0195 - val_rmse: 0.1394\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.6383 - mse: 0.0144 - rmse: 0.1200 - val_loss: 0.0198 - val_mape: 37.5501 - val_mse: 0.0199 - val_rmse: 0.1407\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.2672 - mse: 0.0143 - rmse: 0.1196 - val_loss: 0.0198 - val_mape: 37.2636 - val_mse: 0.0199 - val_rmse: 0.1406\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.1320 - mse: 0.0143 - rmse: 0.1194 - val_loss: 0.0193 - val_mape: 37.7229 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9536 - mse: 0.0142 - rmse: 0.1192 - val_loss: 0.0193 - val_mape: 37.3720 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9336 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0192 - val_mape: 37.8145 - val_mse: 0.0193 - val_rmse: 0.1386\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8793 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 38.3048 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7732 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0191 - val_mape: 37.8908 - val_mse: 0.0192 - val_rmse: 0.1383\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7369 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 37.6233 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6736 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0192 - val_mape: 38.0293 - val_mse: 0.0194 - val_rmse: 0.1387\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7245 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0189 - val_mape: 38.4550 - val_mse: 0.0189 - val_rmse: 0.1373\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6619 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0188 - val_mape: 38.3814 - val_mse: 0.0188 - val_rmse: 0.1371\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5978 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0190 - val_mape: 38.3102 - val_mse: 0.0190 - val_rmse: 0.1378\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5502 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0191 - val_mape: 38.6581 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6034 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0190 - val_mape: 38.7487 - val_mse: 0.0191 - val_rmse: 0.1380\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4634 - mse: 0.0140 - rmse: 0.1182 - val_loss: 0.0193 - val_mape: 38.3528 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6367 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0191 - val_mape: 38.1626 - val_mse: 0.0192 - val_rmse: 0.1383\n",
      "Epoch 18/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4380 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0194 - val_mape: 38.9316 - val_mse: 0.0195 - val_rmse: 0.1392\n",
      "Epoch 19/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4866 - mse: 0.0140 - rmse: 0.1185 - val_loss: 0.0194 - val_mape: 38.1470 - val_mse: 0.0195 - val_rmse: 0.1391\n",
      "Epoch 20/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4212 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0195 - val_mape: 38.6783 - val_mse: 0.0196 - val_rmse: 0.1396\n",
      "Epoch 21/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.5538 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0197 - val_mape: 38.5459 - val_mse: 0.0198 - val_rmse: 0.1403\n",
      "Epoch 22/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.3656 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0194 - val_mape: 37.2401 - val_mse: 0.0195 - val_rmse: 0.1394\n",
      "[MODELO CONGELADO]: 251.42376041412354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.48721764580363, 5.957114875995227, 0.8538501774878017, 21.425420997519083\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.677728377706119, 2.945798427880991, 0.9060939306707038, 23.836310640216634\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.438852614066427, 3.230921325886229, 0.8841059065943168, 24.936977168281075\n",
      "PROCESANDO ARCHIVO: Pinus wallichiana\n",
      "<Conv1D name=conv1d_12, built=True> False\n",
      "<BatchNormalization name=batch_normalization_12, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_10, built=True> False\n",
      "<Conv1D name=conv1d_13, built=True> False\n",
      "<BatchNormalization name=batch_normalization_13, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_11, built=True> False\n",
      "<Conv1D name=conv1d_14, built=True> False\n",
      "<BatchNormalization name=batch_normalization_14, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_12, built=True> False\n",
      "<Dropout name=dropout_2, built=True> True\n",
      "<Conv1D name=conv1d_15, built=True> False\n",
      "<BatchNormalization name=batch_normalization_15, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_13, built=True> False\n",
      "<Conv1D name=conv1d_16, built=True> False\n",
      "<BatchNormalization name=batch_normalization_16, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_14, built=True> False\n",
      "<Conv1D name=conv1d_17, built=True> False\n",
      "<BatchNormalization name=batch_normalization_17, built=True> False\n",
      "<MaxPooling1D name=max_pooling1d_15, built=True> False\n",
      "<Conv1D name=conv1d_18, built=True> True\n",
      "<BatchNormalization name=batch_normalization_18, built=True> True\n",
      "<GlobalAveragePooling1D name=global_average_pooling1d_2, built=True> True\n",
      "<Dense name=dense_4, built=True> True\n",
      "<Dense name=dense_5, built=True> True\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 66 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0149 - mape: 31.6547 - mse: 0.0149 - rmse: 0.1220 - val_loss: 0.0196 - val_mape: 37.6500 - val_mse: 0.0196 - val_rmse: 0.1399\n",
      "Epoch 2/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0144 - mape: 30.5563 - mse: 0.0144 - rmse: 0.1201 - val_loss: 0.0195 - val_mape: 38.2938 - val_mse: 0.0195 - val_rmse: 0.1396\n",
      "Epoch 3/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0143 - mape: 30.3647 - mse: 0.0143 - rmse: 0.1197 - val_loss: 0.0193 - val_mape: 38.2730 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 4/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1177 - mse: 0.0142 - rmse: 0.1194 - val_loss: 0.0194 - val_mape: 38.1011 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 5/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0142 - mape: 30.1268 - mse: 0.0142 - rmse: 0.1191 - val_loss: 0.0193 - val_mape: 37.9216 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 6/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0142 - mape: 29.9016 - mse: 0.0142 - rmse: 0.1190 - val_loss: 0.0192 - val_mape: 38.4347 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 7/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8425 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0191 - val_mape: 39.1700 - val_mse: 0.0191 - val_rmse: 0.1381\n",
      "Epoch 8/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.8399 - mse: 0.0141 - rmse: 0.1189 - val_loss: 0.0191 - val_mape: 37.8104 - val_mse: 0.0192 - val_rmse: 0.1382\n",
      "Epoch 9/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6625 - mse: 0.0141 - rmse: 0.1188 - val_loss: 0.0192 - val_mape: 39.3268 - val_mse: 0.0193 - val_rmse: 0.1385\n",
      "Epoch 10/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6515 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0194 - val_mape: 38.7183 - val_mse: 0.0195 - val_rmse: 0.1393\n",
      "Epoch 11/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.5887 - mse: 0.0141 - rmse: 0.1187 - val_loss: 0.0193 - val_mape: 39.3102 - val_mse: 0.0194 - val_rmse: 0.1389\n",
      "Epoch 12/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6656 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0201 - val_mape: 38.5006 - val_mse: 0.0202 - val_rmse: 0.1419\n",
      "Epoch 13/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.6206 - mse: 0.0141 - rmse: 0.1186 - val_loss: 0.0201 - val_mape: 38.4838 - val_mse: 0.0201 - val_rmse: 0.1417\n",
      "Epoch 14/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.4817 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0196 - val_mape: 38.3441 - val_mse: 0.0197 - val_rmse: 0.1400\n",
      "Epoch 15/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0141 - mape: 29.7014 - mse: 0.0141 - rmse: 0.1185 - val_loss: 0.0198 - val_mape: 38.7836 - val_mse: 0.0199 - val_rmse: 0.1407\n",
      "Epoch 16/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6098 - mse: 0.0140 - rmse: 0.1184 - val_loss: 0.0194 - val_mape: 38.4970 - val_mse: 0.0195 - val_rmse: 0.1395\n",
      "Epoch 17/200\n",
      "\u001b[1m4016/4016\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0140 - mape: 29.6168 - mse: 0.0140 - rmse: 0.1183 - val_loss: 0.0194 - val_mape: 38.7293 - val_mse: 0.0195 - val_rmse: 0.1394\n",
      "[MODELO CONGELADO]: 194.65739631652832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 35.57715277242924, 5.964658646765064, 0.8534797905241029, 21.59416303322401\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.111307744656694, 2.8480357695535874, 0.9076936961421492, 23.95243140266023\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 10.34033121743052, 3.2156385396108376, 0.8908624825166929, 24.698819911659754\n"
     ]
    }
   ],
   "source": [
    "# Creamos un df que contiene los resultados de los modelos freeze de cada especie\n",
    "df_Freeze = pd.DataFrame(columns = [\"File\", \"Time\", \"TrainMSE\", \"TrainRMSE\", \"TrainR2\", \"TrainMAPE\", \n",
    "                                    \"ValidationMSE\", \"ValidationRMSE\", \"ValidationR2\", \"ValidationMAPE\",\n",
    "                                    \"TestMSE\", \"TestRMSE\", \"TestR2\", \"TestMAPE\"])\n",
    "\n",
    "for archivo in os.listdir(\"RCPMergedTransfer\"):\n",
    "    if \"train\" in archivo: \n",
    "        \n",
    "        nombreArchivo = archivo.split(\"_train\")[0]\n",
    "        print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "        # Cargar datos\n",
    "        data_transfer_train = np.load(f'RCPMergedTransferTotal/totalMerged_train_transfer.npz', allow_pickle=True)\n",
    "        data_transfer_val = np.load(f'RCPMergedTransfer/{nombreArchivo}_val.npz', allow_pickle=True)\n",
    "        data_transfer_test = np.load(f'RCPMergedTransfer/{nombreArchivo}_test.npz', allow_pickle=True)\n",
    "        \n",
    "        # Aqui tenemos que usar TRAIN original para aplicar transfer \n",
    "        X_train_transfer = data_transfer_train[\"X_train_transfer\"]\n",
    "        y_train_transfer = data_transfer_train[\"y_train_transfer\"]\n",
    "\n",
    "        # Aqui tenemos que usar VAL original para aplicar transfer \n",
    "        X_val_transfer = data_transfer_val[\"X_val\"]\n",
    "        y_val_transfer = data_transfer_val[\"y_val\"]\n",
    "        \n",
    "        # Este test es para ver la capacidad del modelo\n",
    "        X_test_transfer = data_transfer_test[\"X_test\"]\n",
    "        y_test_transfer = data_transfer_test[\"y_test\"]\n",
    "\n",
    "        # Valor normalizacion\n",
    "        valorNormalizacion_train = data_transfer_train[\"valorNormalizacion\"].item()\n",
    "        valorNormalizacion = data_transfer_test[\"valorNormalizacion\"].item()\n",
    "\n",
    "        # Cargamos el conjunto de datos de val original para hacer el transfer\n",
    "        model = tf.keras.models.load_model('models/TCNNMerged_Option3/totalMerged_model_1.keras')\n",
    "        modelFreeze = model\n",
    "        \n",
    "        # Obtenemos el valor de batch size\n",
    "        with open(f'models/TCNNMerged_Option3/totalMerged_best_models.json') as f:\n",
    "            parameters = json.load(f)\n",
    "\n",
    "        # Obtener el optimizador del modelo\n",
    "        optimizer = model.optimizer\n",
    "\n",
    "        batch_size_LSTM = parameters[0][\"batch_size\"]\n",
    "\n",
    "        # Indicamos el numero de layers a entrenar\n",
    "        NUM_TRAINABLE = 1\n",
    "\n",
    "        numTCNN_layers = sum(1 for layer in model.layers if isinstance(layer, (Conv1D)))\n",
    "\n",
    "        numFreezeLayers = numTCNN_layers - NUM_TRAINABLE # Congelamos todas menos la útlima capa\n",
    "\n",
    "        numberLayersFreezed = 0\n",
    "\n",
    "        # Recorre las capas en orden inverso\n",
    "        for i, layer in enumerate(model.layers):\n",
    "\n",
    "            if isinstance(layer, (Conv1D)):\n",
    "                numberLayersFreezed +=1\n",
    "        \n",
    "            if isinstance(layer, (Conv1D, BatchNormalization, MaxPooling1D)) and numFreezeLayers>=numberLayersFreezed:\n",
    "                \n",
    "                layer.trainable = False\n",
    "            \n",
    "            print(layer, layer.trainable)\n",
    "\n",
    "\n",
    "        # Compilamos el modelo con los nuevos datos\n",
    "        model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[\n",
    "                                    MeanSquaredError(name='mse'),\n",
    "                                    RootMeanSquaredError(name='rmse'),\n",
    "                                    MeanAbsolutePercentageError(name='mape')\n",
    "                                ])\n",
    "\n",
    "        # Comienza a medir el tiempo de entrenamiento\n",
    "        start_time = time.time()\n",
    "\n",
    "        historyLSTMTransfer = modelFreeze.fit(X_train_transfer, y_train_transfer, epochs=200, batch_size=batch_size_LSTM,\n",
    "                                validation_data=(X_val_transfer, y_val_transfer), callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "        \n",
    "        # Finaliza la medición del tiempo de entrenamiento\n",
    "        end_time = time.time()\n",
    "        print(f\"[MODELO CONGELADO]: {end_time-start_time}\")\n",
    "\n",
    "        # Guardamos el modelo\n",
    "        modelFreeze.save(f\"models/TCNNMerged_Option3/{nombreArchivo}.keras\")\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de entrenamiento\n",
    "        predictions_train = predictionForIndividuals(X_train_transfer, y_train_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion_train, \"Predictions\"), axis=1)\n",
    "        predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion_train, \"Actuals\"), axis=1)\n",
    "\n",
    "        train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"],predictions_train[\"PredictionsDenormalize\"])\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        train_mape = (np.sum(np.abs(predictions_train[\"PredictionsDenormalize\"] - predictions_train[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_train[\"ActualDenormalize\"]))) * 100\n",
    "        train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de validación\n",
    "        predictions_val = predictionForIndividuals(X_val_transfer, y_val_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"],predictions_val[\"PredictionsDenormalize\"])\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_mape = (np.sum(np.abs(predictions_val[\"PredictionsDenormalize\"] - predictions_val[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_val[\"ActualDenormalize\"]))) * 100\n",
    "        val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de prueba\n",
    "        predictions_test = predictionForIndividuals(X_test_transfer, y_test_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"],predictions_test[\"PredictionsDenormalize\"])\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mape = (np.sum(np.abs(predictions_test[\"PredictionsDenormalize\"] - predictions_test[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_test[\"ActualDenormalize\"]))) * 100\n",
    "        test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "        # Guardamos los datos calculados\n",
    "        df_Freeze.loc[len(df_Freeze)] = [nombreArchivo, end_time-start_time,train_mse, train_rmse, train_r2, train_mape, val_mse, val_rmse, val_r2, val_mape, test_mse, test_rmse, test_r2, test_mape]\n",
    "\n",
    "df_Freeze.to_csv(\"resultsTransferOption3/resultados_Option3_TCNN.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
