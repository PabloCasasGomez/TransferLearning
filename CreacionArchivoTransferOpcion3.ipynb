{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b9d4a9",
   "metadata": {},
   "source": [
    "# Creamos la estructura de datos para la opción 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a352587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 09:56:50.290127: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 09:56:50.293372: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 09:56:50.303453: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 09:56:50.320945: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 09:56:50.325927: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 09:56:50.344537: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 09:56:51.027973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import os\n",
    "import json\n",
    "\n",
    "import random as python_random\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras import layers, models\n",
    "\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "from keras_tuner import HyperModel, HyperParameters\n",
    "from keras_tuner.tuners import Hyperband\n",
    "\n",
    "from funcionesComunes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e6d38",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f6b41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir el modelo LSTM basado en la configuración\n",
    "def build_model_from_config(input_shape, config):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Añadir capas LSTM iniciales\n",
    "    for i in range(config[\"num_lstm_layers\"]):\n",
    "        units = config.get(f\"units_lstm_{i}\")\n",
    "        if i == 0:\n",
    "            model.add(LSTM(units=units, input_shape=input_shape, return_sequences=True, use_bias=True))\n",
    "        else:\n",
    "            model.add(LSTM(units=units, return_sequences=True, use_bias=True))\n",
    "    \n",
    "    # Capa Dropout\n",
    "    model.add(Dropout(config[\"dropout\"]))\n",
    "    \n",
    "    # Capas LSTM adicionales después de Dropout\n",
    "    for i in range(config[\"num_lstm_layers_after\"]):\n",
    "        units = config.get(f\"units_lstm_after_{i}\")\n",
    "        return_sequences = (i < config[\"num_lstm_layers_after\"] - 1)  # Última capa no tiene return_sequences\n",
    "        model.add(LSTM(units=units, return_sequences=return_sequences, use_bias=True))\n",
    "    \n",
    "    # Capa Dense\n",
    "    model.add(Dense(config[\"dense_units\"], activation=config[\"dense_activation_1\"], use_bias=True))\n",
    "    \n",
    "    # Segunda capa Dropout\n",
    "    model.add(Dropout(config[\"dropout_2\"]))\n",
    "    \n",
    "    # Capa de salida Dense\n",
    "    model.add(Dense(1, activation=config[\"dense_activation_2\"], use_bias=True))\n",
    "    \n",
    "    # Configurar el optimizador con el learning rate especificado\n",
    "    optimizer = Adam(learning_rate=config[\"learning_rate\"])\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=MeanSquaredError(),\n",
    "                  metrics=[MeanSquaredError(name='mse'),\n",
    "                           RootMeanSquaredError(name='rmse'),\n",
    "                           MeanAbsolutePercentageError(name='mape')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16e6ac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: totalMerged\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 8ms/step - loss: 0.0531 - mape: 88.6525 - mse: 0.0531 - rmse: 0.2294 - val_loss: 0.0469 - val_mape: 87.4840 - val_mse: 0.0469 - val_rmse: 0.2166\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - loss: 0.0477 - mape: 87.7562 - mse: 0.0477 - rmse: 0.2184 - val_loss: 0.0467 - val_mape: 87.8727 - val_mse: 0.0467 - val_rmse: 0.2161\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8ms/step - loss: 0.0471 - mape: 86.7097 - mse: 0.0471 - rmse: 0.2170 - val_loss: 0.0472 - val_mape: 89.4058 - val_mse: 0.0472 - val_rmse: 0.2172\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0469 - mape: 86.7213 - mse: 0.0469 - rmse: 0.2166 - val_loss: 0.0469 - val_mape: 88.5503 - val_mse: 0.0469 - val_rmse: 0.2166\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0466 - mape: 86.1260 - mse: 0.0466 - rmse: 0.2159 - val_loss: 0.0465 - val_mape: 86.0774 - val_mse: 0.0465 - val_rmse: 0.2156\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0463 - mape: 85.4693 - mse: 0.0463 - rmse: 0.2152 - val_loss: 0.0468 - val_mape: 84.6582 - val_mse: 0.0468 - val_rmse: 0.2163\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8ms/step - loss: 0.0461 - mape: 85.0562 - mse: 0.0461 - rmse: 0.2146 - val_loss: 0.0463 - val_mape: 85.7231 - val_mse: 0.0462 - val_rmse: 0.2151\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - loss: 0.0460 - mape: 85.1056 - mse: 0.0460 - rmse: 0.2145 - val_loss: 0.0459 - val_mape: 83.5603 - val_mse: 0.0459 - val_rmse: 0.2143\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - loss: 0.0458 - mape: 84.5856 - mse: 0.0458 - rmse: 0.2139 - val_loss: 0.0469 - val_mape: 88.0220 - val_mse: 0.0469 - val_rmse: 0.2166\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0455 - mape: 84.3325 - mse: 0.0455 - rmse: 0.2134 - val_loss: 0.0459 - val_mape: 83.6176 - val_mse: 0.0459 - val_rmse: 0.2141\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8ms/step - loss: 0.0454 - mape: 84.0674 - mse: 0.0454 - rmse: 0.2131 - val_loss: 0.0463 - val_mape: 85.7243 - val_mse: 0.0462 - val_rmse: 0.2151\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0455 - mape: 84.2783 - mse: 0.0455 - rmse: 0.2133 - val_loss: 0.0457 - val_mape: 84.2215 - val_mse: 0.0457 - val_rmse: 0.2137\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0450 - mape: 83.4278 - mse: 0.0450 - rmse: 0.2122 - val_loss: 0.0463 - val_mape: 81.4281 - val_mse: 0.0463 - val_rmse: 0.2152\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0456 - mape: 83.5820 - mse: 0.0456 - rmse: 0.2135 - val_loss: 0.0457 - val_mape: 82.3097 - val_mse: 0.0457 - val_rmse: 0.2138\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0453 - mape: 83.1176 - mse: 0.0453 - rmse: 0.2128 - val_loss: 0.0458 - val_mape: 82.7973 - val_mse: 0.0458 - val_rmse: 0.2141\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0452 - mape: 82.9185 - mse: 0.0452 - rmse: 0.2125 - val_loss: 0.0459 - val_mape: 82.6134 - val_mse: 0.0459 - val_rmse: 0.2142\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0450 - mape: 82.1549 - mse: 0.0450 - rmse: 0.2122 - val_loss: 0.0455 - val_mape: 82.7494 - val_mse: 0.0455 - val_rmse: 0.2133\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0450 - mape: 82.4585 - mse: 0.0450 - rmse: 0.2122 - val_loss: 0.0460 - val_mape: 85.0983 - val_mse: 0.0460 - val_rmse: 0.2145\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0449 - mape: 82.5230 - mse: 0.0449 - rmse: 0.2119 - val_loss: 0.0453 - val_mape: 81.8748 - val_mse: 0.0453 - val_rmse: 0.2129\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0448 - mape: 81.4209 - mse: 0.0448 - rmse: 0.2116 - val_loss: 0.0457 - val_mape: 84.2890 - val_mse: 0.0457 - val_rmse: 0.2139\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0446 - mape: 80.0700 - mse: 0.0446 - rmse: 0.2113 - val_loss: 0.0453 - val_mape: 84.6305 - val_mse: 0.0453 - val_rmse: 0.2129\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0443 - mape: 80.3675 - mse: 0.0443 - rmse: 0.2105 - val_loss: 0.0447 - val_mape: 80.5348 - val_mse: 0.0447 - val_rmse: 0.2115\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0442 - mape: 79.8937 - mse: 0.0442 - rmse: 0.2101 - val_loss: 0.0453 - val_mape: 79.4264 - val_mse: 0.0453 - val_rmse: 0.2128\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0444 - mape: 80.0593 - mse: 0.0444 - rmse: 0.2107 - val_loss: 0.0451 - val_mape: 77.0318 - val_mse: 0.0451 - val_rmse: 0.2125\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0441 - mape: 79.7463 - mse: 0.0441 - rmse: 0.2100 - val_loss: 0.0453 - val_mape: 78.6392 - val_mse: 0.0453 - val_rmse: 0.2129\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0441 - mape: 80.0303 - mse: 0.0441 - rmse: 0.2100 - val_loss: 0.0446 - val_mape: 77.7625 - val_mse: 0.0446 - val_rmse: 0.2112\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0439 - mape: 78.4649 - mse: 0.0439 - rmse: 0.2094 - val_loss: 0.0446 - val_mape: 80.9329 - val_mse: 0.0446 - val_rmse: 0.2112\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0438 - mape: 79.0748 - mse: 0.0438 - rmse: 0.2092 - val_loss: 0.0442 - val_mape: 79.5933 - val_mse: 0.0442 - val_rmse: 0.2103\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0436 - mape: 78.2564 - mse: 0.0436 - rmse: 0.2087 - val_loss: 0.0438 - val_mape: 78.0099 - val_mse: 0.0438 - val_rmse: 0.2094\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0433 - mape: 77.3443 - mse: 0.0433 - rmse: 0.2081 - val_loss: 0.0437 - val_mape: 77.1448 - val_mse: 0.0437 - val_rmse: 0.2092\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0434 - mape: 78.4631 - mse: 0.0434 - rmse: 0.2084 - val_loss: 0.0444 - val_mape: 77.3631 - val_mse: 0.0444 - val_rmse: 0.2107\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0435 - mape: 78.3798 - mse: 0.0435 - rmse: 0.2085 - val_loss: 0.0450 - val_mape: 75.1758 - val_mse: 0.0450 - val_rmse: 0.2121\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0434 - mape: 78.7695 - mse: 0.0434 - rmse: 0.2083 - val_loss: 0.0432 - val_mape: 76.4710 - val_mse: 0.0432 - val_rmse: 0.2078\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0427 - mape: 76.4830 - mse: 0.0427 - rmse: 0.2065 - val_loss: 0.0431 - val_mape: 75.5010 - val_mse: 0.0431 - val_rmse: 0.2076\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0423 - mape: 76.6829 - mse: 0.0423 - rmse: 0.2057 - val_loss: 0.0432 - val_mape: 72.3068 - val_mse: 0.0432 - val_rmse: 0.2079\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0415 - mape: 73.9821 - mse: 0.0415 - rmse: 0.2037 - val_loss: 0.0400 - val_mape: 68.9844 - val_mse: 0.0400 - val_rmse: 0.2000\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0377 - mape: 67.6093 - mse: 0.0377 - rmse: 0.1941 - val_loss: 0.0313 - val_mape: 50.1820 - val_mse: 0.0313 - val_rmse: 0.1768\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0298 - mape: 55.5947 - mse: 0.0298 - rmse: 0.1725 - val_loss: 0.0315 - val_mape: 47.6606 - val_mse: 0.0315 - val_rmse: 0.1774\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0265 - mape: 52.0370 - mse: 0.0265 - rmse: 0.1626 - val_loss: 0.0227 - val_mape: 44.6115 - val_mse: 0.0227 - val_rmse: 0.1507\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0226 - mape: 46.7548 - mse: 0.0226 - rmse: 0.1503 - val_loss: 0.0197 - val_mape: 39.7171 - val_mse: 0.0197 - val_rmse: 0.1403\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0205 - mape: 43.4805 - mse: 0.0205 - rmse: 0.1433 - val_loss: 0.0178 - val_mape: 39.3968 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0198 - mape: 42.2240 - mse: 0.0198 - rmse: 0.1406 - val_loss: 0.0172 - val_mape: 38.1650 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0193 - mape: 41.1470 - mse: 0.0193 - rmse: 0.1390 - val_loss: 0.0172 - val_mape: 37.0367 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0192 - mape: 40.5024 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0173 - val_mape: 37.3695 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0192 - mape: 40.7604 - mse: 0.0192 - rmse: 0.1385 - val_loss: 0.0170 - val_mape: 36.4840 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0191 - mape: 40.0460 - mse: 0.0191 - rmse: 0.1380 - val_loss: 0.0171 - val_mape: 37.3166 - val_mse: 0.0171 - val_rmse: 0.1306\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0190 - mape: 39.9477 - mse: 0.0190 - rmse: 0.1379 - val_loss: 0.0169 - val_mape: 35.5891 - val_mse: 0.0169 - val_rmse: 0.1302\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0190 - mape: 40.0423 - mse: 0.0190 - rmse: 0.1378 - val_loss: 0.0170 - val_mape: 36.4104 - val_mse: 0.0170 - val_rmse: 0.1303\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0189 - mape: 39.6660 - mse: 0.0189 - rmse: 0.1375 - val_loss: 0.0168 - val_mape: 35.1871 - val_mse: 0.0168 - val_rmse: 0.1298\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0188 - mape: 39.0921 - mse: 0.0188 - rmse: 0.1371 - val_loss: 0.0170 - val_mape: 37.4463 - val_mse: 0.0170 - val_rmse: 0.1304\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0189 - mape: 38.8606 - mse: 0.0189 - rmse: 0.1374 - val_loss: 0.0172 - val_mape: 36.9807 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0191 - mape: 39.2873 - mse: 0.0191 - rmse: 0.1381 - val_loss: 0.0201 - val_mape: 46.2373 - val_mse: 0.0201 - val_rmse: 0.1417\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0193 - mape: 39.7584 - mse: 0.0193 - rmse: 0.1389 - val_loss: 0.0193 - val_mape: 41.8368 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0190 - mape: 39.0508 - mse: 0.0190 - rmse: 0.1377 - val_loss: 0.0180 - val_mape: 35.0257 - val_mse: 0.0180 - val_rmse: 0.1341\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.5261 - mse: 0.0188 - rmse: 0.1372 - val_loss: 0.0191 - val_mape: 38.7222 - val_mse: 0.0191 - val_rmse: 0.1382\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.3207 - mse: 0.0187 - rmse: 0.1367 - val_loss: 0.0186 - val_mape: 39.5935 - val_mse: 0.0186 - val_rmse: 0.1364\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0188 - mape: 38.5404 - mse: 0.0188 - rmse: 0.1370 - val_loss: 0.0182 - val_mape: 39.9950 - val_mse: 0.0182 - val_rmse: 0.1350\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.1510 - mse: 0.0187 - rmse: 0.1368 - val_loss: 0.0184 - val_mape: 40.3818 - val_mse: 0.0184 - val_rmse: 0.1358\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.3810 - mse: 0.0187 - rmse: 0.1367 - val_loss: 0.0177 - val_mape: 40.4453 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 9ms/step - loss: 0.0186 - mape: 37.8513 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0187 - val_mape: 46.3175 - val_mse: 0.0187 - val_rmse: 0.1367\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0186 - mape: 37.7563 - mse: 0.0186 - rmse: 0.1365 - val_loss: 0.0184 - val_mape: 45.2781 - val_mse: 0.0184 - val_rmse: 0.1358\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0187 - mape: 38.3522 - mse: 0.0187 - rmse: 0.1366 - val_loss: 0.0180 - val_mape: 39.1733 - val_mse: 0.0180 - val_rmse: 0.1342\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.8181 - mse: 0.0185 - rmse: 0.1362 - val_loss: 0.0178 - val_mape: 35.5716 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 64/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.7369 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0186 - val_mape: 39.2804 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 65/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0184 - mape: 37.2378 - mse: 0.0184 - rmse: 0.1358 - val_loss: 0.0184 - val_mape: 42.1939 - val_mse: 0.0184 - val_rmse: 0.1355\n",
      "Epoch 66/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.6869 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0175 - val_mape: 32.0000 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 67/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.5143 - mse: 0.0185 - rmse: 0.1359 - val_loss: 0.0198 - val_mape: 40.5586 - val_mse: 0.0198 - val_rmse: 0.1408\n",
      "Epoch 68/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 9ms/step - loss: 0.0184 - mape: 37.5035 - mse: 0.0184 - rmse: 0.1357 - val_loss: 0.0186 - val_mape: 40.3848 - val_mse: 0.0186 - val_rmse: 0.1363\n",
      "Epoch 69/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 9ms/step - loss: 0.0185 - mape: 37.9375 - mse: 0.0185 - rmse: 0.1360 - val_loss: 0.0180 - val_mape: 37.6429 - val_mse: 0.0180 - val_rmse: 0.1343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77c28356e980>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOWS_SIZE = 3\n",
    "\n",
    "# Obtenemos el nombre de archivo\n",
    "nombreArchivo = \"totalMerged_best_models.json\".split(\"_best_models.json\")[0]\n",
    "\n",
    "print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "# Cargamos archivos numpy\n",
    "data_train_global = np.load(f'RCPMergedTransferTotal/{nombreArchivo}_train_transfer.npz', allow_pickle=True)\n",
    "data_val_global = np.load(f'RCPMergedTransferTotal/{nombreArchivo}_val_transfer.npz', allow_pickle=True)\n",
    "\n",
    "X_train_transfer = data_train_global['X_train_transfer']\n",
    "y_train_transfer = data_train_global['y_train_transfer']\n",
    "X_val_transfer = data_val_global['X_val_transfer']\n",
    "y_val_transfer = data_val_global['y_val_transfer']\n",
    "valorNormalizacion = data_train_global[\"valorNormalizacion\"]\n",
    "\n",
    "with open(\"models/LSTMMerged_parallel/totalMerged_best_models.json\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "config = params[0]\n",
    "\n",
    "model = build_model_from_config((WINDOWS_SIZE + 1, X_train_transfer.shape[2]), config)\n",
    "\n",
    "\n",
    "model.fit(X_train_transfer, y_train_transfer, epochs=200, batch_size=config[\"batch_size\"],\n",
    "                validation_data=(X_val_transfer, y_val_transfer), callbacks=[EarlyStopping(monitor='val_loss', patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de506e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/LSTMMerged_parallel/totalMerged_best_models.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49082251",
   "metadata": {},
   "source": [
    "# Aplicamos transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acf7d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESANDO ARCHIVO: Cedrus deodara\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0178 - mape: 34.5342 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0173 - val_mape: 34.7953 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.2403 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0173 - val_mape: 34.6343 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.2241 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0173 - val_mape: 34.2759 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.0453 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.4408 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9771 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.5387 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9625 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.7787 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.0971 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.2148 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8185 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0172 - val_mape: 34.5020 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0153 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.3846 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0699 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0172 - val_mape: 34.5175 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0920 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0172 - val_mape: 34.4058 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8509 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0172 - val_mape: 34.6134 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8945 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0172 - val_mape: 34.6444 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9032 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.2025 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9358 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0172 - val_mape: 34.3485 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8667 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0172 - val_mape: 34.4436 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8324 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.2112 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7883 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.7168 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 33.0157 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.3559 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7255 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.1890 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9763 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.1186 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7113 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.6631 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9980 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.2509 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8168 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.0534 - val_mse: 0.0172 - val_rmse: 0.1312\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0189 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.4702 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6895 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.1706 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7347 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 34.5860 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8586 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.2715 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6992 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.3028 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8549 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1569 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7695 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1804 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8334 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2479 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8031 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.5255 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1716 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.1683 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7434 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0172 - val_mape: 33.9630 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8336 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.4482 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9571 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.1694 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8606 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2357 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7936 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2534 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8376 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.2983 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6470 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.5176 - val_mse: 0.0171 - val_rmse: 0.1310\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6838 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2748 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8226 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2429 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7414 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 33.9754 - val_mse: 0.0172 - val_rmse: 0.1311\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6423 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.2474 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8206 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0171 - val_mape: 34.3268 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6527 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0172 - val_mape: 34.1027 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6031 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0172 - val_mape: 33.9614 - val_mse: 0.0172 - val_rmse: 0.1310\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6722 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.2361 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7882 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0171 - val_mape: 34.5429 - val_mse: 0.0171 - val_rmse: 0.1309\n",
      "[MODELO CONGELADO]: 1599.7331244945526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016914617228706776, 0.13005620795912348, 0.650492219070725, 22.12599045286961\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017143818938504654, 0.130934407007878, 0.6486137029246042, 21.796490214293197\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01678556041950578, 0.1295591001030255, 0.6500120533686025, 21.834734805400245\n",
      "PROCESANDO ARCHIVO: Juniperus turkestanica Komar.\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6242 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 34.1867 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9503 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 34.2555 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1539 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0177 - val_mape: 33.7846 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1390 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 34.2402 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2337 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 34.0283 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0574 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 33.9921 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9725 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 34.1162 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0829 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.0080 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0419 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.2098 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9595 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 33.9929 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9529 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.2552 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1652 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.9434 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8708 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.8219 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8880 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.1308 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9427 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.0191 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0498 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.6259 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7839 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.1763 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9114 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.8964 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9236 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.1934 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9299 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.0151 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8965 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 33.8971 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8061 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.7675 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6959 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.6127 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8798 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.7391 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8441 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.2856 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.2212 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.1788 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8792 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.0663 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7508 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.9472 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8007 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.0913 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7991 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.7488 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8224 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 33.8598 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8124 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 33.7387 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7974 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.7820 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6895 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.9598 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8874 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.3193 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5641 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 33.9308 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6874 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.0628 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7194 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.8465 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6657 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.1909 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6399 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 33.8501 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9244 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 33.6351 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7258 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 33.7213 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6854 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.2785 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5915 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.2800 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8770 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.2738 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8751 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.2632 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7685 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 33.7589 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6314 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 33.9472 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7477 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 33.8790 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9531 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.2927 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7446 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.1117 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6350 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 34.1164 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7660 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.5394 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8857 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 33.9434 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "[MODELO CONGELADO]: 1519.2133312225342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016903583451950525, 0.13001378177697365, 0.6507202106816024, 22.07761206892731\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017538552460873325, 0.13243319999484013, 0.6394617684839412, 22.227044276840346\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017133718514219874, 0.13089583077478012, 0.6419916148629556, 22.138152841263214\n",
      "PROCESANDO ARCHIVO: Abies pindrow\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6932 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.0179 - val_mape: 36.3421 - val_mse: 0.0179 - val_rmse: 0.1339\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.3265 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0179 - val_mape: 36.3650 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.4972 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0179 - val_mape: 35.8798 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2157 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0179 - val_mape: 35.8862 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0902 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0179 - val_mape: 35.8367 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0292 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.8899 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0252 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.5952 - val_mse: 0.0179 - val_rmse: 0.1338\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9392 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0179 - val_mape: 35.8598 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0863 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.6989 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0363 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0179 - val_mape: 35.7753 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0227 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.3980 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9027 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0179 - val_mape: 35.7500 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7993 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.5192 - val_mse: 0.0179 - val_rmse: 0.1337\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1017 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.7173 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9722 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0179 - val_mape: 35.5569 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1144 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.9628 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9604 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.9359 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2543 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.7473 - val_mse: 0.0178 - val_rmse: 0.1336\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8617 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0179 - val_mape: 35.6015 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8814 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0179 - val_mape: 35.3697 - val_mse: 0.0179 - val_rmse: 0.1336\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9781 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.9146 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9484 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6519 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8362 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.7581 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8669 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.4876 - val_mse: 0.0178 - val_rmse: 0.1336\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0322 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0178 - val_mape: 35.5358 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9020 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.5788 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8823 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.5481 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9793 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.8841 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7553 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6543 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8026 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.4786 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7389 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.4744 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6526 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.8744 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7311 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.9810 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8220 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6447 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5182 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0178 - val_mape: 35.8486 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8930 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.6691 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6279 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 36.0478 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9083 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.7661 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8609 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 36.0298 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7548 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.5870 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7551 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.4436 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6829 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.8591 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8627 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.2560 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9390 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0178 - val_mape: 35.5321 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7897 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.6565 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5918 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0178 - val_mape: 35.8191 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5201 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0178 - val_mape: 35.8257 - val_mse: 0.0178 - val_rmse: 0.1334\n",
      "[MODELO CONGELADO]: 1322.6410949230194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.01691858368542362, 0.1300714560748192, 0.6504102599305026, 22.129848173292896\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017785736025253056, 0.13336317342224974, 0.6382292283561584, 22.506283863510568\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017354560498359577, 0.13173670900079285, 0.6376699919380304, 22.354758890790546\n",
      "PROCESANDO ARCHIVO: Abies spectabilis\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5916 - mse: 0.0178 - rmse: 0.1336 - val_loss: 0.0193 - val_mape: 38.9501 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0589 - mse: 0.0175 - rmse: 0.1324 - val_loss: 0.0193 - val_mape: 38.7952 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1921 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0193 - val_mape: 38.9518 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0264 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0193 - val_mape: 38.9528 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1406 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0193 - val_mape: 38.9670 - val_mse: 0.0193 - val_rmse: 0.1387\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0808 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.7983 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0138 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0192 - val_mape: 39.1565 - val_mse: 0.0192 - val_rmse: 0.1387\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0514 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.9351 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9836 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0193 - val_mape: 39.0825 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9709 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.9920 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9172 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0193 - val_mape: 38.9308 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1479 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0193 - val_mape: 38.8600 - val_mse: 0.0193 - val_rmse: 0.1389\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7978 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0193 - val_mape: 38.7724 - val_mse: 0.0193 - val_rmse: 0.1390\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8071 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0193 - val_mape: 39.0079 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9844 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0193 - val_mape: 39.0378 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8996 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0193 - val_mape: 39.0672 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9169 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0193 - val_mape: 39.0817 - val_mse: 0.0193 - val_rmse: 0.1388\n",
      "[MODELO CONGELADO]: 455.2026481628418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016993884460435916, 0.1303605939708619, 0.6488543153636852, 22.18013992924924\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.019265318890762516, 0.13879956372684504, 0.5966638271151625, 23.42511559569042\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01846884053320091, 0.13590011233696944, 0.6045903548700358, 23.183141966591915\n",
      "PROCESANDO ARCHIVO: Pinus roxburghii\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5387 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 35.5258 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1249 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 35.2775 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.8984 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 35.1325 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0925 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.5167 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9866 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.1939 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2026 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.2363 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9517 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.1582 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0313 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.9404 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8461 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.1715 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0332 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.1428 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0084 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.9880 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9505 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.1532 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8684 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.1377 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9763 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.0115 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9672 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7618 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6799 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0551 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8725 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.3054 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0205 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7414 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8810 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6287 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9434 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0233 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8709 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8031 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6532 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.2190 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9216 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7271 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9387 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7090 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5526 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1373 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6839 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1632 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9201 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0927 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7771 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0274 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8278 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1297 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9741 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.0156 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7806 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.1501 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7343 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.2388 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9352 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0708 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8829 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.9380 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9543 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7105 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8223 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.2632 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7834 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.0673 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7092 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0728 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7571 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.8655 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9728 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1238 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0483 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0205 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8424 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.0374 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6413 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.9285 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7324 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2243 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6605 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.1171 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7858 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.2328 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7311 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.1184 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8004 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.2856 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7515 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.2789 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8070 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.3652 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7010 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.9105 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7127 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.0376 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6800 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.1318 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6536 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 35.2033 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0264 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.3083 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6318 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.2281 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7549 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.7506 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6829 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.9559 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7612 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.9215 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "[MODELO CONGELADO]: 1667.684571504593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.01685834137484701, 0.1298396756575085, 0.6516550505162422, 22.035708922096713\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.01755635029145863, 0.13250037845779397, 0.6417591052267952, 22.133673383757216\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01701815099489567, 0.130453635422305, 0.6438408074659144, 21.974929158296494\n",
      "PROCESANDO ARCHIVO: Tsuga dumosa\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5521 - mse: 0.0178 - rmse: 0.1336 - val_loss: 0.0177 - val_mape: 35.7066 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.4783 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.6517 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1643 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.8491 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0574 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.4483 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0836 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.9439 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.8661 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.0246 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0071 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.6805 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7689 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.3326 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9431 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.4137 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0887 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.5038 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0249 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.4723 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8341 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.9669 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8081 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.4177 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8360 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.1321 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6453 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.5959 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9104 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.5332 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8269 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.4869 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8345 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.3875 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9416 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4310 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8571 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.4954 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6745 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2101 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8165 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3634 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7663 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.3899 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8646 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.2761 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7963 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3919 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7441 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.5897 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7000 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3910 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6988 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1815 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7985 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2963 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7628 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.8672 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9227 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1922 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8982 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2264 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6850 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1397 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9152 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2276 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7168 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.3682 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8516 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.4539 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8751 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3680 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5918 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.7809 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.1004 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.4462 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7822 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1570 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9397 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3769 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8315 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.2502 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8812 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.6861 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7526 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1531 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8088 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.3886 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7780 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1511 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8989 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.2242 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6111 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.3952 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7564 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.4565 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "[MODELO CONGELADO]: 1373.8717730045319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016909827116054998, 0.1300377911072585, 0.6505911974644236, 22.10411480579424\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017492963838544085, 0.13226096868896767, 0.6435026518961946, 22.097579441760633\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01718503114317932, 0.13109168983264852, 0.6412502820075581, 22.04795466399267\n",
      "PROCESANDO ARCHIVO: Betula utilis\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.4827 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 35.0890 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.3806 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 35.0034 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1512 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.8460 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0671 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.6023 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8790 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.7289 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2210 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.6418 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9292 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.4624 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1597 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.5526 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0178 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.2950 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0208 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.4409 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8942 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.4994 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8290 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.6948 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9066 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.7038 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8279 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.7384 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9050 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.3146 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8934 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.2935 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7503 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.2047 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0523 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.6564 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8635 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6307 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7500 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.4995 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8431 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4204 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7072 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5368 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7157 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.3902 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9618 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.5699 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8750 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4541 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7636 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5881 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7138 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.1601 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7850 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5116 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7994 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.2790 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6508 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.5048 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8479 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.4628 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8737 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.4323 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6142 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.2474 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8299 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5214 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7465 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8172 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9740 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.3133 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.4047 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.6470 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8399 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5826 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7259 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3850 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8540 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.3536 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7939 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.4664 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7217 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4923 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6678 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3781 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8978 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4090 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7753 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.6639 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7017 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.6977 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8118 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.7573 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6914 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.9664 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7300 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.6968 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5687 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.5045 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5419 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.5081 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5990 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.7587 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6203 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3411 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7068 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.6983 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9199 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.6413 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0172 - mape: 32.6422 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0176 - val_mape: 34.2514 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7350 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.7409 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "[MODELO CONGELADO]: 1642.3727021217346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016887320265138218, 0.12995122263810455, 0.6510562579155865, 22.09645862131307\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.01756690171108279, 0.13254018904122172, 0.639665064317, 22.186710892035645\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017175044958423813, 0.13105359574778486, 0.6401588357808768, 22.08443831022249\n",
      "PROCESANDO ARCHIVO: Juniperus spp. \n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6483 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0174 - val_mape: 35.2264 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0239 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0174 - val_mape: 35.0938 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1504 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 35.1035 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9602 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 34.8594 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0609 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 34.9919 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0605 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.8243 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9834 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 35.2656 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7970 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0173 - val_mape: 35.2715 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9987 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 35.0762 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9659 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0173 - val_mape: 34.8106 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9274 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.9094 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0051 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 35.1309 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8625 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.9090 - val_mse: 0.0173 - val_rmse: 0.1316\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8853 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.9519 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8446 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 35.2928 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0314 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0173 - val_mape: 35.0509 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9467 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 35.0167 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8820 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.7355 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8030 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.9981 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7835 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.7652 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7441 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.8050 - val_mse: 0.0173 - val_rmse: 0.1315\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6918 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.9128 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8842 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.7380 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8625 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 35.0025 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7595 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.9551 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8340 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.7957 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8913 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 35.0713 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8340 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 35.1828 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7735 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 35.0315 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6565 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.9432 - val_mse: 0.0172 - val_rmse: 0.1313\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9151 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0172 - val_mape: 34.9315 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9229 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.8361 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9995 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0173 - val_mape: 34.7483 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8112 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.9023 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6731 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.9418 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7743 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.6399 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6662 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.5337 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7428 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 34.6709 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0238 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0172 - val_mape: 34.6313 - val_mse: 0.0173 - val_rmse: 0.1313\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7133 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.5017 - val_mse: 0.0173 - val_rmse: 0.1314\n",
      "[MODELO CONGELADO]: 1140.792265176773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.01691023821280179, 0.13003937177947988, 0.6505827029469435, 22.046435165157654\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017278360285838443, 0.13144717678915147, 0.642673283240745, 22.046086974825403\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017028789038712903, 0.13049440232712245, 0.6454966414359029, 22.006075261929755\n",
      "PROCESANDO ARCHIVO: Pinus gerardiana\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0178 - mape: 34.5677 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0175 - val_mape: 35.6285 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2146 - mse: 0.0175 - rmse: 0.1325 - val_loss: 0.0175 - val_mape: 35.4142 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2358 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 35.3441 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1452 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 35.0780 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0457 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 34.9861 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9092 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 35.1404 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8299 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.5044 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1412 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.1967 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9847 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.0782 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8872 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 35.3276 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0193 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.2801 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9727 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.2969 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8046 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.0222 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1630 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.0550 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9856 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 34.9383 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8097 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.2038 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9690 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.0240 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9878 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.0419 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7172 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 34.8511 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9483 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.0912 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2515 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.9589 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1924 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.9776 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8164 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.0685 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0048 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1852 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8413 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1292 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8890 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.1992 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.5688 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.0600 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6719 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.0044 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9717 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.9679 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8884 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.9993 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0404 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.1035 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9962 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.9448 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8821 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.9844 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8788 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.8135 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6164 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.1262 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7885 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.9429 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9138 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.2227 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7845 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.9120 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5397 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.9685 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7634 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.8234 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.4907 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.3596 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7253 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.8258 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.6497 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 34.8731 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7623 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 34.7041 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7297 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.0634 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6924 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 34.9854 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6313 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.1694 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8234 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.3402 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9878 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.2574 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9167 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 34.8044 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9063 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.3595 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9453 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.1027 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8298 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 34.8356 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7179 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.3676 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7304 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 34.8319 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9837 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 34.8151 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8188 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.1853 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5862 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 34.8516 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6657 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.1610 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6168 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 35.0759 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8121 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.1408 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8279 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 35.1592 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0172 - mape: 32.6417 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0173 - val_mape: 35.2576 - val_mse: 0.0173 - val_rmse: 0.1317\n",
      "Epoch 64/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6727 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 35.1874 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "[MODELO CONGELADO]: 1851.6011171340942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016887336486660565, 0.12995128505197848, 0.651055922729268, 22.093254679037347\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.0173482749465146, 0.13171285034693692, 0.6462895363057009, 22.072991804432096\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017018700862121112, 0.13045574292502846, 0.6463210223271755, 22.01708059380188\n",
      "PROCESANDO ARCHIVO: Picea smithiana\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.4316 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0175 - val_mape: 35.8329 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1586 - mse: 0.0175 - rmse: 0.1325 - val_loss: 0.0175 - val_mape: 35.8541 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9645 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.8413 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0577 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.4464 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1383 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.7185 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0961 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.5418 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8576 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0175 - val_mape: 35.8136 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9435 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0175 - val_mape: 35.6309 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9042 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0175 - val_mape: 35.2946 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9717 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.8449 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2521 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 35.2388 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2211 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.7519 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1331 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.3995 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0855 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 35.5565 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8694 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.4787 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7653 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.2195 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8422 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.4367 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0903 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4267 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8750 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2740 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9065 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.4141 - val_mse: 0.0174 - val_rmse: 0.1321\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7943 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0795 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8744 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 35.5038 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0082 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.3586 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0717 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.5848 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7082 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1740 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9047 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.6152 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9674 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 35.3035 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.1006 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3026 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6135 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4739 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8195 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.4301 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6856 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2899 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8748 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5913 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8810 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.2978 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8026 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.3625 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6367 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.4932 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9048 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3090 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8332 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.6132 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7772 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4245 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6789 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1899 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7287 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5586 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6962 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4200 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9130 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.5338 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8178 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.1873 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7417 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3000 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0262 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.4410 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7521 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.5768 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8236 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4673 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8952 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.4798 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7040 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.6916 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8288 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.2388 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6427 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.6159 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7248 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 35.2653 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8514 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.6028 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9925 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.5565 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6706 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.3394 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6267 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 35.3570 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.4847 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5219 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9747 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.5856 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8856 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 35.7393 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5955 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.7014 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8317 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 35.3182 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "[MODELO CONGELADO]: 1719.2005228996277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016887899404470205, 0.12995345091404925, 0.6510442911237854, 22.067772640290002\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017398220531571747, 0.13190231435259864, 0.645359821912978, 22.105906038471073\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01691622672322895, 0.13006239550011736, 0.6486308378924728, 21.869697634934404\n",
      "PROCESANDO ARCHIVO: Juniperus spp. L.\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.4208 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0175 - val_mape: 32.6891 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1274 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0175 - val_mape: 32.1666 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2487 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0175 - val_mape: 32.2770 - val_mse: 0.0175 - val_rmse: 0.1322\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1243 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 32.1655 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9522 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0174 - val_mape: 32.4212 - val_mse: 0.0175 - val_rmse: 0.1320\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9673 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0174 - val_mape: 32.2642 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8404 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 32.1398 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9519 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 32.0795 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9065 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 32.0114 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.1424 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 31.7632 - val_mse: 0.0175 - val_rmse: 0.1321\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0519 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 31.9176 - val_mse: 0.0175 - val_rmse: 0.1320\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9365 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 32.1381 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1171 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 32.0257 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0052 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 31.7613 - val_mse: 0.0175 - val_rmse: 0.1320\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2778 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0174 - val_mape: 31.8634 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8440 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 31.9823 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8260 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.9061 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7829 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.6860 - val_mse: 0.0174 - val_rmse: 0.1320\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8308 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.8577 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8817 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0174 - val_mape: 31.9128 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7817 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 32.0284 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0068 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.1015 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7544 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.6536 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8244 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.8831 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9159 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.9121 - val_mse: 0.0174 - val_rmse: 0.1319\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8820 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0174 - val_mape: 31.9563 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7678 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.9071 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8847 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.0835 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9662 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.1366 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8517 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.7729 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0093 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.7766 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9402 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.8803 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9740 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 32.0326 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9316 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.7413 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7941 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.9203 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7822 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 31.7828 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8266 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.0311 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9696 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0174 - val_mape: 32.2329 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7602 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0173 - val_mape: 32.1057 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7619 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.6378 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9213 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 32.0594 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5796 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.8139 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6587 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.2102 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6112 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 32.1420 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9128 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 31.9844 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7582 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.9105 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.9345 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.7450 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8383 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.8431 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5515 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.9567 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6853 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0173 - val_mape: 32.1399 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5456 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 32.4481 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7567 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 31.9927 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6089 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 31.9174 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.6254 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 31.8626 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8801 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 31.7904 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7557 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.2390 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6246 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 31.8246 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5911 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.0081 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6301 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.9754 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5651 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0174 - val_mape: 31.8682 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5445 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 32.4287 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7220 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.0635 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7131 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0173 - val_mape: 32.0302 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 64/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7358 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0174 - val_mape: 31.5717 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "Epoch 65/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.3890 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0173 - val_mape: 32.2086 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 66/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0172 - mape: 32.5340 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0174 - val_mape: 32.0228 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 67/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5060 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0174 - val_mape: 32.2264 - val_mse: 0.0174 - val_rmse: 0.1317\n",
      "Epoch 68/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0172 - mape: 32.6805 - mse: 0.0172 - rmse: 0.1313 - val_loss: 0.0174 - val_mape: 31.9437 - val_mse: 0.0174 - val_rmse: 0.1318\n",
      "[MODELO CONGELADO]: 1988.6928911209106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016881936566755195, 0.1299305066824385, 0.6511675016079268, 22.06579775633096\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.01736412631321402, 0.13177301056443244, 0.6442067211998354, 22.071339818036677\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017037869412404847, 0.13052918988641907, 0.644167645735031, 22.01135104099524\n",
      "PROCESANDO ARCHIVO: Populus ciliata\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.5281 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0177 - val_mape: 35.3323 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0680 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0176 - val_mape: 35.2823 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9881 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.0470 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2900 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.2042 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0626 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.1381 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.2126 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.1017 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0206 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 34.9703 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2842 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.0603 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9014 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.7059 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9314 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.2316 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1686 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 34.9650 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8424 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.2685 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1553 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.1232 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0777 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.9731 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7813 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.9427 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.7972 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.0167 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 33.0820 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.9135 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7962 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7613 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1616 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.8255 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7902 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7080 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8499 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2698 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8317 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.7482 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9568 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.8973 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9022 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7786 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8145 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6701 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9920 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 35.0424 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9318 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.9572 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7346 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.7612 - val_mse: 0.0176 - val_rmse: 0.1324\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6659 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0297 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8708 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1029 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6703 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.7414 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9287 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.2426 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5589 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.0116 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7620 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.8191 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7474 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1891 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6180 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0554 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8394 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 34.9110 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7665 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.0823 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9828 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9229 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7472 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0042 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7260 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9313 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8566 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1794 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7819 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9281 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8292 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1944 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9543 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0175 - val_mape: 34.8084 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7092 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.0769 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.5788 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9073 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6562 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2603 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9161 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.0293 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5242 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9320 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9822 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9727 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8251 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.6751 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5720 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.2576 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7845 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.1284 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7831 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 34.9440 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6619 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 34.7035 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6840 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.0963 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7695 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.0076 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6011 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9899 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.7192 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 34.9603 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7381 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1256 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6969 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 34.9880 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 63/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6437 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.1527 - val_mse: 0.0175 - val_rmse: 0.1323\n",
      "[MODELO CONGELADO]: 1817.758069038391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.01686217535702744, 0.12985443911175096, 0.6515758287055512, 22.075490647529797\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017504282741689317, 0.13230375180503884, 0.6413887103115661, 22.168257649502987\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017131089660988624, 0.13088578861354133, 0.6419146535058772, 22.101512608542972\n",
      "PROCESANDO ARCHIVO: Juniperus recurva\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - loss: 0.0179 - mape: 34.3236 - mse: 0.0179 - rmse: 0.1336 - val_loss: 0.0177 - val_mape: 35.7407 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0405 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 35.5683 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2416 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 35.6465 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.0698 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.4640 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0169 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0176 - val_mape: 35.7547 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1881 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0176 - val_mape: 35.7493 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9608 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.2856 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9262 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.0783 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8521 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.3644 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9793 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.9069 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7966 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.3030 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7140 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1368 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8363 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.5197 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8844 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0176 - val_mape: 35.3461 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9861 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.0531 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9787 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.3697 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7147 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.0987 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9281 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.2159 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8476 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1835 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9829 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 35.4738 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6832 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.8456 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6186 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.2427 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7934 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8908 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7561 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1674 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7416 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.0835 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.6405 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.1629 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8824 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.1255 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7468 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 35.2090 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8269 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1863 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8230 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.3123 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0013 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.8803 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7913 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.1153 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7483 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.2290 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7482 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.2022 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6591 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.2528 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8479 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.6688 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7842 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.2618 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7352 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.2696 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6551 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.4128 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8246 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.1043 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7248 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0175 - val_mape: 35.3671 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5906 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.1894 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6152 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.4666 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7779 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.2005 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7720 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.3625 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7085 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.2512 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9327 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.1549 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6504 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.6125 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8011 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.3519 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7502 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.3781 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7250 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.4547 - val_mse: 0.0175 - val_rmse: 0.1325\n",
      "Epoch 52/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8195 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0175 - val_mape: 35.5846 - val_mse: 0.0175 - val_rmse: 0.1324\n",
      "Epoch 53/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5452 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.2829 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 54/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7674 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.3373 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 55/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7798 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.2343 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 56/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8395 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0175 - val_mape: 35.3552 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 57/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5552 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.2892 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 58/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5140 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0175 - val_mape: 35.3984 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 59/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5242 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.2511 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 60/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6212 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 35.3077 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 61/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.4719 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.5586 - val_mse: 0.0176 - val_rmse: 0.1325\n",
      "Epoch 62/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7356 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 35.0356 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "[MODELO CONGELADO]: 1769.1250414848328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.01687563051463046, 0.12990623739694127, 0.651297803952623, 22.04150188127271\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017573155540844224, 0.13256377914364173, 0.6406665403134971, 22.24877281603308\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.017268761591148898, 0.13141066011229416, 0.6390128011359555, 22.250760316534826\n",
      "PROCESANDO ARCHIVO: Pinus wallichiana\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.7336 - mse: 0.0178 - rmse: 0.1335 - val_loss: 0.0178 - val_mape: 36.0513 - val_mse: 0.0178 - val_rmse: 0.1335\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1640 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0178 - val_mape: 36.2629 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.1722 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0178 - val_mape: 35.9330 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9342 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0178 - val_mape: 36.2039 - val_mse: 0.0178 - val_rmse: 0.1332\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0175 - mape: 33.0670 - mse: 0.0175 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 36.0576 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9621 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 35.9905 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8439 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 36.0311 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1407 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.8249 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0762 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 36.0665 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0355 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.9035 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9396 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 35.7621 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8322 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 35.9459 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.9389 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.8545 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1660 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.5794 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0566 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.6117 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8163 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.7420 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8097 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.9185 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8538 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.6543 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8663 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.4678 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8756 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.9801 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0173 - mape: 32.8770 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.7939 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.8224 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.8016 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7785 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.8861 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8133 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.8778 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7570 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0177 - val_mape: 35.8310 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7215 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.4151 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7344 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.7578 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - loss: 0.0174 - mape: 32.5997 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.7167 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8237 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.8103 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6388 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 35.7324 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9562 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.9901 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7571 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.6678 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8139 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0177 - val_mape: 35.6208 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6305 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.7272 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6093 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.9151 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6135 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.8404 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7648 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0177 - val_mape: 35.3893 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0446 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 35.6807 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7326 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 35.9411 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5707 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.7366 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6384 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 35.8654 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "[MODELO CONGELADO]: 1188.0668478012085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016930416457707695, 0.13011693378537512, 0.6501657586256651, 22.126174378140096\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.01764890188301877, 0.13284916967380253, 0.6403126062757806, 22.350724619255413\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01717936122959644, 0.1310700622934026, 0.6399095138509182, 22.2219353198516\n",
      "PROCESANDO ARCHIVO: Juniperus excelsa M.-Bieb\n",
      "<LSTM name=lstm_15, built=True> False\n",
      "<LSTM name=lstm_16, built=True> False\n",
      "<Dropout name=dropout_7, built=True> True\n",
      "<LSTM name=lstm_17, built=True> False\n",
      "<LSTM name=lstm_18, built=True> True\n",
      "<Dense name=dense_6, built=True> True\n",
      "<Dropout name=dropout_8, built=True> True\n",
      "<Dense name=dense_7, built=True> True\n",
      "Epoch 1/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.0178 - mape: 34.6165 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.0178 - val_mape: 34.9667 - val_mse: 0.0178 - val_rmse: 0.1333\n",
      "Epoch 2/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0176 - mape: 33.1570 - mse: 0.0176 - rmse: 0.1325 - val_loss: 0.0177 - val_mape: 34.7402 - val_mse: 0.0177 - val_rmse: 0.1332\n",
      "Epoch 3/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0175 - mape: 33.2410 - mse: 0.0175 - rmse: 0.1323 - val_loss: 0.0177 - val_mape: 34.8352 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 4/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.3097 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.7507 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 5/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1443 - mse: 0.0174 - rmse: 0.1321 - val_loss: 0.0177 - val_mape: 34.8942 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 6/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0758 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.6145 - val_mse: 0.0177 - val_rmse: 0.1331\n",
      "Epoch 7/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0175 - mape: 32.9111 - mse: 0.0175 - rmse: 0.1322 - val_loss: 0.0177 - val_mape: 34.9185 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 8/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8549 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.8349 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 9/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7542 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.6193 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 10/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9458 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.5380 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 11/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8556 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.9028 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 12/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0272 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.7416 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 13/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0690 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0177 - val_mape: 34.6682 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 14/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.1627 - mse: 0.0174 - rmse: 0.1320 - val_loss: 0.0177 - val_mape: 34.4832 - val_mse: 0.0177 - val_rmse: 0.1330\n",
      "Epoch 15/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8970 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 35.0231 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 16/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9308 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.7886 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 17/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9098 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 34.5804 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 18/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9137 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.9587 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 19/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8864 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0177 - val_mape: 34.4668 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 20/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7940 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6121 - val_mse: 0.0177 - val_rmse: 0.1328\n",
      "Epoch 21/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0538 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7356 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 22/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 33.0253 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5948 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 23/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.7804 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0177 - val_mape: 34.1232 - val_mse: 0.0177 - val_rmse: 0.1329\n",
      "Epoch 24/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8464 - mse: 0.0174 - rmse: 0.1319 - val_loss: 0.0176 - val_mape: 34.3701 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 25/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.9893 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.6209 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 26/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8160 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.5037 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 27/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8901 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7261 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 28/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5699 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6691 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 29/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8465 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.7510 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 30/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0174 - mape: 33.0218 - mse: 0.0174 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.4543 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 31/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7414 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5168 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 32/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6637 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7910 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 33/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6768 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.3808 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 34/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5858 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.3989 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 35/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9072 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7382 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 36/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8752 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7006 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 37/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.9172 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.7262 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 38/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8340 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.6420 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 39/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8143 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.5517 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 40/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7834 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.7068 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 41/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6206 - mse: 0.0173 - rmse: 0.1316 - val_loss: 0.0176 - val_mape: 34.8476 - val_mse: 0.0176 - val_rmse: 0.1326\n",
      "Epoch 42/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.6606 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.6549 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 43/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0174 - mape: 32.8393 - mse: 0.0174 - rmse: 0.1318 - val_loss: 0.0176 - val_mape: 34.5306 - val_mse: 0.0176 - val_rmse: 0.1328\n",
      "Epoch 44/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7247 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7729 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 45/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7280 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.3640 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 46/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8579 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.7171 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 47/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7837 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7730 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 48/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7541 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7903 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 49/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.8908 - mse: 0.0173 - rmse: 0.1317 - val_loss: 0.0176 - val_mape: 34.7526 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 50/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.5943 - mse: 0.0173 - rmse: 0.1314 - val_loss: 0.0176 - val_mape: 34.3132 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "Epoch 51/200\n",
      "\u001b[1m5355/5355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.0173 - mape: 32.7248 - mse: 0.0173 - rmse: 0.1315 - val_loss: 0.0176 - val_mape: 34.8929 - val_mse: 0.0176 - val_rmse: 0.1327\n",
      "[MODELO CONGELADO]: 1456.2003922462463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 0.016897695305639737, 0.12999113548869298, 0.6508418778126432, 22.115984367853013\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 0.017597400446943974, 0.13265519381819912, 0.6388550455845334, 22.162110143292225\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 0.01716419099332396, 0.13101217879771315, 0.639301031953541, 22.09023833840815\n"
     ]
    }
   ],
   "source": [
    "# Creamos un df que contiene los resultados de los modelos freeze de cada especie\n",
    "df_Freeze = pd.DataFrame(columns = [\"File\", \"Time\", \"TrainMSE\", \"TrainRMSE\", \"TrainR2\", \"TrainMAPE\", \n",
    "                                    \"ValidationMSE\", \"ValidationRMSE\", \"ValidationR2\", \"ValidationMAPE\",\n",
    "                                    \"TestMSE\", \"TestRMSE\", \"TestR2\", \"TestMAPE\"])\n",
    "\n",
    "for archivo in os.listdir(\"RCPMergedTransfer\"):\n",
    "    if \"train\" in archivo: \n",
    "        \n",
    "        nombreArchivo = archivo.split(\"_train\")[0]\n",
    "        print(f\"PROCESANDO ARCHIVO: {nombreArchivo}\")\n",
    "\n",
    "        # Cargar datos\n",
    "        data_transfer_train = np.load(f'RCPMergedTransferTotal/totalMerged_train_transfer.npz', allow_pickle=True)\n",
    "        data_transfer_val = np.load(f'RCPMergedTransfer/{nombreArchivo}_val.npz', allow_pickle=True)\n",
    "        data_transfer_test = np.load(f'RCPMergedTransfer/{nombreArchivo}_test.npz', allow_pickle=True)\n",
    "        \n",
    "        # Aqui tenemos que usar TRAIN original para aplicar transfer \n",
    "        X_train_transfer = data_transfer_train[\"X_train_transfer\"]\n",
    "        y_train_transfer = data_transfer_train[\"y_train_transfer\"]\n",
    "\n",
    "        # Aqui tenemos que usar VAL original para aplicar transfer \n",
    "        X_val_transfer = data_transfer_val[\"X_val\"]\n",
    "        y_val_transfer = data_transfer_val[\"y_val\"]\n",
    "        \n",
    "        # Este test es para ver la capacidad del modelo\n",
    "        X_test_transfer = data_transfer_test[\"X_test\"]\n",
    "        y_test_transfer = data_transfer_test[\"y_test\"]\n",
    "        \n",
    "        # Cargamos el conjunto de datos de val original para hacer el transfer\n",
    "        model = tf.keras.models.load_model('models/LSTMMerged_parallel/totalMerged_best_models.keras')\n",
    "        modelFreeze = model\n",
    "        \n",
    "        # Cargamos el json para obtener el batch_size\n",
    "        with open(\"models/LSTMMerged_parallel/totalMerged_best_models.json\") as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        config = params[0]\n",
    "\n",
    "        # Obtener el optimizador del modelo\n",
    "        optimizer = modelFreeze.optimizer\n",
    "\n",
    "        # Obtenemos el batch\n",
    "        batch_size_LSTM = config[\"batch_size\"]\n",
    "\n",
    "        # Indicamos el numero de layers a entrenar\n",
    "        NUM_TRAINABLE = 1\n",
    "\n",
    "        numLSTM_layers = sum(1 for layer in modelFreeze.layers if \"lstm\" in layer.name)\n",
    "\n",
    "        numFreezeLayers = numLSTM_layers - NUM_TRAINABLE # Congelamos todas menos la útlima capa\n",
    "\n",
    "        numberLayersFreezed = 0\n",
    "\n",
    "        # Congelar las primeras 'numFreezeLayers' capas LSTM\n",
    "        for i, layer in enumerate(modelFreeze.layers):\n",
    "\n",
    "            if \"lstm\" in layer.name and numFreezeLayers>numberLayersFreezed:\n",
    "                numberLayersFreezed += 1\n",
    "                layer.trainable = False\n",
    "\n",
    "            print(layer, layer.trainable)\n",
    "\n",
    "        # Compilamos el modelo con los nuevos datos\n",
    "        modelFreeze.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[\n",
    "                                    MeanSquaredError(name='mse'),\n",
    "                                    RootMeanSquaredError(name='rmse'),\n",
    "                                    MeanAbsolutePercentageError(name='mape')\n",
    "                                ])\n",
    "\n",
    "        # Comienza a medir el tiempo de entrenamiento\n",
    "        start_time = time.time()\n",
    "\n",
    "        historyLSTMTransfer = modelFreeze.fit(X_train_transfer, y_train_transfer, epochs=200, batch_size=batch_size_LSTM,\n",
    "                                validation_data=(X_val_transfer, y_val_transfer), callbacks=[EarlyStopping(monitor='val_loss', patience=10)])\n",
    "        \n",
    "        # Finaliza la medición del tiempo de entrenamiento\n",
    "        end_time = time.time()\n",
    "        print(f\"[MODELO CONGELADO]: {end_time-start_time}\")\n",
    "\n",
    "        # Guardamos el modelo\n",
    "        modelFreeze.save(f\"models/LSTMMerged_parallel/{nombreArchivo}.keras\")\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de entrenamiento\n",
    "        predictions_train = predictionForIndividuals(X_train_transfer, y_train_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"],predictions_train[\"PredictionsDenormalize\"])\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        train_mape = (np.sum(np.abs(predictions_train[\"PredictionsDenormalize\"] - predictions_train[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_train[\"ActualDenormalize\"]))) * 100\n",
    "        train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de validación\n",
    "        predictions_val = predictionForIndividuals(X_val_transfer, y_val_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"],predictions_val[\"PredictionsDenormalize\"])\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_mape = (np.sum(np.abs(predictions_val[\"PredictionsDenormalize\"] - predictions_val[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_val[\"ActualDenormalize\"]))) * 100\n",
    "        val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de prueba\n",
    "        predictions_test = predictionForIndividuals(X_test_transfer, y_test_transfer, modelFreeze, batch_size_LSTM)\n",
    "        predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"],predictions_test[\"PredictionsDenormalize\"])\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mape = (np.sum(np.abs(predictions_test[\"PredictionsDenormalize\"] - predictions_test[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_test[\"ActualDenormalize\"]))) * 100\n",
    "        test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "        # Guardamos los datos calculados\n",
    "        df_Freeze.loc[len(df_Freeze)] = [nombreArchivo, end_time-start_time,train_mse, train_rmse, train_r2, train_mape, val_mse, val_rmse, val_r2, val_mape, test_mse, test_rmse, test_r2, test_mape]\n",
    "\n",
    "df_Freeze.to_csv(\"resultsTransferOption3/resultados_Option3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
