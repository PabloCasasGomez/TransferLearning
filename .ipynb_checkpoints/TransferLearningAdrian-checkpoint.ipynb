{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 12:51:25.645984: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 12:51:25.708758: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 12:51:25.878510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 12:51:25.957831: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 12:51:25.979967: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 12:51:26.215627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 12:51:27.449533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import os\n",
    "import json\n",
    "\n",
    "import random as python_random\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras import layers, models\n",
    "\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "from funcionesComunes import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasnfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los diferentes modelos\n",
    "for model in os.listdir(\"models/LSTM\"):\n",
    "\n",
    "    # Creamos un df que contiene los resultados de los modelos freeze de cada especie\n",
    "    df_Freeze = pd.DataFrame(columns = [\"File\", \"Time\", \"TrainMSE\", \"TrainRMSE\", \"TrainR2\", \"TrainMAPE\", \n",
    "                                        \"ValidationMSE\", \"ValidationRMSE\", \"ValidationR2\", \"ValidationMAPE\",\n",
    "                                        \"TestMSE\", \"TestRMSE\", \"TestR2\", \"TestMAPE\"])\n",
    "\n",
    "\n",
    "    if model != \"model_Abies_spectabilis.keras\":\n",
    "        print(f'Procesando el modelo: {model}')\n",
    "\n",
    "        # Para cada archivo \n",
    "        for archivo in os.listdir(\"RCPMerged\"):\n",
    "\n",
    "            # Comprobamos que el modelo no sea del archivo a procesar\n",
    "            archivoProcesar = archivo.split(\"_merged\")[0]\n",
    "            modeloProcesar = model.split(\"model_\")[1].split(\".keras\")[0]\n",
    "            print(archivoProcesar, modeloProcesar)\n",
    "\n",
    "            # Lanzamos la ejecución siempre que no sea el mismo archivo o el global\n",
    "            if archivoProcesar != modeloProcesar and archivo != \"totalMerged.csv\":\n",
    "\n",
    "                # Cargar el archivo CSV con punto y coma como delimitador\n",
    "                df = pd.read_csv(f'RCPMerged/{archivo}')\n",
    "                df = df[~df[\"nametag\"].str.startswith(\"INDI005\")]\n",
    "\n",
    "                # Codificamos, normalización y split de datos\n",
    "                df = codification(df)\n",
    "                print(df.shape)\n",
    "\n",
    "                df, valorNormalizacion = individualNormalization(df)\n",
    "                print(f\"SE HA NORMALIZADO EL ARCHIVO: {archivo}\")\n",
    "\n",
    "                temp_df = df\n",
    "                train_data, val_data, test_data = split_population_individuals(temp_df, train_pct=0.80, val_pct_in_train=0.20, details=False)\n",
    "                train_data.shape, val_data.shape, test_data.shape\n",
    "\n",
    "                # Obtenemos X e y para los datasets de train, val y test \n",
    "                WINDOWS_SIZE = 3\n",
    "                X_train, y_train = df_to_X_y_ind_3(train_data, WINDOWS_SIZE)\n",
    "                X_val, y_val = df_to_X_y_ind_3(val_data, WINDOWS_SIZE)\n",
    "                X_test, y_test = df_to_X_y_ind_3(test_data, WINDOWS_SIZE)\n",
    "                print(X_train.shape, X_test.shape, X_val.shape)\n",
    "\n",
    "                # Cargamos el modelo global\n",
    "                modelLSTM = tf.keras.models.load_model(f'models/LSTM/{model}')\n",
    "                modelLSTMFreeze = modelLSTM\n",
    "\n",
    "                # Obtener el optimizador del modelo\n",
    "                optimizer = modelLSTMFreeze.optimizer\n",
    "\n",
    "                # Obtenemos el valor de batch size\n",
    "                with open(f'arquitecturaModelosJSON/LSTM/{archivo.split(\".csv\")[0]}_best_models_updated_no_train.json') as f:\n",
    "                    parameters = json.load(f)\n",
    "\n",
    "                batch_size_LSTM = parameters[0][\"batch_size\"]\n",
    "\n",
    "                # Indicamos el numero de layers a entrenar\n",
    "                NUM_TRAINABLE = 1\n",
    "\n",
    "                numLSTM_layers = sum(1 for layer in modelLSTMFreeze.layers if \"lstm\" in layer.name)\n",
    "\n",
    "                numFreezeLayers = numLSTM_layers - NUM_TRAINABLE # Congelamos todas menos la útlima capa\n",
    "\n",
    "                numberLayersFreezed = 0\n",
    "\n",
    "                # Congelar las primeras 'numFreezeLayers' capas LSTM\n",
    "                for i, layer in enumerate(modelLSTMFreeze.layers):\n",
    "\n",
    "                    if \"lstm\" in layer.name and numFreezeLayers>numberLayersFreezed:\n",
    "                        numberLayersFreezed += 1\n",
    "                        layer.trainable = False\n",
    "\n",
    "                    print(layer, layer.trainable)\n",
    "\n",
    "                # Compilamos el modelo con los nuevos datos\n",
    "                modelLSTMFreeze.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[\n",
    "                                            MeanSquaredError(name='mse'),\n",
    "                                            RootMeanSquaredError(name='rmse'),\n",
    "                                            MeanAbsolutePercentageError(name='mape')\n",
    "                                        ])\n",
    "\n",
    "                # Comienza a medir el tiempo de entrenamiento\n",
    "                start_time = time.time()\n",
    "\n",
    "                historyLSTMTransfer = modelLSTMFreeze.fit(X_train, y_train, epochs=200, batch_size=batch_size_LSTM,\n",
    "                                        validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss', patience=10)], verbose=0)\n",
    "\n",
    "                # Finaliza la medición del tiempo de entrenamiento\n",
    "                end_time = time.time()\n",
    "                print(f\"[MODELO CONGELADO]: {end_time-start_time}\")\n",
    "\n",
    "                # Realizar predicciones y calcular métricas para el conjunto de entrenamiento\n",
    "                predictions_train = predictionForIndividuals(X_train, y_train, modelLSTMFreeze, batch_size_LSTM)\n",
    "                predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "                predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "                train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"],predictions_train[\"PredictionsDenormalize\"])\n",
    "                train_rmse = np.sqrt(train_mse)\n",
    "                train_mape = (np.sum(np.abs(predictions_train[\"PredictionsDenormalize\"] - predictions_train[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_train[\"ActualDenormalize\"]))) * 100\n",
    "                train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "                # Realizar predicciones y calcular métricas para el conjunto de validación\n",
    "                predictions_val = predictionForIndividuals(X_val, y_val, modelLSTMFreeze, batch_size_LSTM)\n",
    "                predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "                predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "                val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"],predictions_val[\"PredictionsDenormalize\"])\n",
    "                val_rmse = np.sqrt(val_mse)\n",
    "                val_mape = (np.sum(np.abs(predictions_val[\"PredictionsDenormalize\"] - predictions_val[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_val[\"ActualDenormalize\"]))) * 100\n",
    "                val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "                # Realizar predicciones y calcular métricas para el conjunto de prueba\n",
    "                predictions_test = predictionForIndividuals(X_test, y_test, modelLSTMFreeze, batch_size_LSTM)\n",
    "                predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "                predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "                test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"],predictions_test[\"PredictionsDenormalize\"])\n",
    "                test_rmse = np.sqrt(test_mse)\n",
    "                test_mape = (np.sum(np.abs(predictions_test[\"PredictionsDenormalize\"] - predictions_test[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_test[\"ActualDenormalize\"]))) * 100\n",
    "                test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "                print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "                print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "                print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "                # Guardamos los datos calculados\n",
    "                df_Freeze.loc[len(df_Freeze)] = [archivo, end_time-start_time,train_mse, train_rmse, train_r2, train_mape, val_mse, val_rmse, val_r2, val_mape, test_mse, test_rmse, test_r2, test_mape]\n",
    "\n",
    "    df_Freeze.to_csv(f'resultadosTransfer_{model.split(\"model_\")[1].split(\".keras\")[0]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento desde 0 de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el modelo LSTM basado en los parámetros del JSON\n",
    "def create_lstm_model(params, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Añadir capas LSTM\n",
    "    for i in range(params['num_lstm_layers']):\n",
    "        if i == 0:\n",
    "            # Primera capa LSTM necesita el input_shape\n",
    "            model.add(tf.keras.layers.LSTM(units=params[f'units_lstm_{i}'],\n",
    "                                           return_sequences=True,\n",
    "                                           use_bias = True, \n",
    "                                           input_shape=input_shape))\n",
    "        else:\n",
    "            # Capas posteriores\n",
    "            model.add(tf.keras.layers.LSTM(units=params[f'units_lstm_{i}'], \n",
    "                                           use_bias = True,\n",
    "                                           return_sequences=True))\n",
    "\n",
    "    # CAPA DROPOUT\n",
    "    model.add(Dropout(params[\"dropout\"]))\n",
    "\n",
    "    # Añadir las capas LSTM adicionales (si existen)\n",
    "    for i in range(params['num_lstm_layers_after']):\n",
    "        model.add(tf.keras.layers.LSTM(units=params[f'units_lstm_after_{i}'], \n",
    "                                       use_bias = True,\n",
    "                                       return_sequences=(i < params['num_lstm_layers_after'] - 1)))\n",
    "\n",
    "    # Añadir capa densa\n",
    "    model.add(tf.keras.layers.Dense(units=params['dense_units'], activation=params['dense_activation'], use_bias = True))\n",
    "\n",
    "    # DROPOUT 2\n",
    "    model.add(Dropout(params[\"dropout_2\"]))\n",
    "\n",
    "    # Añadir la capa de salida (una sola unidad de salida)\n",
    "    model.add(tf.keras.layers.Dense(1, activation=params[\"dense_activation\"], use_bias = True))\n",
    "\n",
    "    # Compilar el modelo según el optimizador especificado en los parámetros\n",
    "    learning_rate = params['learning_rate']\n",
    "    optimizer_name = params['optimizer']\n",
    "\n",
    "    if optimizer_name == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer {optimizer_name} not recognized\")\n",
    "\n",
    "    # Compilamos el modelo\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',  # Asumo que quieres minimizar el MSE\n",
    "                  metrics=['mse', 'mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34476, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Picea smithiana merged.csv\n",
      "(19933, 4, 43) (7272, 4, 43) (5863, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 576.243658542633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 171.35650608905578, 13.090321084261294, 0.49782712259134665, 37.79580734658723\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 186.241596963849, 13.647036197059382, 0.4625561654478877, 39.92407381916745\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 203.87084700933804, 14.278334882238125, 0.3115369007042479, 43.19865538799758\n",
      "(16018, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Abies pindrow merged.csv\n",
      "(9042, 4, 43) (3441, 4, 43) (2815, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 226.3893609046936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 174.9178956076841, 13.225652936913326, 0.2491965093517563, 44.430568099919974\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 153.26960167737204, 12.380210082117832, 0.1256753664008613, 40.72868331199774\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 295.90314407053324, 17.20183548550948, -1.0919516143090129, 51.13291186131542\n",
      "(7449, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus excelsa M.-Bieb merged.csv\n",
      "(4189, 4, 43) (1707, 4, 43) (1228, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 73.0703227519989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 17.669238243990634, 4.2034793021960555, 0.28178075634869104, 46.07955751601084\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 19.291555137805286, 4.392215288189467, 0.2642924960360509, 50.63104232696824\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 75.12913465026521, 8.667706423862382, -0.11385185293023725, 66.5711385083088\n",
      "(6305, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus turkestanica Komar. merged.csv\n",
      "(3664, 4, 43) (1368, 4, 43) (1001, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 95.84277200698853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 8.183904468569413, 2.8607524304926164, 0.817676718395278, 27.923413534980746\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 6.952433082884572, 2.6367466853842014, 0.5956971781549277, 35.72901647707773\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 2.998765129730553, 1.7316942945365827, 0.4483109737188521, 33.05222052318821\n",
      "(10635, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus roxburghii merged.csv\n",
      "(6309, 4, 43) (2167, 4, 43) (1647, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 64.67873430252075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 184.77641292644756, 13.593248799549267, 0.30726675347998755, 43.89959138246116\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 159.38235107614057, 12.624672315594594, 0.2884981258774989, 45.59964761497086\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 168.16164394334055, 12.96771544811732, 0.2943586031278257, 45.07524276965995\n",
      "(9365, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus wallichiana merged.csv\n",
      "(5508, 4, 43) (1957, 4, 43) (1500, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 117.10288763046265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 23.88511283209151, 4.8872397968681165, 0.645683412274819, 28.24645782709006\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 29.743652442199707, 5.453774146607073, 0.5024759512511255, 33.36518162483442\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 38.956364436469, 6.241503379512744, 0.07606736702023309, 40.83397530763276\n",
      "(10101, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Pinus gerardiana merged.csv\n",
      "(5767, 4, 43) (2181, 4, 43) (1745, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 93.55375266075134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 12.968559077267479, 3.601188564525257, 0.6659062521081816, 28.34312358158072\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 18.294157447345956, 4.277166988480337, 0.5376758558890424, 33.047655645727616\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 15.900546270668638, 3.9875489051130946, 0.6042222967922775, 31.949995271618842\n",
      "(1182, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Populus ciliata merged.csv\n",
      "(705, 4, 43) (156, 4, 43) (265, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 71.95125031471252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 181.39042676226723, 13.468126327083038, 0.5005671660991107, 36.518049329336556\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 204.46283827286928, 14.299050257722339, 0.1288258472054905, 44.6090142110594\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 81.00120553666918, 9.000066974010203, 0.5952567659966514, 31.848031861572263\n",
      "(3473, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Betula utilis merged.csv\n",
      "(2059, 4, 43) (665, 4, 43) (593, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 23.186583280563354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 3.7527241807667755, 1.9371949258571723, 0.44600300872176213, 47.890538368824814\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 1.6447854860635096, 1.2824919048725063, 0.14345125923894775, 45.566121917170015\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 1.5628139307792177, 1.2501255660049584, 0.4027711365691067, 46.27843115130922\n",
      "(20493, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Tsuga dumosa merged.csv\n",
      "(11935, 4, 43) (4144, 4, 43) (3469, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 298.64744806289673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 255.14040114103338, 15.973114947969083, 0.34485276202126014, 45.17569716835284\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 210.03758020080787, 14.492673328299643, 0.33347638026739046, 41.279456563624585\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 377.5528719356513, 19.43071979973082, 0.38373524469335174, 46.07046550014789\n",
      "(37273, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Cedrus deodara merged.csv\n",
      "(22017, 4, 43) (7410, 4, 43) (6282, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 2512.251734495163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 183.02485779206756, 13.528667997702788, 0.5715006762944945, 38.28249048613594\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 237.64851660148022, 15.415852769194451, 0.4673232583108976, 40.72177911389589\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 156.29432925223992, 12.501773044342148, 0.5565211525394063, 37.471294974276624\n",
      "(7264, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus spp. L. merged.csv\n",
      "(4216, 4, 43) (1524, 4, 43) (1188, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 150.6079878807068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 4.648975639655266, 2.1561483343349237, 0.6290903505328437, 39.71466939207775\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 1.5261438087796229, 1.2353719313549352, 0.3228143285134779, 42.80357229760276\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 13.420136850135593, 3.6633504951254108, 0.2920798992780137, 53.54400975401785\n",
      "(5316, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus recurva merged.csv\n",
      "(3188, 4, 43) (1082, 4, 43) (810, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 103.51394319534302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 8.45629687955978, 2.9079712652568936, 0.6639780302158466, 33.234290301671074\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 7.599576065682429, 2.756732860776036, 0.7240486286010984, 29.749938258111857\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 3.0112565297438, 1.7352972453570599, 0.6798665459140527, 27.580481593978817\n",
      "(17976, 77)\n",
      "SE HA NORMALIZADO EL ARCHIVO: Juniperus spp.  merged.csv\n",
      "(10218, 4, 43) (3900, 4, 43) (3018, 4, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODELO CONGELADO]: 258.2245650291443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n",
      "/home/workstation/Escritorio/PabloC/TransferLearning/funcionesComunes.py:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  predictionsDF = pd.concat([predictionsDF, tempDF], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Train): 20.157254829637722, 4.489683154704541, 0.6712489846085818, 35.417586445858724\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Val): 8.608813333573943, 2.934077935838437, 0.5623988466501744, 40.58349332693904\n",
      "RESULTADOS DE MSE, RMSE, R2, MAPE (Test): 30.19989208883748, 5.49544284738159, 0.7109956473826915, 39.595025150939\n"
     ]
    }
   ],
   "source": [
    "df_Not_Freeze = pd.DataFrame(columns = [\"File\", \"Time\", \"TrainMSE\", \"TrainRMSE\", \"TrainR2\", \"TrainMAPE\", \n",
    "                                \"ValidationMSE\", \"ValidationRMSE\", \"ValidationR2\", \"ValidationMAPE\",\n",
    "                                \"TestMSE\", \"TestRMSE\", \"TestR2\", \"TestMAPE\"])\n",
    "\n",
    "for archivo in os.listdir(\"RCPMerged\"):\n",
    "\n",
    "    if archivo != \"totalMerged.csv\" and archivo != \"Abies spectabilis_merged.csv\":\n",
    "\n",
    "        # Cargar el archivo CSV con punto y coma como delimitador\n",
    "        df = pd.read_csv(f'RCPMerged/{archivo}')\n",
    "        df = df[~df[\"nametag\"].str.startswith(\"INDI005\")]\n",
    "\n",
    "        # Codificamos, normalización y split de datos\n",
    "        df = codification(df)\n",
    "        print(df.shape)\n",
    "\n",
    "        df, valorNormalizacion = individualNormalization(df)\n",
    "        print(f'SE HA NORMALIZADO EL ARCHIVO: {archivo.replace(\"_\",\" \")}')\n",
    "\n",
    "        temp_df = df\n",
    "        train_data, val_data, test_data = split_population_individuals(temp_df, train_pct=0.80, val_pct_in_train=0.20, details=False)\n",
    "        train_data.shape, val_data.shape, test_data.shape\n",
    "\n",
    "        # Obtenemos X e y para los datasets de train, val y test \n",
    "        WINDOWS_SIZE = 3\n",
    "        X_train, y_train = df_to_X_y_ind_3(train_data, WINDOWS_SIZE)\n",
    "        X_val, y_val = df_to_X_y_ind_3(val_data, WINDOWS_SIZE)\n",
    "        X_test, y_test = df_to_X_y_ind_3(test_data, WINDOWS_SIZE)\n",
    "        print(X_train.shape, X_test.shape, X_val.shape)\n",
    "\n",
    "        # Lectura de la arquitectura del modelo LSTM\n",
    "        with open(f'arquitecturaModelosJSON/LSTM/{archivo.split(\".csv\")[0]}_best_models_updated_no_train.json', \"r\") as f:\n",
    "            arquitectura_json = json.load(f)\n",
    "\n",
    "        arquitecturaLSTM = arquitectura_json[0]\n",
    "\n",
    "        # Crear el modelo desde cero basado en las configuraciones\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        modelLSTM = create_lstm_model(arquitecturaLSTM, input_shape)\n",
    "\n",
    "        # Obtener el optimizador y otros hiperparámetros desde el JSON\n",
    "        learning_rate = arquitecturaLSTM['learning_rate']\n",
    "        optimizer_name = arquitecturaLSTM['optimizer']\n",
    "        batch_size_LSTM = arquitecturaLSTM['batch_size']\n",
    "\n",
    "        if optimizer_name == 'rmsprop':\n",
    "            opt = RMSprop(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'adam':\n",
    "            opt = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_name == 'sgd':\n",
    "            opt = SGD(learning_rate=learning_rate)\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizador {optimizer_name} no reconocido\")\n",
    "\n",
    "        # Compilar el modelo con los hiperparámetros del JSON\n",
    "        modelLSTM.compile(optimizer=opt,\n",
    "                    loss=MeanSquaredError(),\n",
    "                    metrics=[\n",
    "                        MeanSquaredError(name='mse'),\n",
    "                        RootMeanSquaredError(name='rmse'),\n",
    "                        MeanAbsolutePercentageError(name='mape')\n",
    "                    ])\n",
    "        \n",
    "        # Inicio del entrenamiento \n",
    "        start_time = time.time()\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        historyLSTM = modelLSTM.fit(X_train, y_train, epochs=200, batch_size=batch_size_LSTM,\n",
    "                    validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss', patience=20)], verbose = 0)\n",
    "        \n",
    "        # Finaliza la medición del tiempo de entrenamiento\n",
    "        end_time = time.time()\n",
    "        print(f\"[MODELO CONGELADO]: {end_time-start_time}\")\n",
    "\n",
    "        # Guardamos el modelo entrenado \n",
    "        modelLSTM.save(f'models/model_{archivo.split(\"_merged\")[0]}.keras')\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de entrenamiento\n",
    "        predictions_train = predictionForIndividuals(X_train, y_train, modelLSTM, batch_size_LSTM)\n",
    "        predictions_train[\"PredictionsDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_train[\"ActualDenormalize\"] = predictions_train.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        train_mse = mean_squared_error(predictions_train[\"ActualDenormalize\"],predictions_train[\"PredictionsDenormalize\"])\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        train_mape = (np.sum(np.abs(predictions_train[\"PredictionsDenormalize\"] - predictions_train[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_train[\"ActualDenormalize\"]))) * 100\n",
    "        train_r2 = r2_score(predictions_train[\"ActualDenormalize\"], predictions_train[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de validación\n",
    "        predictions_val = predictionForIndividuals(X_val, y_val, modelLSTM, batch_size_LSTM)\n",
    "        predictions_val[\"PredictionsDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_val[\"ActualDenormalize\"] = predictions_val.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        val_mse = mean_squared_error(predictions_val[\"ActualDenormalize\"],predictions_val[\"PredictionsDenormalize\"])\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        val_mape = (np.sum(np.abs(predictions_val[\"PredictionsDenormalize\"] - predictions_val[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_val[\"ActualDenormalize\"]))) * 100\n",
    "        val_r2 = r2_score(predictions_val[\"ActualDenormalize\"], predictions_val[\"PredictionsDenormalize\"])\n",
    "\n",
    "        # Realizar predicciones y calcular métricas para el conjunto de prueba\n",
    "        predictions_test = predictionForIndividuals(X_test, y_test, modelLSTM, batch_size_LSTM)\n",
    "        predictions_test[\"PredictionsDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Predictions\"), axis=1)\n",
    "        predictions_test[\"ActualDenormalize\"] = predictions_test.apply(lambda row: desnormalizacionBAI(row, valorNormalizacion, \"Actuals\"), axis=1)\n",
    "\n",
    "        test_mse = mean_squared_error(predictions_test[\"ActualDenormalize\"],predictions_test[\"PredictionsDenormalize\"])\n",
    "        test_rmse = np.sqrt(test_mse)\n",
    "        test_mape = (np.sum(np.abs(predictions_test[\"PredictionsDenormalize\"] - predictions_test[\"ActualDenormalize\"])) / np.sum(np.abs(predictions_test[\"ActualDenormalize\"]))) * 100\n",
    "        test_r2 = r2_score(predictions_test[\"ActualDenormalize\"], predictions_test[\"PredictionsDenormalize\"])\n",
    "\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Train): {train_mse}, {train_rmse}, {train_r2}, {train_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Val): {val_mse}, {val_rmse}, {val_r2}, {val_mape}\")\n",
    "        print(f\"RESULTADOS DE MSE, RMSE, R2, MAPE (Test): {test_mse}, {test_rmse}, {test_r2}, {test_mape}\")\n",
    "\n",
    "        # Guardamos los datos calculados\n",
    "        df_Not_Freeze.loc[len(df_Not_Freeze)] = [archivo, end_time-start_time,train_mse, train_rmse, train_r2, train_mape, val_mse, val_rmse, val_r2, val_mape, test_mse, test_rmse, test_r2, test_mape]\n",
    "\n",
    "df_Not_Freeze.to_csv(\"resultados_Not_Transfer.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
